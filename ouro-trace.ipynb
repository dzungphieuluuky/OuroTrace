{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzungphieuluuky/OuroTrace/blob/claude/ouro-trace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup libraries"
      ],
      "metadata": {
        "id": "S0M-JZCdnzA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip uninstall -y transformers tokenizers accelerate -q\n",
        "!pip install \"transformers==4.56.0\" \"protobuf==5.29.3\" -q\n",
        "!pip install torch datasets -q\n",
        "!pip install pandas matplotlib seaborn tqdm wandb pyyaml\n",
        "!pip install bitsandbytes accelerate\n",
        "# !pip install -r requirements.txt\n",
        "!pip install --force-reinstall --no-cache-dir \"numpy<2.0\""
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tjC_YOBlnzA-",
        "outputId": "7f5f929e-63cc-4b3c-df6f-dbf4b2dc4b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.0 requires accelerate>=0.21.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.3)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.0)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
            "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-1.12.0\n",
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1b16415ddd5f4884bc5a85e47292c082"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the latest github repo version\n",
        "import os\n",
        "def configure_environment_paths():\n",
        "    \"\"\"Detect environment and configure paths\"\"\"\n",
        "    try:\n",
        "        if \"google.colab\" in str(get_ipython()):\n",
        "            print(\"‚úÖ Environment: Google Colab\")\n",
        "            base_data_path = \"/content/\"\n",
        "            base_output_path = \"/content/\"\n",
        "            environment_name = \"colab\"\n",
        "        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
        "            print(\"‚úÖ Environment: Kaggle\")\n",
        "            base_data_path = \"/kaggle/input/\"\n",
        "            base_output_path = \"/kaggle/working/\"\n",
        "            environment_name = \"kaggle\"\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n",
        "            base_data_path = \"./data/\"\n",
        "            base_output_path = \"./output/\"\n",
        "            environment_name = \"local\"\n",
        "    except NameError:\n",
        "        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n",
        "        base_data_path = \"./data/\"\n",
        "        base_output_path = \"./output/\"\n",
        "        environment_name = \"local\"\n",
        "\n",
        "    os.makedirs(base_output_path, exist_ok=True)\n",
        "    print(f\"üìÇ Data Path: {base_data_path}\")\n",
        "    print(f\"üì¶ Output Path: {base_output_path}\")\n",
        "\n",
        "    return base_data_path, base_output_path, environment_name\n",
        "\n",
        "INPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\n",
        "%cd /content/\n",
        "!rm -r -f OuroTrace\n",
        "!git clone --branch claude https://github.com/dzungphieuluuky/OuroTrace.git\n",
        "%cd OuroTrace"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyaPdq3RnzA8",
        "outputId": "4be7df9b-9c12-4237-b29a-b8759e338991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment: Google Colab\n",
            "üìÇ Data Path: /content/\n",
            "üì¶ Output Path: /content/\n",
            "/content\n",
            "Cloning into 'OuroTrace'...\n",
            "remote: Enumerating objects: 834, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 834 (delta 37), reused 41 (delta 23), pack-reused 777 (from 1)\u001b[K\n",
            "Receiving objects: 100% (834/834), 1.35 MiB | 3.57 MiB/s, done.\n",
            "Resolving deltas: 100% (551/551), done.\n",
            "/content/OuroTrace\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config input/output path and clone latest repo"
      ],
      "metadata": {
        "id": "wDA1HyzsnzA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress warnings for clean output\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\n",
        "print(\"‚úÖ Packages installed successfully!\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3KSZamlnzA_",
        "outputId": "8f406d48-0bb7-45dd-bfe6-6f2e0292cc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Packages installed successfully!\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "\"Built-in libraries\"\n",
        "import re\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import hashlib\n",
        "import glob\n",
        "import zipfile\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "import yaml\n",
        "import logging\n",
        "import random\n",
        "\n",
        "\"Deep learning and NLP libraries\"\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    GenerationConfig,\n",
        "    logging as hf_logging\n",
        ")\n",
        "\n",
        "\"Data processing libraries\"\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from tqdm.auto import tqdm\n",
        "from IPython import get_ipython\n",
        "\n",
        "# Configure logging\n",
        "logging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\n",
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "print(f\"Python Version: {sys.version}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW3-Anw9nzBA",
        "outputId": "a9823ce2-9159-42aa-ee3a-714bd2be9de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch Version: 2.9.0+cu126\n",
            "CUDA Available: True\n",
            "CUDA Version: 12.6\n",
            "Thu Dec 18 16:14:02 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "# 1. Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "    try:\n",
        "        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n",
        "        wandb_key = userdata.get('WANDB_API_KEY')\n",
        "        wandb.login(key=wandb_key)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n",
        "\n",
        "# 2. Check if running in Kaggle\n",
        "elif os.path.exists('/kaggle/input'):\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        user_secrets = UserSecretsClient()\n",
        "        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
        "        wandb.login(key=wandb_key)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaOteqd3nzBA",
        "outputId": "2fd26858-32cd-4ad9-e584-9841f9d74556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from src.config_loader import load_config_from_json, post_process_config\n",
        "\n",
        "# this is the fused version when single and batch use the same predict function\n",
        "from src.new_runner import run_batch_experiment\n",
        "\n",
        "# this is the original version when single and batch use different functions\n",
        "# from src.runner import run_batch_experiment\n",
        "\n",
        "from src.evaluation import analyze_experiment_results\n",
        "\n",
        "\n",
        "# 1. Load Configuration from JSON\n",
        "config = load_config_from_json('configs/batch_ouro_1.4b_thinking.json')\n",
        "\n",
        "# 2. Post-process (Convert 'torch.float16' string to object, generate timestamps)\n",
        "config = post_process_config(config)\n",
        "\n",
        "config[\"INFERENCE_STEPS\"] = [4]\n",
        "config[\"OPTIMIZATION\"][\"enable_batch\"] = False\n",
        "config[\"DATA\"][\"n_ary\"][\"num_samples_per_level\"] = 1\n",
        "config[\"reasoning_primitives\"][\"num_samples\"] = 5\n",
        "\n",
        "# 4. Execute\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "print(f\"üïí Timestamp: {timestamp}\")\n",
        "print(\"üöÄ Starting Experiment...\")\n",
        "acc_results, ppl_results, hol_results = run_batch_experiment(config)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKc8czt-nzBB",
        "outputId": "89fcd57d-9eb4-4f30-c8f3-448fc4f2c4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üïí Timestamp: 20251218_161404\n",
            "üöÄ Starting Experiment...\n",
            "üîó Initializing W&B (timeout: 30s)...\n",
            "‚ö†Ô∏è W&B initialization failed: 1 validation error for Settings\n",
            "start_timeout\n",
            "  Extra inputs are not permitted [type=extra_forbidden, input_value=30, input_type=int]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden. Continuing offline.\n",
            "\n",
            "======================================================================\n",
            "üîß EXPERIMENT CONFIGURATION\n",
            "======================================================================\n",
            "Model Path: ByteDance/Ouro-1.4B-Thinking\n",
            "UT Steps to Test: [4]\n",
            "Data Type: torch.bfloat16\n",
            "4-bit Quantization: False\n",
            "Torch Compile: True\n",
            "Max Batch Size: 8\n",
            "Max New Tokens: 512\n",
            "Batching: False\n",
            "Calculate Perplexity: True\n",
            "Early Exit: 1.0\n",
            "======================================================================\n",
            "\n",
            "[+] Quality monitor initialized:\n",
            "    ‚Üí Garbage threshold: 30%\n",
            "    ‚Üí Example similarity threshold: 85%\n",
            "    ‚Üí Min samples before check: 10\n",
            "üé≤ Random seed set to 42\n",
            "\n",
            "======================================================================\n",
            "üì¶ LOADING TEST DATASETS\n",
            "======================================================================\n",
            "‚öôÔ∏è Generating new test datasets...\n",
            "‚úÖ Generated test datasets\n",
            "\n",
            "Dataset Summary:\n",
            "   n_ary       :    3 samples\n",
            "   p_hop       :   24 samples\n",
            "   igsm        :    8 samples\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üìã PAPER COMPLIANCE CHECK\n",
            "======================================================================\n",
            "Task Alignment: {'has_n_ary': True, 'has_p_hop': True, 'has_igsm': True, 'all_paper_tasks': True}\n",
            "UT Steps Coverage: {'min_ut': 4, 'max_ut': 4, 'covers_baseline': False, 'covers_paper_range': False, 'recommended_range': [1, 2, 4, 8]}\n",
            "======================================================================\n",
            "\n",
            "üìö Preparing perplexity evaluation data...\n",
            "‚úÖ Prepared 50 samples for PPL\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üß™ EXPERIMENT 1/1: UT Steps = 4\n",
            "======================================================================\n",
            "\n",
            "‚öôÔ∏è  AUTO-OPTIMIZATION SETTINGS:\n",
            "   Batch Processing: ‚ùå DISABLED\n",
            "   Torch Compile: ‚úÖ ENABLED\n",
            "   NOTE: torch.compile is not the culprit, batching with generate(), not with generate_batch() function.\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚öôÔ∏è  LOADING MODEL CONFIGURATION\n",
            "============================================================\n",
            "Model Path: ByteDance/Ouro-1.4B-Thinking\n",
            "Requested UT Steps: 4\n",
            "Data Type: torch.bfloat16\n",
            "4-bit Quantization: False\n",
            "Torch Compile: True\n",
            "\n",
            "‚Üí Base config loaded\n",
            "   Original UT steps: 4\n",
            "   Original early exit: 1.0\n",
            "\n",
            "‚Üí Modified config:\n",
            "   New UT steps: 4\n",
            "   Early exit threshold: 1.0 (from default)\n",
            "\n",
            "‚Üí Tokenizer loaded\n",
            "   Vocab size: 49152\n",
            "   PAD token: <|im_end|>\n",
            "   EOS token: <|im_end|>\n",
            "\n",
            "‚Üí Loading model weights...\n",
            "‚Üí Applying torch.compile()\n",
            "\n",
            "============================================================\n",
            "‚úÖ MODEL LOADED SUCCESSFULLY\n",
            "============================================================\n",
            "Device: cuda:0\n",
            "Model dtype: torch.bfloat16\n",
            "VERIFIED UT steps: 4\n",
            "VERIFIED early exit: 1.0\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üöÄ APPLYING SAFE OPTIMIZATIONS (UT Steps = 4)\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Optimizing attention backend\n",
            "   ‚Üí Flash Attention / Memory-Efficient SDPA enabled\n",
            "‚úÖ Applying inference optimizations\n",
            "   ‚Üí TF32 enabled for matmul\n",
            "   ‚Üí cuDNN auto-tuning enabled\n",
            "‚úÖ Optimizing CUDA memory allocation\n",
            "   ‚Üí Memory pool optimized\n",
            "‚úÖ Warming up model (3 passes)...\n",
            "   ‚Üí Pass 1/3 (compiling kernels...)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Save Results\n",
        "df_acc = pd.DataFrame(acc_results)\n",
        "df_ppl = pd.DataFrame(ppl_results)\n",
        "df_hol = pd.DataFrame(hol_results)\n",
        "# 4. Visualization & Reporting\n",
        "if not df_acc.empty:\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\nüìä VISUALIZATION\\n\" + \"=\"*50)\n",
        "\n",
        "    # Summary Tables\n",
        "    # NOTE: The variable 'results_acc' is used here, assuming it holds the raw data\n",
        "    # (list of dicts) required by 'analyze_experiment_results'.\n",
        "    summary = analyze_experiment_results(acc_results)\n",
        "    print(\"\\n--- Summary Statistics ---\")\n",
        "    print(summary)\n",
        "\n",
        "    # Plotting\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "        # Plot 1: Accuracy\n",
        "        acc_summary = df_acc.groupby(['task_type', 'ut_steps'])['is_correct'].mean().reset_index()\n",
        "        sns.barplot(data=acc_summary, x='ut_steps', y='is_correct', hue='task_type', ax=axes[0])\n",
        "        axes[0].set_title('Accuracy by UT Steps')\n",
        "        axes[0].set_ylabel('Accuracy')\n",
        "        axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
        "\n",
        "        # Plot 2: Time\n",
        "        time_summary = df_acc.groupby(['task_type', 'ut_steps'])['generation_time'].mean().reset_index()\n",
        "        sns.barplot(data=time_summary, x='ut_steps', y='generation_time', hue='task_type', ax=axes[1])\n",
        "        axes[1].set_title('Inference Time (s) by UT Steps')\n",
        "\n",
        "        # Plot 3: Token Count\n",
        "        sns.boxplot(data=df_acc, x='ut_steps', y='generated_tokens', hue='task_type', ax=axes[2])\n",
        "        axes[2].set_title('Generated Tokens Distribution')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Visualization error: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No results to visualize.\")\n",
        "\n",
        "print(\"\\nüèÅ Experiment Complete.\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "0p4QBYsDnzBB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "\n",
        "def zip_all_results_folders(output_base_path: str):\n",
        "    os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "    search_pattern = os.path.join(output_base_path, \"results_*\")\n",
        "    results_folders = glob.glob(search_pattern)\n",
        "    results_directories = [d for d in results_folders if os.path.isdir(d)]\n",
        "\n",
        "    if not results_directories:\n",
        "        print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c n√†o b·∫Øt ƒë·∫ßu b·∫±ng 'results_' trong '{output_base_path}'.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîç T√¨m th·∫•y {len(results_directories)} th∆∞ m·ª•c k·∫øt qu·∫£ ƒë·ªÉ n√©n.\")\n",
        "\n",
        "    successful_zips = 0\n",
        "\n",
        "    for folder_path in results_directories:\n",
        "        folder_name = os.path.basename(folder_path)\n",
        "        zip_filename = os.path.join(output_base_path, f\"{folder_name}.zip\")\n",
        "\n",
        "        try:\n",
        "            print(f\"\\n   -> ƒêang n√©n th∆∞ m·ª•c: {folder_name}...\")\n",
        "\n",
        "            with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "                for root, _, files in os.walk(folder_path):\n",
        "                    for file in files:\n",
        "                        file_path = os.path.join(root, file)\n",
        "                        arcname = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
        "                        zipf.write(file_path, arcname)\n",
        "\n",
        "            print(f\"   ‚úÖ ƒê√£ t·∫°o file ZIP: {os.path.basename(zip_filename)}\")\n",
        "            successful_zips += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå L·ªói khi n√©n th∆∞ m·ª•c {folder_name}: {e}\")\n",
        "\n",
        "    print(f\"\\n‚úÖ HO√ÄN T·∫§T! ƒê√£ n√©n th√†nh c√¥ng {successful_zips} tr√™n {len(results_directories)} th∆∞ m·ª•c k·∫øt qu·∫£.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    if 'OUTPUT_PATH' in globals():\n",
        "        zip_all_results_folders(OUTPUT_PATH)\n",
        "    else:\n",
        "        print(\"OUTPUT_PATH not defined.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"OUTPUT_PATH not defined.\")\n",
        "except Exception as e:\n",
        "    print(f\"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh n√©n: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "8inXWmVwnzBC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Inspection:\\n\")\n",
        "print(\"Top 20 Accuracy Report:\\n\")\n",
        "print(df_acc.head(20))\n",
        "print(f\"Full Response:\\n\")\n",
        "print(df_acc['full_response'])\n",
        "print(\"Perplexity Report:\\n\")\n",
        "print(df_ppl.head(20))"
      ],
      "metadata": {
        "trusted": true,
        "id": "3zpz9ccInzBD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_acc[['full_response', 'generated_tokens']])"
      ],
      "metadata": {
        "trusted": true,
        "id": "EDWCUkMqnzBD"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}