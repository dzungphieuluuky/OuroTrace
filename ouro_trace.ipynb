{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFjYdqo8Q-E1"
   },
   "source": [
    "<a href=\"https://www.kaggle.com/code/dzung271828/ouro-trace?scriptVersionId=288557226\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0M-JZCdnzA6"
   },
   "source": [
    "# Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:26.626721Z",
     "iopub.status.busy": "2025-12-26T15:01:26.62614Z",
     "iopub.status.idle": "2025-12-26T15:01:29.159696Z",
     "shell.execute_reply": "2025-12-26T15:01:29.158969Z",
     "shell.execute_reply.started": "2025-12-26T15:01:26.626698Z"
    },
    "id": "tjC_YOBlnzA-",
    "outputId": "7d998f0c-a3c1-4eea-c08e-b6a4a678a8df",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!uv pip install --upgrade pip\n",
    "!uv pip uninstall transformers tokenizers accelerate -q\n",
    "\n",
    "!uv pip install \"transformers==4.56.0\" \"protobuf==5.29.3\" -q\n",
    "!uv pip install torch datasets -q\n",
    "!uv pip install pandas matplotlib seaborn tqdm wandb pyyaml\n",
    "!uv pip install bitsandbytes accelerate optimum lm_eval\n",
    "# !uv pip install -r requirements.txt\n",
    "!uv pip install --force-reinstall --no-cache-dir \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t_XpUsOs_my"
   },
   "source": [
    "# Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:29.161514Z",
     "iopub.status.busy": "2025-12-26T15:01:29.161259Z",
     "iopub.status.idle": "2025-12-26T15:01:29.166226Z",
     "shell.execute_reply": "2025-12-26T15:01:29.165483Z",
     "shell.execute_reply.started": "2025-12-26T15:01:29.161489Z"
    },
    "id": "t3KSZamlnzA_",
    "outputId": "67ccee26-9c48-43d7-d429-3f262ee264e4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Suppress warnings for clean output\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abWE_VV3s_my"
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:29.167333Z",
     "iopub.status.busy": "2025-12-26T15:01:29.167072Z",
     "iopub.status.idle": "2025-12-26T15:01:29.435225Z",
     "shell.execute_reply": "2025-12-26T15:01:29.434416Z",
     "shell.execute_reply.started": "2025-12-26T15:01:29.167308Z"
    },
    "id": "vW3-Anw9nzBA",
    "outputId": "b112d497-5b40-4269-9a01-f75c989f09c1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"Built-in libraries\"\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import glob\n",
    "import zipfile\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import yaml\n",
    "import logging\n",
    "import random\n",
    "\n",
    "\"Deep learning and NLP libraries\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    "    logging as hf_logging,\n",
    ")\n",
    "\n",
    "\"Data processing libraries\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Configure logging\n",
    "logging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:29.436701Z",
     "iopub.status.busy": "2025-12-26T15:01:29.43644Z",
     "iopub.status.idle": "2025-12-26T15:01:29.443721Z",
     "shell.execute_reply": "2025-12-26T15:01:29.442967Z",
     "shell.execute_reply.started": "2025-12-26T15:01:29.436675Z"
    },
    "id": "NxqV6hTMs_mz",
    "outputId": "3fc8f675-cf3d-42b5-8205-568f643055fa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def configure_environment_paths():\n",
    "    \"\"\"Detect environment and configure paths\"\"\"\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            print(\"‚úÖ Environment: Google Colab\")\n",
    "            base_data_path = \"/content/\"\n",
    "            base_output_path = \"/content/\"\n",
    "            environment_name = \"colab\"\n",
    "        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "            print(\"‚úÖ Environment: Kaggle\")\n",
    "            base_data_path = \"/kaggle/input/\"\n",
    "            base_output_path = \"/kaggle/working/\"\n",
    "            environment_name = \"kaggle\"\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n",
    "            base_data_path = \"./data/\"\n",
    "            base_output_path = \"./output/\"\n",
    "            environment_name = \"local\"\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n",
    "        base_data_path = \"./data/\"\n",
    "        base_output_path = \"./output/\"\n",
    "        environment_name = \"local\"\n",
    "\n",
    "    os.makedirs(base_output_path, exist_ok=True)\n",
    "    print(f\"üìÇ Data Path: {base_data_path}\")\n",
    "    print(f\"üì¶ Output Path: {base_output_path}\")\n",
    "\n",
    "    return base_data_path, base_output_path, environment_name\n",
    "\n",
    "\n",
    "INPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0HV8HMrs_mz"
   },
   "source": [
    "# Setup WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:29.446153Z",
     "iopub.status.busy": "2025-12-26T15:01:29.44586Z",
     "iopub.status.idle": "2025-12-26T15:01:29.637392Z",
     "shell.execute_reply": "2025-12-26T15:01:29.63687Z",
     "shell.execute_reply.started": "2025-12-26T15:01:29.446136Z"
    },
    "id": "UaOteqd3nzBA",
    "outputId": "1ccccb83-55a1-4d6d-e283-1392a0c8074e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "if \"colab\" in ENV_NAME:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    try:\n",
    "        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n",
    "        wandb_key = userdata.get(\"WANDB_API_KEY\")\n",
    "        wandb.login(key=wandb_key)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n",
    "\n",
    "# 2. Check if running in Kaggle\n",
    "elif \"kaggle\" in ENV_NAME:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "        user_secrets = UserSecretsClient()\n",
    "        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "        wandb.login(key=wandb_key)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDA1HyzsnzA_"
   },
   "source": [
    "# Config input/output path and clone latest repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:29.638187Z",
     "iopub.status.busy": "2025-12-26T15:01:29.637985Z",
     "iopub.status.idle": "2025-12-26T15:01:29.782772Z",
     "shell.execute_reply": "2025-12-26T15:01:29.781898Z",
     "shell.execute_reply.started": "2025-12-26T15:01:29.638171Z"
    },
    "id": "qyaPdq3RnzA8",
    "outputId": "3c2188b8-b655-47b6-9586-4320a38fc543",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Clone the latest github repo version\n",
    "%cd {OUTPUT_PATH}\n",
    "torch.cuda.empty_cache()\n",
    "!rm -rf OuroTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:29.784001Z",
     "iopub.status.busy": "2025-12-26T15:01:29.783774Z",
     "iopub.status.idle": "2025-12-26T15:01:30.609172Z",
     "shell.execute_reply": "2025-12-26T15:01:30.608411Z",
     "shell.execute_reply.started": "2025-12-26T15:01:29.783978Z"
    },
    "id": "3S4kc_Vjs_m0",
    "outputId": "e2428bf8-5703-4306-a964-c8e00feb8a35",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone --branch claude https://github.com/dzungphieuluuky/OuroTrace.git\n",
    "%cd OuroTrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmJUVG32s_m0"
   },
   "source": [
    "# Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:01:30.610463Z",
     "iopub.status.busy": "2025-12-26T15:01:30.610233Z"
    },
    "id": "CKc8czt-nzBB",
    "outputId": "642f029b-808b-4223-ca83-fb7fb65c08c8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.config_loader import load_config_from_json, post_process_config\n",
    "from runner import run_experiment\n",
    "from src.evaluation_analysis import analyze_experiment_results\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)                          # Python random\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Python hash seed\n",
    "    np.random.seed(seed)                      # NumPy\n",
    "    torch.manual_seed(seed)                   # PyTorch CPU & GPU\n",
    "\n",
    "    # Additional GPU-specific settings\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)      # For multi-GPU\n",
    "\n",
    "set_all_seeds(1415)\n",
    "# 1. Load Configuration from JSON\n",
    "config = load_config_from_json(\"configs/ouro_1.4b_thinking.json\")\n",
    "\n",
    "# 2. Post-process (Convert 'torch.float16' string to object, generate timestamps)\n",
    "config = post_process_config(config)\n",
    "\n",
    "config[\"INFERENCE_STEPS\"] = [4]\n",
    "config[\"OPTIMIZATION\"][\"enable_batch\"] = False\n",
    "config[\"MODEL\"][\"use_torch_compile\"] = True\n",
    "\n",
    "# config[\"EVAL_SETTINGS\"][\"calculate_perplexity\"] = False\n",
    "# config[\"DATA\"][\"n_ary\"][\"num_samples_per_level\"] = 0\n",
    "# config[\"DATA\"][\"p_hop\"][\"num_samples_per_level\"] = 0\n",
    "# config[\"DATA\"][\"igsm\"][\"num_samples\"] = 0\n",
    "# config[\"DATA\"][\"reasoning_primitives\"][\"num_samples\"] = 0\n",
    "\n",
    "# 4. Execute\n",
    "print(\"üöÄ Starting Experiment...\")\n",
    "try:\n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    simple_reasoning_results, ppl_results, primitives_results, benchmark_results = run_experiment(config)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8inXWmVwnzBC",
    "outputId": "6302a19d-5042-4b2b-c1f0-2353ce63e948",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "from typing import List\n",
    "def find_result_folders(base_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return a list of absolute paths to all directories under `base_path`\n",
    "    whose names start with 'results_'.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(base_path, \"results_*\")\n",
    "    # glob returns both files and directories; filter to directories only\n",
    "    return [p for p in glob.glob(pattern) if os.path.isdir(p)]\n",
    "def zip_folder(folder_path: str, output_base_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Zip the contents of `folder_path` into a file named\n",
    "    <folder_name>.zip` inside `output_base_path`.\n",
    "\n",
    "    Returns True on success, False otherwise.\n",
    "    \"\"\"\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    zip_path = os.path.join(output_base_path, f\"{folder_name}.zip\")\n",
    "    try:\n",
    "        print(f\"   -> Zipping folder: {folder_name}...\")\n",
    "        with zipfile.ZipFile(\n",
    "            zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED\n",
    "        ) as zipf:\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    # Preserve relative path inside the zip\n",
    "                    arcname = os.path.relpath(full_path, os.path.dirname(folder_path))\n",
    "                    zipf.write(full_path, arcname)\n",
    "        print(f\"   ‚úÖ Created ZIP: {os.path.basename(zip_path)}\")\n",
    "        return True\n",
    "    except Exception as exc:\n",
    "        print(f\"   ‚ùå Failed to zip {folder_name}: {exc}\")\n",
    "        return False\n",
    "def zip_stats_results_folders(output_base_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Main driver: locate all result folders and zip each one.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "    result_folders = find_result_folders(output_base_path)\n",
    "    if not result_folders:\n",
    "        print(f\"‚ö†Ô∏è No folders starting with 'results_' found in '{output_base_path}'.\")\n",
    "        return\n",
    "    print(f\"üîç Found {len(result_folders)} result folder(s) to zip.\")\n",
    "    successful = 0\n",
    "    for folder in result_folders:\n",
    "        if zip_folder(folder, output_base_path):\n",
    "            successful += 1\n",
    "    print(\n",
    "        f\"\\n‚úÖ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\"\n",
    "    )\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Prefer an environment variable; fall back to a global if defined\n",
    "        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n",
    "        if not output_root:\n",
    "            raise ValueError(\"OUTPUT_PATH not defined\")\n",
    "        # The script expects a sub‚Äëfolder named 'OuroTrace' under OUTPUT_PATH\n",
    "        target_path = os.path.join(output_root, \"\")\n",
    "        zip_stats_results_folders(target_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zpz9ccInzBD",
    "outputId": "7367fb72-b55e-440b-a15b-6f1b6e9e5d67",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_simple = pd.DataFrame(simple_reasoning_results)\n",
    "df_ppl = pd.DataFrame(ppl_results)\n",
    "\n",
    "print(\"Final Inspection:\\n\")\n",
    "print(\"Top 20 Accuracy Report:\\n\")\n",
    "print(df_simple.head(20))\n",
    "print(f\"Full Response:\\n\")\n",
    "print(df_simple[\"full_response\"])\n",
    "print(\"Perplexity Report:\\n\")\n",
    "print(df_ppl.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDWCUkMqnzBD",
    "outputId": "731156b0-54c4-41d2-a3ad-c6c93193fef0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_simple[[\"full_response\", \"generated_tokens\"]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ourotrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "070510a8fc544415b22064f02f3d10b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2259429e5d534c228b4df6475b4ae337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30a7bc39d0054376afc124bfbad6db54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3265a61b55954ce6aead7dfd4b716574": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_386786d9ab64458fb1f435151655bd72",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30a7bc39d0054376afc124bfbad6db54",
      "value": 8
     }
    },
    "386786d9ab64458fb1f435151655bd72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "454290f4c59c430f87c5457c695f00bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ffcc357d35e42f0bad07feee5395cbe",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5f72ac54802e42e09093dd2bdb96368a",
      "value": "‚Äá‚Äá‚Äán_ary:‚Äá‚Äá‚Äá2%"
     }
    },
    "5f72ac54802e42e09093dd2bdb96368a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ffcc357d35e42f0bad07feee5395cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2359f2feba346c285640a9d563fb978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f01740e30a1e4f73a2258ffb2631bbbd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_070510a8fc544415b22064f02f3d10b1",
      "value": "‚Äá8/500‚Äá[01:45&lt;1:46:02,‚Äá12.93s/it]"
     }
    },
    "ef92f2bc151b4288a8b849d43c83f53e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_454290f4c59c430f87c5457c695f00bf",
       "IPY_MODEL_3265a61b55954ce6aead7dfd4b716574",
       "IPY_MODEL_a2359f2feba346c285640a9d563fb978"
      ],
      "layout": "IPY_MODEL_2259429e5d534c228b4df6475b4ae337"
     }
    },
    "f01740e30a1e4f73a2258ffb2631bbbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
