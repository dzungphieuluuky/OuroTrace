{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"gpuType":"T4","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cbfa7e05d2bc4756b80e6857a1b9ff93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0aa1a6cab3d4ff080cbd337ed760694","IPY_MODEL_087021df58824f188d1679892365584b","IPY_MODEL_9d2e1ec21b334579a737498e15660187"],"layout":"IPY_MODEL_86a6c9926c094201a3894b53f773f805"}},"b0aa1a6cab3d4ff080cbd337ed760694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb84f1120a6b43ce8f47bd9464acdc6c","placeholder":"​","style":"IPY_MODEL_af6d89cb3e7c454e867837b23e263a6d","value":"config.json: "}},"087021df58824f188d1679892365584b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9840a19e36994155be216ca06ed6102a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92bad06f017342caae546d5ec3d0580d","value":1}},"9d2e1ec21b334579a737498e15660187":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52ee5800bdc647fa8be85aaa7fee5576","placeholder":"​","style":"IPY_MODEL_14aada98d09641e78a96c642a57739f8","value":" 1.47k/? [00:00&lt;00:00, 161kB/s]"}},"86a6c9926c094201a3894b53f773f805":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb84f1120a6b43ce8f47bd9464acdc6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6d89cb3e7c454e867837b23e263a6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9840a19e36994155be216ca06ed6102a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"92bad06f017342caae546d5ec3d0580d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52ee5800bdc647fa8be85aaa7fee5576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14aada98d09641e78a96c642a57739f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f81db505830a46cd8476f112c294fdf8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd1e0b595efd4004b3d7b99a6d1d2c86","IPY_MODEL_6a26ebaa5485490091bc925d3d84bea2","IPY_MODEL_f6777f8e272c49c9bbad82f5df9dd6b0"],"layout":"IPY_MODEL_951e227348484175bf0ef5d05ff16f23"}},"fd1e0b595efd4004b3d7b99a6d1d2c86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_760e7d679d04432ab13f673a3dff7cc0","placeholder":"​","style":"IPY_MODEL_e27de45d7def43dab1d9655f43c7de2a","value":"configuration_ouro.py: "}},"6a26ebaa5485490091bc925d3d84bea2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86413511a63744f79321d4f108d5faf9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1531c3ed5a941a588a43fca48bd9084","value":1}},"f6777f8e272c49c9bbad82f5df9dd6b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82312216be9d4b28ae82d67428e717d6","placeholder":"​","style":"IPY_MODEL_1bacddad80a54403a38ba59837979090","value":" 11.6k/? [00:00&lt;00:00, 896kB/s]"}},"951e227348484175bf0ef5d05ff16f23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"760e7d679d04432ab13f673a3dff7cc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e27de45d7def43dab1d9655f43c7de2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86413511a63744f79321d4f108d5faf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b1531c3ed5a941a588a43fca48bd9084":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82312216be9d4b28ae82d67428e717d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bacddad80a54403a38ba59837979090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6586524ac76f4a668f26192a782de9d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c38ec7f28c7047a88238b292a81fbaf2","IPY_MODEL_f07062d77612431bb8b603b7b3a94ed4","IPY_MODEL_843ae3732e7f4737beaaac3a634de464"],"layout":"IPY_MODEL_108b9245822c49f3a637036ab2fea623"}},"c38ec7f28c7047a88238b292a81fbaf2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06449a215bc64e2ba973b0b3d469fd41","placeholder":"​","style":"IPY_MODEL_756aed11677a4dfbbaa17230590d36bc","value":"tokenizer_config.json: "}},"f07062d77612431bb8b603b7b3a94ed4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b519ad55b6d8464bb9cd2220e2ff03b9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c062d0286b1144c9b186642bbc0be1fe","value":1}},"843ae3732e7f4737beaaac3a634de464":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d6ceb10925944c59ad6414063a8fa50","placeholder":"​","style":"IPY_MODEL_2905d57ba80c4ba6a272aec576169c3c","value":" 4.30k/? [00:00&lt;00:00, 420kB/s]"}},"108b9245822c49f3a637036ab2fea623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06449a215bc64e2ba973b0b3d469fd41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"756aed11677a4dfbbaa17230590d36bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b519ad55b6d8464bb9cd2220e2ff03b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c062d0286b1144c9b186642bbc0be1fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d6ceb10925944c59ad6414063a8fa50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2905d57ba80c4ba6a272aec576169c3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c86d55c0a06542069fab0c91c5a941b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9487a49a73e4c04b9ef09909688ae3e","IPY_MODEL_db9dca8d7c7e4756a957e7b91f117cd2","IPY_MODEL_67e2e9bffe734bbc989373a58925ccc6"],"layout":"IPY_MODEL_e6b03493f21049df94ed6cbe152d1ae7"}},"b9487a49a73e4c04b9ef09909688ae3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daccd31c614a42c387acd2d138436280","placeholder":"​","style":"IPY_MODEL_a3ba285f3f7246ed9e4bf0923facbb1e","value":"vocab.json: "}},"db9dca8d7c7e4756a957e7b91f117cd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1131b28abb0e4bdb8a481ef5d4991c53","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4979abf001f846dc886b331ced50aae2","value":1}},"67e2e9bffe734bbc989373a58925ccc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6113a5f9e2834375a1dc191d4e4db4aa","placeholder":"​","style":"IPY_MODEL_0870c62c0f59470ebfd687e20c6ff213","value":" 801k/? [00:00&lt;00:00, 29.5MB/s]"}},"e6b03493f21049df94ed6cbe152d1ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daccd31c614a42c387acd2d138436280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3ba285f3f7246ed9e4bf0923facbb1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1131b28abb0e4bdb8a481ef5d4991c53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4979abf001f846dc886b331ced50aae2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6113a5f9e2834375a1dc191d4e4db4aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0870c62c0f59470ebfd687e20c6ff213":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9caf756920684148a399102e21c51b36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25c0a5f93ffa4acebdf0a8db8ed96e08","IPY_MODEL_0bf2ed122e0a427e9ead0840ca89d5fe","IPY_MODEL_0c55a0a54a23460499f73fdacccf1ca2"],"layout":"IPY_MODEL_90cf06707e994e13b064c45efc62e1bf"}},"25c0a5f93ffa4acebdf0a8db8ed96e08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2cc756d632f427ba33eb535536267a3","placeholder":"​","style":"IPY_MODEL_75b260b035544375ba6fd7e42e51675a","value":"merges.txt: "}},"0bf2ed122e0a427e9ead0840ca89d5fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2936e77162d944f793aa87897a2fb4d1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d4e47e2a0db4285a781dc1668c8a3f6","value":1}},"0c55a0a54a23460499f73fdacccf1ca2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67c6f9f91f2c4a2d8d09f011e8c1f499","placeholder":"​","style":"IPY_MODEL_d1a189cdab4c4587a7e72d9836cc2fa2","value":" 466k/? [00:00&lt;00:00, 20.9MB/s]"}},"90cf06707e994e13b064c45efc62e1bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2cc756d632f427ba33eb535536267a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75b260b035544375ba6fd7e42e51675a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2936e77162d944f793aa87897a2fb4d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1d4e47e2a0db4285a781dc1668c8a3f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67c6f9f91f2c4a2d8d09f011e8c1f499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1a189cdab4c4587a7e72d9836cc2fa2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d324aede2128462fa5fe24e8dda6b1de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e07c026ac8f4042bf2b55b4ebcb5973","IPY_MODEL_aacb3b902b214184aa2f15bec5e0e60f","IPY_MODEL_23008f1fd1984caa895657c1b9539f7c"],"layout":"IPY_MODEL_e0a2c9e85d91488bbbc9254d92d71012"}},"0e07c026ac8f4042bf2b55b4ebcb5973":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9c760b9f43641128e64358a936522a5","placeholder":"​","style":"IPY_MODEL_fbed1a3d0c814572bb81d156cf8e071d","value":"tokenizer.json: "}},"aacb3b902b214184aa2f15bec5e0e60f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa77b140f2484c9499e4a19404661ff5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_51489f0f94c945c2b97890335fb8ff52","value":1}},"23008f1fd1984caa895657c1b9539f7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2b187b694c443548fc2052a60b8ac97","placeholder":"​","style":"IPY_MODEL_ff25415edff54bd08def970f35906689","value":" 3.52M/? [00:00&lt;00:00, 100MB/s]"}},"e0a2c9e85d91488bbbc9254d92d71012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9c760b9f43641128e64358a936522a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbed1a3d0c814572bb81d156cf8e071d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa77b140f2484c9499e4a19404661ff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"51489f0f94c945c2b97890335fb8ff52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2b187b694c443548fc2052a60b8ac97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff25415edff54bd08def970f35906689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"088a455105f1404cb74776852b6a2b63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5480893a86ce41e59da6d31cd5dcb681","IPY_MODEL_5ad450646dcf43cfa1c7346e5b6dd87f","IPY_MODEL_0c007f24682c4b258dbd883f84e5ad71"],"layout":"IPY_MODEL_4f0e86f74d4948669b402fad78a0ea82"}},"5480893a86ce41e59da6d31cd5dcb681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a82829f0dec549159866fbceaafdc0da","placeholder":"​","style":"IPY_MODEL_8ed9461b5e674dd988f8425d8a0a740a","value":"special_tokens_map.json: 100%"}},"5ad450646dcf43cfa1c7346e5b6dd87f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e8902f755004253a493c15a6196757e","max":965,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d8fb9ae68c14b4bb0054d7af6a9cd59","value":965}},"0c007f24682c4b258dbd883f84e5ad71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de0bee8cbdcb48a7863668c885cd8039","placeholder":"​","style":"IPY_MODEL_e9d993c2266e4980be451e65114bdec3","value":" 965/965 [00:00&lt;00:00, 109kB/s]"}},"4f0e86f74d4948669b402fad78a0ea82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a82829f0dec549159866fbceaafdc0da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ed9461b5e674dd988f8425d8a0a740a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e8902f755004253a493c15a6196757e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8fb9ae68c14b4bb0054d7af6a9cd59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de0bee8cbdcb48a7863668c885cd8039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d993c2266e4980be451e65114bdec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4532e4a54c65442bbd511e24368ebe2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63d4c33bc5a4412cb12a1179e13d1b18","IPY_MODEL_eb77cee645df4344996acdd68ed70576","IPY_MODEL_849b67ab2a4e48289c5f8b4e5affb543"],"layout":"IPY_MODEL_e23c010114114f999ca98c7cdc00305e"}},"63d4c33bc5a4412cb12a1179e13d1b18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15f534c2bd75498c9f6f532e9b0af9fb","placeholder":"​","style":"IPY_MODEL_37cfff542aa34b75939d42e04bce9344","value":"modeling_ouro.py: "}},"eb77cee645df4344996acdd68ed70576":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea90def59d9d44989a3b304a267f79e2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18d2696e094849fd8876e9f99c9d0aec","value":1}},"849b67ab2a4e48289c5f8b4e5affb543":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_255a66cc97d14a77b2f3a7369e935d78","placeholder":"​","style":"IPY_MODEL_d4ad723e7b87403ca6cf4241ed756d5d","value":" 33.4k/? [00:00&lt;00:00, 3.49MB/s]"}},"e23c010114114f999ca98c7cdc00305e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15f534c2bd75498c9f6f532e9b0af9fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37cfff542aa34b75939d42e04bce9344":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea90def59d9d44989a3b304a267f79e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"18d2696e094849fd8876e9f99c9d0aec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"255a66cc97d14a77b2f3a7369e935d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ad723e7b87403ca6cf4241ed756d5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a68a48dd8a54751a0367d1399ae3122":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34c8d2d527e145cca504c6a405d05873","IPY_MODEL_d6d8988e210c4940ae7ae4c10c36d390","IPY_MODEL_8b499d9c0cfa498ca442436d36b293f9"],"layout":"IPY_MODEL_6ea55815aace410c8c05837f5bfbe00a"}},"34c8d2d527e145cca504c6a405d05873":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9214eb4a78942ca8916d79bdf416200","placeholder":"​","style":"IPY_MODEL_4777a639bcc84589bbce5cf1b8fbbdae","value":"model.safetensors: 100%"}},"d6d8988e210c4940ae7ae4c10c36d390":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb4b8ce248c14858827bf89f6fa2bcb7","max":2869336434,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d87357c0a3d64f2aa15f1a797281cdbc","value":2869336434}},"8b499d9c0cfa498ca442436d36b293f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba4d8ebe68b24c76902b94f16e721a3d","placeholder":"​","style":"IPY_MODEL_39972f5d67e74cfdbbf430af7cd8bf40","value":" 2.87G/2.87G [00:28&lt;00:00, 136MB/s]"}},"6ea55815aace410c8c05837f5bfbe00a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9214eb4a78942ca8916d79bdf416200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4777a639bcc84589bbce5cf1b8fbbdae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb4b8ce248c14858827bf89f6fa2bcb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d87357c0a3d64f2aa15f1a797281cdbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba4d8ebe68b24c76902b94f16e721a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39972f5d67e74cfdbbf430af7cd8bf40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0749a8ba183f4b298aca0b49e78a5888":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_909700ae213948c2b03fd548a45b151c","IPY_MODEL_18a9a9bd46374708a5a83e803a33808f","IPY_MODEL_8ff9899358b44f0e984426a4ec3abaa6"],"layout":"IPY_MODEL_8fb46b75282f40f98387a444c4d46121"}},"909700ae213948c2b03fd548a45b151c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b4e6cda2d64ded8a905a1c323530e9","placeholder":"​","style":"IPY_MODEL_a3c5ac7180f1426ba25ae390a8269612","value":"Calculating PPL (UT=5): 100%"}},"18a9a9bd46374708a5a83e803a33808f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6c18721170a4ddb9311f7605fe18fd6","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8658167319b84ebe893f06bb36293fd4","value":8}},"8ff9899358b44f0e984426a4ec3abaa6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0dd378d630d4917b1fa0b77f27b64ed","placeholder":"​","style":"IPY_MODEL_c5ea7d9e7c1f44b6a289ba6fe8725be1","value":" 8/8 [01:21&lt;00:00,  7.61s/it]"}},"8fb46b75282f40f98387a444c4d46121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54b4e6cda2d64ded8a905a1c323530e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c5ac7180f1426ba25ae390a8269612":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6c18721170a4ddb9311f7605fe18fd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8658167319b84ebe893f06bb36293fd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0dd378d630d4917b1fa0b77f27b64ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5ea7d9e7c1f44b6a289ba6fe8725be1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"369a9294e96c45ba96cc8faefb073da2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5395080b7f5401e8f691148cf3b2ead","IPY_MODEL_d745f85a05dc421daf75eb51b24f63c1","IPY_MODEL_c5e93489f1c841cfbe7512dc304c7d1b"],"layout":"IPY_MODEL_88de3c80a95945fdbf5727a42fb17cd2"}},"a5395080b7f5401e8f691148cf3b2ead":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4ef7646447f4a3a879962267095514d","placeholder":"​","style":"IPY_MODEL_84d56646e8434984a6623aded109b0db","value":"   n_ary:  17%"}},"d745f85a05dc421daf75eb51b24f63c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9de508dbd01f49879b9ddf1622cac206","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8071376a62534e10a4c030134173a737","value":86}},"c5e93489f1c841cfbe7512dc304c7d1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d5b7c9e477646ff81a4937fb1b9096c","placeholder":"​","style":"IPY_MODEL_aafc93c21617450f91261a206bf4d33f","value":" 86/500 [11:59&lt;55:20,  8.02s/it]"}},"88de3c80a95945fdbf5727a42fb17cd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4ef7646447f4a3a879962267095514d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84d56646e8434984a6623aded109b0db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9de508dbd01f49879b9ddf1622cac206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8071376a62534e10a4c030134173a737":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d5b7c9e477646ff81a4937fb1b9096c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aafc93c21617450f91261a206bf4d33f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dzung271828/ouro-trace?scriptVersionId=288567809\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/dzung271828/ouro-trace?scriptVersionId=288557226\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"id":"PFjYdqo8Q-E1"}},{"cell_type":"markdown","source":"# Setup libraries","metadata":{"id":"S0M-JZCdnzA6"}},{"cell_type":"code","source":"!uv pip install --upgrade pip\n!uv pip uninstall transformers tokenizers accelerate -q\n\n!uv pip install \"transformers==4.56.0\" \"protobuf==5.29.3\" -q\n!uv pip install torch datasets -q\n!uv pip install pandas matplotlib seaborn tqdm wandb pyyaml\n!uv pip install bitsandbytes accelerate optimum lm_eval\n# !uv pip install -r requirements.txt\n!uv pip install --force-reinstall --no-cache-dir \"numpy<2.0\"","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:11.927771Z","iopub.execute_input":"2025-12-26T16:25:11.928153Z","iopub.status.idle":"2025-12-26T16:25:14.653105Z","shell.execute_reply.started":"2025-12-26T16:25:11.928117Z","shell.execute_reply":"2025-12-26T16:25:14.652428Z"},"id":"tjC_YOBlnzA-","outputId":"91102fc8-c640-46a0-eeb3-802f8e7f8043","trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 41ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.17ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m98 packages\u001b[0m \u001b[2min 195ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m                                  \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 146ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 369ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 30ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Suppress warnings","metadata":{"id":"7t_XpUsOs_my"}},{"cell_type":"code","source":"# Suppress warnings for clean output\nimport warnings\nimport os\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nos.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\nprint(\"✅ Packages installed successfully!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:14.654634Z","iopub.execute_input":"2025-12-26T16:25:14.654842Z","iopub.status.idle":"2025-12-26T16:25:14.660157Z","shell.execute_reply.started":"2025-12-26T16:25:14.654821Z","shell.execute_reply":"2025-12-26T16:25:14.659534Z"},"id":"t3KSZamlnzA_","outputId":"668fdd34-362d-4421-c82a-5f3abb81bc6d","trusted":true},"outputs":[{"name":"stdout","text":"✅ Packages installed successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Install Libraries","metadata":{"id":"abWE_VV3s_my"}},{"cell_type":"code","source":"\"Built-in libraries\"\nimport re\nimport sys\nimport gc\nimport time\nimport json\nimport hashlib\nimport glob\nimport zipfile\nfrom io import StringIO\nfrom datetime import datetime\nfrom typing import Dict, List, Optional, Tuple, Any\nimport yaml\nimport logging\nimport random\n\n\"Deep learning and NLP libraries\"\nimport torch\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    GenerationConfig,\n    logging as hf_logging,\n)\n\n\"Data processing libraries\"\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport wandb\nfrom tqdm.auto import tqdm\nfrom IPython import get_ipython\n\n# Configure logging\nlogging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\nhf_logging.set_verbosity_error()\n\n\nprint(f\"Python Version: {sys.version}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA Version: {torch.version.cuda}\")\n!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:14.661244Z","iopub.execute_input":"2025-12-26T16:25:14.66149Z","iopub.status.idle":"2025-12-26T16:25:21.394944Z","shell.execute_reply.started":"2025-12-26T16:25:14.661468Z","shell.execute_reply":"2025-12-26T16:25:21.39403Z"},"id":"vW3-Anw9nzBA","outputId":"3e1a4bb9-33c9-41d3-e894-cb9c244c30e0","trusted":true},"outputs":[{"name":"stdout","text":"Python Version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch Version: 2.6.0+cu124\nCUDA Available: True\nCUDA Version: 12.4\nFri Dec 26 16:25:21 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   73C    P8             16W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   73C    P8             13W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\n\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"✅ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"✅ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"⚠️ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"⚠️ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"📂 Data Path: {base_data_path}\")\n    print(f\"📦 Output Path: {base_output_path}\")\n\n    return base_data_path, base_output_path, environment_name\n\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:21.396212Z","iopub.execute_input":"2025-12-26T16:25:21.396523Z","iopub.status.idle":"2025-12-26T16:25:21.404506Z","shell.execute_reply.started":"2025-12-26T16:25:21.396494Z","shell.execute_reply":"2025-12-26T16:25:21.403914Z"},"id":"NxqV6hTMs_mz","outputId":"53dd58ec-5146-4f43-dea0-c5efe32871b7","trusted":true},"outputs":[{"name":"stdout","text":"✅ Environment: Kaggle\n📂 Data Path: /kaggle/input/\n📦 Output Path: /kaggle/working/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Setup WANDB","metadata":{"id":"m0HV8HMrs_mz"}},{"cell_type":"code","source":"import os\nimport wandb\n\nif \"colab\" in ENV_NAME:\n    from google.colab import userdata\n\n    try:\n        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n        wandb_key = userdata.get(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n\n# 2. Check if running in Kaggle\nelif \"kaggle\" in ENV_NAME:\n    try:\n        from kaggle_secrets import UserSecretsClient\n\n        user_secrets = UserSecretsClient()\n        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:21.406125Z","iopub.execute_input":"2025-12-26T16:25:21.406385Z","iopub.status.idle":"2025-12-26T16:25:28.310147Z","shell.execute_reply.started":"2025-12-26T16:25:21.406367Z","shell.execute_reply":"2025-12-26T16:25:28.309529Z"},"id":"UaOteqd3nzBA","outputId":"769ef322-0e1f-4f27-8355-2ac40985f3e1","trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Config input/output path and clone latest repo","metadata":{"id":"wDA1HyzsnzA_"}},{"cell_type":"code","source":"# Clone the latest github repo version\n%cd {OUTPUT_PATH}\ntorch.cuda.empty_cache()\n!rm -rf OuroTrace","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:28.310812Z","iopub.execute_input":"2025-12-26T16:25:28.311326Z","iopub.status.idle":"2025-12-26T16:25:28.461094Z","shell.execute_reply.started":"2025-12-26T16:25:28.311306Z","shell.execute_reply":"2025-12-26T16:25:28.460018Z"},"id":"qyaPdq3RnzA8","outputId":"62fc8dcf-48fa-4c62-9a52-ca8df799dfd4","trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!git clone --branch claude https://github.com/dzungphieuluuky/OuroTrace.git\n%cd OuroTrace","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-26T16:25:28.462383Z","iopub.execute_input":"2025-12-26T16:25:28.462921Z","iopub.status.idle":"2025-12-26T16:25:29.606585Z","shell.execute_reply.started":"2025-12-26T16:25:28.462895Z","shell.execute_reply":"2025-12-26T16:25:29.605852Z"},"id":"3S4kc_Vjs_m0","outputId":"d519c377-22cc-40fd-962e-9a772286fba1","trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'OuroTrace'...\nremote: Enumerating objects: 2369, done.\u001b[K\nremote: Counting objects: 100% (251/251), done.\u001b[K\nremote: Compressing objects: 100% (201/201), done.\u001b[K\nremote: Total 2369 (delta 147), reused 143 (delta 50), pack-reused 2118 (from 2)\u001b[K\nReceiving objects: 100% (2369/2369), 7.09 MiB | 20.68 MiB/s, done.\nResolving deltas: 100% (1504/1504), done.\n/kaggle/working/OuroTrace\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Run Benchmark","metadata":{"id":"GmJUVG32s_m0"}},{"cell_type":"code","source":"from src.config_loader import load_config_from_json, post_process_config\nfrom src.new_refactored_runner import run_experiment\nfrom src.evaluation_analysis import analyze_experiment_results\n\ndef set_all_seeds(seed):\n    random.seed(seed)                          # Python random\n    os.environ['PYTHONHASHSEED'] = str(seed)  # Python hash seed\n    np.random.seed(seed)                      # NumPy\n    torch.manual_seed(seed)                   # PyTorch CPU & GPU\n\n    # Additional GPU-specific settings\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)      # For multi-GPU\n\nset_all_seeds(1415)\n# 1. Load Configuration from JSON\nconfig = load_config_from_json(\"configs/ouro_1.4b_thinking.json\")\n\n# 2. Post-process (Convert 'torch.float16' string to object, generate timestamps)\nconfig = post_process_config(config)\n\nconfig[\"INFERENCE_STEPS\"] = [4]\n# config[\"EVAL_SETTINGS\"][\"calculate_perplexity\"] = False\n# config[\"DATA\"][\"n_ary\"][\"num_samples_per_level\"] = 0\n# config[\"DATA\"][\"p_hop\"][\"num_samples_per_level\"] = 0\n# config[\"DATA\"][\"igsm\"][\"num_samples\"] = 0\n# config[\"DATA\"][\"reasoning_primitives\"][\"num_samples\"] = 0\n# config[\"ENABLE_HEAVY_BENCHMARKS\"] = True\n# 4. Execute\nprint(\"🚀 Starting Experiment...\")\ntry:\n    del model, tokenizer\n    torch.cuda.empty_cache()\n    gc.collect()\nexcept:\n    pass\n\ntry:\n    simple_reasoning_results, ppl_results, primitives_results, benchmark_results = run_experiment(config)\nexcept Exception as e:\n    print(f\"An unexpected error occurred: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cbfa7e05d2bc4756b80e6857a1b9ff93","b0aa1a6cab3d4ff080cbd337ed760694","087021df58824f188d1679892365584b","9d2e1ec21b334579a737498e15660187","86a6c9926c094201a3894b53f773f805","fb84f1120a6b43ce8f47bd9464acdc6c","af6d89cb3e7c454e867837b23e263a6d","9840a19e36994155be216ca06ed6102a","92bad06f017342caae546d5ec3d0580d","52ee5800bdc647fa8be85aaa7fee5576","14aada98d09641e78a96c642a57739f8","f81db505830a46cd8476f112c294fdf8","fd1e0b595efd4004b3d7b99a6d1d2c86","6a26ebaa5485490091bc925d3d84bea2","f6777f8e272c49c9bbad82f5df9dd6b0","951e227348484175bf0ef5d05ff16f23","760e7d679d04432ab13f673a3dff7cc0","e27de45d7def43dab1d9655f43c7de2a","86413511a63744f79321d4f108d5faf9","b1531c3ed5a941a588a43fca48bd9084","82312216be9d4b28ae82d67428e717d6","1bacddad80a54403a38ba59837979090","6586524ac76f4a668f26192a782de9d3","c38ec7f28c7047a88238b292a81fbaf2","f07062d77612431bb8b603b7b3a94ed4","843ae3732e7f4737beaaac3a634de464","108b9245822c49f3a637036ab2fea623","06449a215bc64e2ba973b0b3d469fd41","756aed11677a4dfbbaa17230590d36bc","b519ad55b6d8464bb9cd2220e2ff03b9","c062d0286b1144c9b186642bbc0be1fe","0d6ceb10925944c59ad6414063a8fa50","2905d57ba80c4ba6a272aec576169c3c","c86d55c0a06542069fab0c91c5a941b5","b9487a49a73e4c04b9ef09909688ae3e","db9dca8d7c7e4756a957e7b91f117cd2","67e2e9bffe734bbc989373a58925ccc6","e6b03493f21049df94ed6cbe152d1ae7","daccd31c614a42c387acd2d138436280","a3ba285f3f7246ed9e4bf0923facbb1e","1131b28abb0e4bdb8a481ef5d4991c53","4979abf001f846dc886b331ced50aae2","6113a5f9e2834375a1dc191d4e4db4aa","0870c62c0f59470ebfd687e20c6ff213","9caf756920684148a399102e21c51b36","25c0a5f93ffa4acebdf0a8db8ed96e08","0bf2ed122e0a427e9ead0840ca89d5fe","0c55a0a54a23460499f73fdacccf1ca2","90cf06707e994e13b064c45efc62e1bf","a2cc756d632f427ba33eb535536267a3","75b260b035544375ba6fd7e42e51675a","2936e77162d944f793aa87897a2fb4d1","1d4e47e2a0db4285a781dc1668c8a3f6","67c6f9f91f2c4a2d8d09f011e8c1f499","d1a189cdab4c4587a7e72d9836cc2fa2","d324aede2128462fa5fe24e8dda6b1de","0e07c026ac8f4042bf2b55b4ebcb5973","aacb3b902b214184aa2f15bec5e0e60f","23008f1fd1984caa895657c1b9539f7c","e0a2c9e85d91488bbbc9254d92d71012","c9c760b9f43641128e64358a936522a5","fbed1a3d0c814572bb81d156cf8e071d","aa77b140f2484c9499e4a19404661ff5","51489f0f94c945c2b97890335fb8ff52","a2b187b694c443548fc2052a60b8ac97","ff25415edff54bd08def970f35906689","088a455105f1404cb74776852b6a2b63","5480893a86ce41e59da6d31cd5dcb681","5ad450646dcf43cfa1c7346e5b6dd87f","0c007f24682c4b258dbd883f84e5ad71","4f0e86f74d4948669b402fad78a0ea82","a82829f0dec549159866fbceaafdc0da","8ed9461b5e674dd988f8425d8a0a740a","3e8902f755004253a493c15a6196757e","9d8fb9ae68c14b4bb0054d7af6a9cd59","de0bee8cbdcb48a7863668c885cd8039","e9d993c2266e4980be451e65114bdec3","4532e4a54c65442bbd511e24368ebe2f","63d4c33bc5a4412cb12a1179e13d1b18","eb77cee645df4344996acdd68ed70576","849b67ab2a4e48289c5f8b4e5affb543","e23c010114114f999ca98c7cdc00305e","15f534c2bd75498c9f6f532e9b0af9fb","37cfff542aa34b75939d42e04bce9344","ea90def59d9d44989a3b304a267f79e2","18d2696e094849fd8876e9f99c9d0aec","255a66cc97d14a77b2f3a7369e935d78","d4ad723e7b87403ca6cf4241ed756d5d","8a68a48dd8a54751a0367d1399ae3122","34c8d2d527e145cca504c6a405d05873","d6d8988e210c4940ae7ae4c10c36d390","8b499d9c0cfa498ca442436d36b293f9","6ea55815aace410c8c05837f5bfbe00a","b9214eb4a78942ca8916d79bdf416200","4777a639bcc84589bbce5cf1b8fbbdae","fb4b8ce248c14858827bf89f6fa2bcb7","d87357c0a3d64f2aa15f1a797281cdbc","ba4d8ebe68b24c76902b94f16e721a3d","39972f5d67e74cfdbbf430af7cd8bf40","0749a8ba183f4b298aca0b49e78a5888","909700ae213948c2b03fd548a45b151c","18a9a9bd46374708a5a83e803a33808f","8ff9899358b44f0e984426a4ec3abaa6","8fb46b75282f40f98387a444c4d46121","54b4e6cda2d64ded8a905a1c323530e9","a3c5ac7180f1426ba25ae390a8269612","d6c18721170a4ddb9311f7605fe18fd6","8658167319b84ebe893f06bb36293fd4","f0dd378d630d4917b1fa0b77f27b64ed","c5ea7d9e7c1f44b6a289ba6fe8725be1","369a9294e96c45ba96cc8faefb073da2","a5395080b7f5401e8f691148cf3b2ead","d745f85a05dc421daf75eb51b24f63c1","c5e93489f1c841cfbe7512dc304c7d1b","88de3c80a95945fdbf5727a42fb17cd2","a4ef7646447f4a3a879962267095514d","84d56646e8434984a6623aded109b0db","9de508dbd01f49879b9ddf1622cac206","8071376a62534e10a4c030134173a737","6d5b7c9e477646ff81a4937fb1b9096c","aafc93c21617450f91261a206bf4d33f"]},"execution":{"iopub.status.busy":"2025-12-26T16:25:29.60767Z","iopub.execute_input":"2025-12-26T16:25:29.60791Z","iopub.status.idle":"2025-12-26T17:45:35.555996Z","shell.execute_reply.started":"2025-12-26T16:25:29.607886Z","shell.execute_reply":"2025-12-26T17:45:35.555381Z"},"id":"CKc8czt-nzBB","outputId":"7510defa-4ce6-4a6b-ded5-d771e529f4d8","trusted":true},"outputs":[{"name":"stdout","text":"🚀 Starting Experiment...\nInitializing W&B (timeout: 30s)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251226_162529-w0lf8jb7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/w0lf8jb7' target=\"_blank\">rare-sunset-159</a></strong> to <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/w0lf8jb7' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/w0lf8jb7</a>"},"metadata":{}},{"name":"stdout","text":"W&B initialized successfully\n\n======================================================================\nEXPERIMENT CONFIGURATION\n======================================================================\nModel Path: ByteDance/Ouro-1.4B-Thinking\nUT Steps to Test: [4]\nData Type: torch.bfloat16\n4-bit Quantization: False\nTorch Compile: False\nMax Batch Size: 8\nMax New Tokens: 16\nBatching: False\nCalculate Perplexity: True\nEarly Exit: 1.0\n======================================================================\n\nQuality monitor initialized:\n    Garbage threshold: 30%\n    Example similarity threshold: 85%\n    Min samples before check: 10\n\n======================================================================\nLOADING TEST DATASETS\n======================================================================\nGenerating new test datasets...\nGenerated test datasets successfully\n\nDataset Summary:\n   n_ary       :  500 samples\n   p_hop       :  300 samples\n   igsm        :  100 samples\n======================================================================\n\nPreparing perplexity evaluation data...\nPrepared 50 samples for PPL\n\n✅ Configuration saved to ../results_20251226_162535_UT_4/config.json\n✅ Task templates saved to ../results_20251226_162535_UT_4/task_templates.json\n\n======================================================================\nEXPERIMENT 1/1: UT Steps = 4\n======================================================================\n\n\n============================================================\nLOADING MODEL CONFIGURATION\n============================================================\nModel Path: ByteDance/Ouro-1.4B-Thinking\nRequested UT Steps: 4\nData Type: torch.bfloat16\n4-bit Quantization: False\nTorch Compile: False\n\nBase config loaded\n   Original UT steps: 4\n   Original early exit: 1.0\n\nModified config:\n   New UT steps: 4\n   Early exit threshold: 1.0 (from default)\n\nTokenizer loaded\n   Vocab size: 49152\n   PAD token: <|im_end|>\n   EOS token: <|im_end|>\n\nLoading model weights...\n","output_type":"stream"},{"name":"stderr","text":"2025-12-26 16:25:37.255227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766766337.271817     336 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766766337.276692     336 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\n────────────────────────────────────────────────────────────\nAPPLYING SAFE OPTIMIZATIONS\n────────────────────────────────────────────────────────────\n   Flash Attention / SDPA enabled\n   TF32 enabled for matmul\n   cuDNN auto-tuning enabled\n   Memory pool optimized\n   Running 3 warmup passes...\n   Warmup complete\n────────────────────────────────────────────────────────────\n\n============================================================\nMODEL LOADED SUCCESSFULLY\n============================================================\nDevice: cuda:0\nModel dtype: torch.bfloat16\nVERIFIED UT steps: 4\nVERIFIED early exit: 1.0\n============================================================\n\nBuilding task templates...\nTask templates with pre-tokenized components computed.\n    System prompt N_ary tokens: 813 tokens\n    System prompt P_hop tokens: 682 tokens\n    System prompt IGSM tokens: 1136 tokens\n    User prefix tokens: 14 tokens\n    User suffix tokens: 6 tokens\n    Force start tokens: 4 tokens\nTask templates built successfully\n\n✅ Configuration saved to ../results_20251226_162535_UT_4/config.json\n✅ Task templates saved to ../results_20251226_162535_UT_4/task_templates.json\nExperiment configuration saved with task templates\n\n======================================================================\nPERPLEXITY EVALUATION\n======================================================================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating PPL (UT=4):   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be09cd246184316a1220133cabe964d"}},"metadata":{}},{"name":"stdout","text":"\nPerplexity Results:\n   Perplexity: 0.2361\n   Avg Loss:   1.2663\n\n======================================================================\nACCURACY EVALUATION\n======================================================================\n\n\n──────────────────────────────────────────────────────────────────────\nTask: N_ARY\n──────────────────────────────────────────────────────────────────────\nTotal Samples: 500\nBatch Size: 1\nStrategy: Sequential Processing\n\nProcessing 500 items sequentially...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   n_ary:   0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"    test_input        full_response  generated_tokens\n0  871 + 556 =  [FINAL]  1427 [END]                 8\n    test_input        full_response  generated_tokens\n0  888 + 759 =  [FINAL]  1647 [END]                 8\n    test_input        full_response  generated_tokens\n0  670 + 418 =  [FINAL]  1088 [END]                 8\n    test_input        full_response  generated_tokens\n0  661 + 544 =  [FINAL]  1205 [END]                 8\n    test_input        full_response  generated_tokens\n0  328 + 902 =  [FINAL]  1230 [END]                 8\n    test_input       full_response  generated_tokens\n0  696 + 243 =  [FINAL]  939 [END]                 7\n    test_input        full_response  generated_tokens\n0  810 + 357 =  [FINAL]  1167 [END]                 8\n    test_input       full_response  generated_tokens\n0  191 + 780 =  [FINAL]  971 [END]                 7\n    test_input        full_response  generated_tokens\n0  933 + 652 =  [FINAL]  1585 [END]                 8\n    test_input        full_response  generated_tokens\n0  995 + 551 =  [FINAL]  1546 [END]                 8\n    test_input        full_response  generated_tokens\n0  227 + 885 =  [FINAL]  1112 [END]                 8\n    test_input        full_response  generated_tokens\n0  395 + 913 =  [FINAL]  1308 [END]                 8\n    test_input        full_response  generated_tokens\n0  661 + 800 =  [FINAL]  1461 [END]                 8\n    test_input       full_response  generated_tokens\n0  262 + 254 =  [FINAL]  516 [END]                 7\n    test_input        full_response  generated_tokens\n0  244 + 977 =  [FINAL]  1221 [END]                 8\n    test_input       full_response  generated_tokens\n0  433 + 105 =  [FINAL]  538 [END]                 7\n    test_input        full_response  generated_tokens\n0  594 + 781 =  [FINAL]  1375 [END]                 8\n    test_input        full_response  generated_tokens\n0  587 + 573 =  [FINAL]  1160 [END]                 8\n    test_input       full_response  generated_tokens\n0  191 + 618 =  [FINAL]  809 [END]                 7\n    test_input        full_response  generated_tokens\n0  682 + 984 =  [FINAL]  1666 [END]                 8\n    test_input        full_response  generated_tokens\n0  795 + 227 =  [FINAL]  1022 [END]                 8\n    test_input        full_response  generated_tokens\n0  919 + 109 =  [FINAL]  1028 [END]                 8\n    test_input       full_response  generated_tokens\n0  471 + 164 =  [FINAL]  635 [END]                 7\n    test_input        full_response  generated_tokens\n0  851 + 650 =  [FINAL]  1401 [END]                 8\n    test_input        full_response  generated_tokens\n0  882 + 157 =  [FINAL]  1039 [END]                 8\n    test_input       full_response  generated_tokens\n0  341 + 322 =  [FINAL]  663 [END]                 7\n    test_input        full_response  generated_tokens\n0  814 + 812 =  [FINAL]  1626 [END]                 8\n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n    test_input       full_response  generated_tokens\n0  524 + 231 =  [FINAL]  755 [END]                 7\n    test_input        full_response  generated_tokens\n0  818 + 463 =  [FINAL]  1281 [END]                 8\n    test_input        full_response  generated_tokens\n0  725 + 384 =  [FINAL]  1109 [END]                 8\n    test_input       full_response  generated_tokens\n0  165 + 142 =  [FINAL]  307 [END]                 7\n    test_input       full_response  generated_tokens\n0  078 + 742 =  [FINAL]  820 [END]                 7\n    test_input        full_response  generated_tokens\n0  020 + 992 =  [FINAL]  1012 [END]                 8\n    test_input       full_response  generated_tokens\n0  176 + 446 =  [FINAL]  622 [END]                 7\n    test_input       full_response  generated_tokens\n0  104 + 856 =  [FINAL]  960 [END]                 7\n    test_input       full_response  generated_tokens\n0  401 + 405 =  [FINAL]  806 [END]                 7\n    test_input       full_response  generated_tokens\n0  507 + 084 =  [FINAL]  591 [END]                 7\n    test_input       full_response  generated_tokens\n0  475 + 089 =  [FINAL]  564 [END]                 7\n    test_input       full_response  generated_tokens\n0  066 + 868 =  [FINAL]  934 [END]                 7\n    test_input       full_response  generated_tokens\n0  322 + 290 =  [FINAL]  612 [END]                 7\n    test_input        full_response  generated_tokens\n0  574 + 902 =  [FINAL]  1476 [END]                 8\n    test_input       full_response  generated_tokens\n0  098 + 767 =  [FINAL]  865 [END]                 7\n    test_input       full_response  generated_tokens\n0  379 + 372 =  [FINAL]  751 [END]                 7\n    test_input       full_response  generated_tokens\n0  105 + 123 =  [FINAL]  228 [END]                 7\n    test_input       full_response  generated_tokens\n0  202 + 195 =  [FINAL]  397 [END]                 7\n    test_input        full_response  generated_tokens\n0  695 + 944 =  [FINAL]  1639 [END]                 8\n    test_input        full_response  generated_tokens\n0  560 + 719 =  [FINAL]  1279 [END]                 8\n    test_input        full_response  generated_tokens\n0  516 + 546 =  [FINAL]  1062 [END]                 8\n    test_input        full_response  generated_tokens\n0  802 + 300 =  [FINAL]  1102 [END]                 8\n    test_input       full_response  generated_tokens\n0  682 + 019 =  [FINAL]  691 [END]                 7\n    test_input        full_response  generated_tokens\n0  543 + 874 =  [FINAL]  1417 [END]                 8\n    test_input        full_response  generated_tokens\n0  761 + 884 =  [FINAL]  1645 [END]                 8\n    test_input       full_response  generated_tokens\n0  685 + 169 =  [FINAL]  854 [END]                 7\n    test_input       full_response  generated_tokens\n0  536 + 175 =  [FINAL]  711 [END]                 7\n    test_input        full_response  generated_tokens\n0  788 + 307 =  [FINAL]  1095 [END]                 8\n    test_input       full_response  generated_tokens\n0  190 + 700 =  [FINAL]  890 [END]                 7\n    test_input        full_response  generated_tokens\n0  634 + 466 =  [FINAL]  1090 [END]                 8\n    test_input       full_response  generated_tokens\n0  615 + 126 =  [FINAL]  741 [END]                 7\n    test_input        full_response  generated_tokens\n0  771 + 891 =  [FINAL]  1662 [END]                 8\n    test_input       full_response  generated_tokens\n0  034 + 496 =  [FINAL]  530 [END]                 7\n    test_input        full_response  generated_tokens\n0  125 + 876 =  [FINAL]  1001 [END]                 8\n    test_input       full_response  generated_tokens\n0  174 + 419 =  [FINAL]  593 [END]                 7\n    test_input        full_response  generated_tokens\n0  593 + 573 =  [FINAL]  1166 [END]                 8\n    test_input       full_response  generated_tokens\n0  357 + 257 =  [FINAL]  614 [END]                 7\n    test_input       full_response  generated_tokens\n0  002 + 470 =  [FINAL]  472 [END]                 7\n    test_input        full_response  generated_tokens\n0  561 + 864 =  [FINAL]  1425 [END]                 8\n    test_input       full_response  generated_tokens\n0  341 + 016 =  [FINAL]  357 [END]                 7\n    test_input        full_response  generated_tokens\n0  325 + 686 =  [FINAL]  1011 [END]                 8\n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n    test_input        full_response  generated_tokens\n0  868 + 549 =  [FINAL]  1417 [END]                 8\n    test_input        full_response  generated_tokens\n0  627 + 814 =  [FINAL]  1441 [END]                 8\n    test_input        full_response  generated_tokens\n0  455 + 760 =  [FINAL]  1215 [END]                 8\n    test_input       full_response  generated_tokens\n0  467 + 012 =  [FINAL]  479 [END]                 7\n    test_input       full_response  generated_tokens\n0  084 + 579 =  [FINAL]  663 [END]                 7\n    test_input        full_response  generated_tokens\n0  499 + 713 =  [FINAL]  1212 [END]                 8\n    test_input       full_response  generated_tokens\n0  279 + 446 =  [FINAL]  725 [END]                 7\n    test_input       full_response  generated_tokens\n0  284 + 232 =  [FINAL]  516 [END]                 7\n    test_input       full_response  generated_tokens\n0  680 + 246 =  [FINAL]  926 [END]                 7\n    test_input        full_response  generated_tokens\n0  878 + 401 =  [FINAL]  1279 [END]                 8\n    test_input       full_response  generated_tokens\n0  209 + 362 =  [FINAL]  571 [END]                 7\n    test_input        full_response  generated_tokens\n0  995 + 494 =  [FINAL]  1489 [END]                 8\n    test_input       full_response  generated_tokens\n0  137 + 278 =  [FINAL]  415 [END]                 7\n    test_input       full_response  generated_tokens\n0  256 + 045 =  [FINAL]  301 [END]                 7\n    test_input       full_response  generated_tokens\n0  255 + 585 =  [FINAL]  840 [END]                 7\n    test_input       full_response  generated_tokens\n0  059 + 353 =  [FINAL]  412 [END]                 7\n    test_input       full_response  generated_tokens\n0  954 + 007 =  [FINAL]  961 [END]                 7\n    test_input       full_response  generated_tokens\n0  243 + 548 =  [FINAL]  791 [END]                 7\n    test_input       full_response  generated_tokens\n0  054 + 747 =  [FINAL]  801 [END]                 7\n    test_input        full_response  generated_tokens\n0  194 + 825 =  [FINAL]  1019 [END]                 8\n    test_input        full_response  generated_tokens\n0  934 + 402 =  [FINAL]  1336 [END]                 8\n    test_input        full_response  generated_tokens\n0  772 + 557 =  [FINAL]  1329 [END]                 8\n    test_input       full_response  generated_tokens\n0  344 + 264 =  [FINAL]  608 [END]                 7\n    test_input       full_response  generated_tokens\n0  013 + 524 =  [FINAL]  537 [END]                 7\n    test_input        full_response  generated_tokens\n0  770 + 451 =  [FINAL]  1221 [END]                 8\n    test_input       full_response  generated_tokens\n0  303 + 209 =  [FINAL]  512 [END]                 7\n    test_input        full_response  generated_tokens\n0  321 + 804 =  [FINAL]  1125 [END]                 8\n    test_input       full_response  generated_tokens\n0  589 + 313 =  [FINAL]  902 [END]                 7\n    test_input       full_response  generated_tokens\n0  170 + 522 =  [FINAL]  692 [END]                 7\n    test_input        full_response  generated_tokens\n0  710 + 816 =  [FINAL]  1526 [END]                 8\n    test_input        full_response  generated_tokens\n0  636 + 682 =  [FINAL]  1318 [END]                 8\n    test_input        full_response  generated_tokens\n0  397 + 660 =  [FINAL]  1057 [END]                 8\n                test_input        full_response  generated_tokens\n0  950 + 755 + 994 + 329 =  [FINAL]  2928 [END]                 8\n                test_input        full_response  generated_tokens\n0  736 + 412 + 088 + 387 =  [FINAL]  1623 [END]                 8\n                test_input        full_response  generated_tokens\n0  753 + 339 + 879 + 891 =  [FINAL]  3462 [END]                 8\n                test_input        full_response  generated_tokens\n0  275 + 325 + 508 + 714 =  [FINAL]  1812 [END]                 8\n                test_input        full_response  generated_tokens\n0  364 + 364 + 250 + 530 =  [FINAL]  1408 [END]                 8\n                test_input        full_response  generated_tokens\n0  935 + 994 + 509 + 813 =  [FINAL]  3251 [END]                 8\n                test_input        full_response  generated_tokens\n0  255 + 498 + 438 + 405 =  [FINAL]  1696 [END]                 8\n                test_input        full_response  generated_tokens\n0  468 + 035 + 227 + 239 =  [FINAL]  1069 [END]                 8\n                test_input        full_response  generated_tokens\n0  665 + 304 + 526 + 303 =  [FINAL]  1800 [END]                 8\n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                test_input        full_response  generated_tokens\n0  495 + 900 + 517 + 587 =  [FINAL]  2599 [END]                 8\n                test_input        full_response  generated_tokens\n0  825 + 944 + 297 + 294 =  [FINAL]  2550 [END]                 8\n                test_input        full_response  generated_tokens\n0  765 + 307 + 249 + 787 =  [FINAL]  2108 [END]                 8\n                test_input        full_response  generated_tokens\n0  155 + 277 + 282 + 752 =  [FINAL]  1466 [END]                 8\n                test_input        full_response  generated_tokens\n0  009 + 470 + 325 + 499 =  [FINAL]  1393 [END]                 8\n                test_input        full_response  generated_tokens\n0  855 + 459 + 091 + 180 =  [FINAL]  1585 [END]                 8\n                test_input       full_response  generated_tokens\n0  507 + 089 + 087 + 048 =  [FINAL]  721 [END]                 7\n                test_input        full_response  generated_tokens\n0  976 + 206 + 812 + 298 =  [FINAL]  2282 [END]                 8\n                test_input        full_response  generated_tokens\n0  574 + 983 + 449 + 071 =  [FINAL]  2097 [END]                 8\n                test_input        full_response  generated_tokens\n0  656 + 191 + 321 + 614 =  [FINAL]  1782 [END]                 8\n                test_input        full_response  generated_tokens\n0  912 + 485 + 028 + 850 =  [FINAL]  2275 [END]                 8\n                test_input        full_response  generated_tokens\n0  493 + 584 + 462 + 991 =  [FINAL]  2530 [END]                 8\n                test_input        full_response  generated_tokens\n0  087 + 253 + 336 + 327 =  [FINAL]  1253 [END]                 8\n                test_input        full_response  generated_tokens\n0  471 + 537 + 249 + 938 =  [FINAL]  2295 [END]                 8\n                test_input        full_response  generated_tokens\n0  698 + 537 + 507 + 857 =  [FINAL]  2599 [END]                 8\n                test_input        full_response  generated_tokens\n0  042 + 704 + 934 + 325 =  [FINAL]  2405 [END]                 8\n                test_input        full_response  generated_tokens\n0  765 + 869 + 357 + 801 =  [FINAL]  2892 [END]                 8\n                test_input        full_response  generated_tokens\n0  162 + 786 + 745 + 399 =  [FINAL]  2612 [END]                 8\n                test_input        full_response  generated_tokens\n0  790 + 481 + 146 + 926 =  [FINAL]  2243 [END]                 8\n                test_input        full_response  generated_tokens\n0  547 + 141 + 779 + 534 =  [FINAL]  2001 [END]                 8\n                test_input       full_response  generated_tokens\n0  570 + 037 + 142 + 083 =  [FINAL]  832 [END]                 7\n                test_input        full_response  generated_tokens\n0  943 + 645 + 374 + 332 =  [FINAL]  2294 [END]                 8\n                test_input        full_response  generated_tokens\n0  462 + 976 + 726 + 421 =  [FINAL]  2585 [END]                 8\n                test_input        full_response  generated_tokens\n0  607 + 810 + 371 + 912 =  [FINAL]  2700 [END]                 8\n                test_input       full_response  generated_tokens\n0  246 + 069 + 217 + 191 =  [FINAL]  713 [END]                 7\n                test_input        full_response  generated_tokens\n0  732 + 601 + 419 + 941 =  [FINAL]  2703 [END]                 8\n                test_input        full_response  generated_tokens\n0  802 + 371 + 088 + 637 =  [FINAL]  1918 [END]                 8\n                test_input       full_response  generated_tokens\n0  198 + 219 + 059 + 430 =  [FINAL]  906 [END]                 7\n                test_input        full_response  generated_tokens\n0  464 + 734 + 308 + 569 =  [FINAL]  2175 [END]                 8\n                test_input        full_response  generated_tokens\n0  543 + 727 + 204 + 400 =  [FINAL]  1874 [END]                 8\n                test_input        full_response  generated_tokens\n0  746 + 277 + 470 + 649 =  [FINAL]  2142 [END]                 8\n                test_input        full_response  generated_tokens\n0  388 + 860 + 856 + 019 =  [FINAL]  2123 [END]                 8\n                test_input        full_response  generated_tokens\n0  217 + 875 + 881 + 739 =  [FINAL]  3292 [END]                 8\n                test_input        full_response  generated_tokens\n0  778 + 834 + 074 + 378 =  [FINAL]  2074 [END]                 8\n                test_input        full_response  generated_tokens\n0  526 + 133 + 277 + 607 =  [FINAL]  1543 [END]                 8\n                test_input        full_response  generated_tokens\n0  146 + 711 + 893 + 164 =  [FINAL]  2214 [END]                 8\n                test_input        full_response  generated_tokens\n0  787 + 660 + 983 + 204 =  [FINAL]  2634 [END]                 8\n                test_input        full_response  generated_tokens\n0  591 + 666 + 408 + 270 =  [FINAL]  1935 [END]                 8\n                test_input        full_response  generated_tokens\n0  006 + 604 + 361 + 367 =  [FINAL]  1338 [END]                 8\n                test_input        full_response  generated_tokens\n0  224 + 650 + 599 + 027 =  [FINAL]  1550 [END]                 8\n                test_input        full_response  generated_tokens\n0  989 + 193 + 537 + 909 =  [FINAL]  3528 [END]                 8\n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                test_input        full_response  generated_tokens\n0  103 + 495 + 301 + 933 =  [FINAL]  1822 [END]                 8\n                test_input        full_response  generated_tokens\n0  040 + 904 + 342 + 697 =  [FINAL]  1983 [END]                 8\n                test_input        full_response  generated_tokens\n0  456 + 480 + 533 + 333 =  [FINAL]  1702 [END]                 8\n                test_input       full_response  generated_tokens\n0  161 + 373 + 167 + 216 =  [FINAL]  917 [END]                 7\n                test_input        full_response  generated_tokens\n0  179 + 785 + 017 + 087 =  [FINAL]  1088 [END]                 8\n                test_input        full_response  generated_tokens\n0  015 + 090 + 869 + 541 =  [FINAL]  1515 [END]                 8\n                test_input        full_response  generated_tokens\n0  617 + 886 + 169 + 047 =  [FINAL]  1629 [END]                 8\n                test_input        full_response  generated_tokens\n0  191 + 305 + 248 + 808 =  [FINAL]  1552 [END]                 8\n                test_input        full_response  generated_tokens\n0  176 + 433 + 869 + 902 =  [FINAL]  2570 [END]                 8\n                test_input        full_response  generated_tokens\n0  292 + 969 + 909 + 631 =  [FINAL]  3701 [END]                 8\n                test_input        full_response  generated_tokens\n0  283 + 738 + 746 + 116 =  [FINAL]  2583 [END]                 8\n                test_input        full_response  generated_tokens\n0  648 + 237 + 738 + 644 =  [FINAL]  2267 [END]                 8\n                test_input        full_response  generated_tokens\n0  314 + 780 + 586 + 271 =  [FINAL]  1951 [END]                 8\n                test_input        full_response  generated_tokens\n0  159 + 879 + 396 + 615 =  [FINAL]  2059 [END]                 8\n                test_input        full_response  generated_tokens\n0  266 + 765 + 765 + 594 =  [FINAL]  2970 [END]                 8\n                test_input        full_response  generated_tokens\n0  196 + 151 + 866 + 055 =  [FINAL]  1298 [END]                 8\n                test_input        full_response  generated_tokens\n0  383 + 699 + 069 + 897 =  [FINAL]  2048 [END]                 8\n                test_input        full_response  generated_tokens\n0  234 + 303 + 921 + 932 =  [FINAL]  2490 [END]                 8\n                test_input        full_response  generated_tokens\n0  306 + 390 + 176 + 792 =  [FINAL]  1864 [END]                 8\n                test_input        full_response  generated_tokens\n0  082 + 942 + 942 + 984 =  [FINAL]  3730 [END]                 8\n                test_input        full_response  generated_tokens\n0  874 + 052 + 788 + 727 =  [FINAL]  3031 [END]                 8\n                test_input        full_response  generated_tokens\n0  900 + 858 + 140 + 689 =  [FINAL]  2587 [END]                 8\n                test_input        full_response  generated_tokens\n0  510 + 338 + 265 + 090 =  [FINAL]  1193 [END]                 8\n                test_input        full_response  generated_tokens\n0  845 + 989 + 389 + 146 =  [FINAL]  2379 [END]                 8\n                test_input        full_response  generated_tokens\n0  104 + 787 + 937 + 587 =  [FINAL]  2365 [END]                 8\n                test_input        full_response  generated_tokens\n0  195 + 401 + 392 + 871 =  [FINAL]  2559 [END]                 8\n                test_input        full_response  generated_tokens\n0  896 + 815 + 747 + 924 =  [FINAL]  3472 [END]                 8\n                test_input        full_response  generated_tokens\n0  448 + 389 + 302 + 127 =  [FINAL]  1366 [END]                 8\n                test_input        full_response  generated_tokens\n0  145 + 224 + 728 + 416 =  [FINAL]  1513 [END]                 8\n                test_input        full_response  generated_tokens\n0  505 + 501 + 533 + 404 =  [FINAL]  1943 [END]                 8\n                test_input        full_response  generated_tokens\n0  766 + 718 + 653 + 348 =  [FINAL]  2525 [END]                 8\n                test_input        full_response  generated_tokens\n0  052 + 820 + 365 + 174 =  [FINAL]  1411 [END]                 8\n                test_input        full_response  generated_tokens\n0  151 + 020 + 698 + 793 =  [FINAL]  1652 [END]                 8\n                test_input        full_response  generated_tokens\n0  704 + 411 + 794 + 099 =  [FINAL]  2008 [END]                 8\n                test_input        full_response  generated_tokens\n0  145 + 373 + 531 + 603 =  [FINAL]  1652 [END]                 8\n                test_input        full_response  generated_tokens\n0  871 + 524 + 264 + 069 =  [FINAL]  1718 [END]                 8\n                test_input        full_response  generated_tokens\n0  746 + 880 + 907 + 025 =  [FINAL]  2558 [END]                 8\n                test_input        full_response  generated_tokens\n0  534 + 133 + 980 + 044 =  [FINAL]  1691 [END]                 8\n                test_input        full_response  generated_tokens\n0  910 + 840 + 573 + 541 =  [FINAL]  2864 [END]                 8\n                test_input        full_response  generated_tokens\n0  581 + 752 + 433 + 854 =  [FINAL]  2520 [END]                 8\n                test_input        full_response  generated_tokens\n0  605 + 937 + 191 + 122 =  [FINAL]  1855 [END]                 8\n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                test_input        full_response  generated_tokens\n0  728 + 121 + 019 + 360 =  [FINAL]  1238 [END]                 8\n                test_input        full_response  generated_tokens\n0  840 + 990 + 159 + 890 =  [FINAL]  3629 [END]                 8\n                test_input                full_response  generated_tokens\n0  378 + 751 + 875 + 929 =  [FINAL]  378 + 751 + 875 +                 16\n                test_input        full_response  generated_tokens\n0  113 + 487 + 796 + 745 =  [FINAL]  2121 [END]                 8\n                test_input        full_response  generated_tokens\n0  986 + 197 + 047 + 277 =  [FINAL]  1407 [END]                 8\n                test_input        full_response  generated_tokens\n0  849 + 468 + 542 + 421 =  [FINAL]  2280 [END]                 8\n                test_input        full_response  generated_tokens\n0  822 + 773 + 320 + 564 =  [FINAL]  2579 [END]                 8\n                test_input        full_response  generated_tokens\n0  440 + 418 + 958 + 794 =  [FINAL]  2610 [END]                 8\n                test_input        full_response  generated_tokens\n0  783 + 552 + 317 + 921 =  [FINAL]  2573 [END]                 8\n                                        test_input        full_response  \\\n0  992 + 523 + 224 + 838 + 857 + 407 + 252 + 810 =  [FINAL]  4086 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  324 + 822 + 430 + 694 + 881 + 497 + 701 + 384 =  [FINAL]  4633 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  037 + 354 + 386 + 588 + 275 + 832 + 054 + 827 =  [FINAL]  3760 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  799 + 680 + 894 + 862 + 712 + 286 + 938 + 475 =  [FINAL]  5301 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  922 + 939 + 285 + 928 + 476 + 328 + 446 + 992 =  [FINAL]  5100 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  850 + 381 + 755 + 546 + 803 + 879 + 541 + 177 =  [FINAL]  4722 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  491 + 370 + 627 + 593 + 255 + 543 + 333 + 605 =  [FINAL]  3422 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  152 + 086 + 769 + 910 + 778 + 498 + 567 + 558 =  [FINAL]  4804 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  481 + 215 + 805 + 384 + 553 + 814 + 338 + 981 =  [FINAL]  4681 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  963 + 784 + 226 + 461 + 601 + 703 + 394 + 492 =  [FINAL]  3914 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  182 + 094 + 202 + 102 + 528 + 766 + 094 + 592 =  [FINAL]  3194 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  703 + 406 + 809 + 719 + 234 + 546 + 966 + 682 =  [FINAL]  4775 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  112 + 844 + 902 + 662 + 117 + 663 + 082 + 930 =  [FINAL]  3376 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  057 + 490 + 439 + 133 + 074 + 630 + 732 + 033 =  [FINAL]  3408 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  225 + 514 + 629 + 113 + 801 + 862 + 444 + 299 =  [FINAL]  3857 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  279 + 754 + 178 + 522 + 014 + 203 + 894 + 108 =  [FINAL]  3106 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  282 + 637 + 509 + 991 + 131 + 968 + 934 + 425 =  [FINAL]  5006 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  074 + 461 + 239 + 115 + 249 + 644 + 858 + 261 =  [FINAL]  3191 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  739 + 301 + 113 + 078 + 609 + 814 + 946 + 934 =  [FINAL]  5004 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  934 + 945 + 832 + 298 + 959 + 860 + 815 + 278 =  [FINAL]  5905 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  944 + 232 + 466 + 155 + 808 + 044 + 859 + 796 =  [FINAL]  4759 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  654 + 276 + 070 + 518 + 521 + 740 + 919 + 051 =  [FINAL]  4500 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  928 + 478 + 234 + 091 + 387 + 931 + 438 + 009 =  [FINAL]  3470 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  452 + 979 + 122 + 651 + 107 + 722 + 397 + 674 =  [FINAL]  4006 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  410 + 384 + 120 + 265 + 210 + 299 + 863 + 004 =  [FINAL]  2635 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  206 + 370 + 266 + 293 + 489 + 197 + 893 + 450 =  [FINAL]  3144 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  695 + 701 + 049 + 666 + 642 + 255 + 580 + 317 =  [FINAL]  3955 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  730 + 296 + 300 + 525 + 542 + 423 + 698 + 198 =  [FINAL]  3720 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  003 + 375 + 844 + 045 + 100 + 622 + 268 + 401 =  [FINAL]  2628 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  253 + 183 + 318 + 920 + 120 + 325 + 000 + 938 =  [FINAL]  2731 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  931 + 097 + 677 + 784 + 603 + 380 + 763 + 667 =  [FINAL]  5100 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  568 + 331 + 615 + 948 + 027 + 941 + 732 + 755 =  [FINAL]  5006 [END]   \n\n   generated_tokens  \n0                 8  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                        test_input        full_response  \\\n0  575 + 138 + 974 + 818 + 631 + 405 + 903 + 053 =  [FINAL]  5002 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  039 + 864 + 618 + 414 + 576 + 693 + 261 + 108 =  [FINAL]  3547 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  692 + 858 + 340 + 690 + 578 + 904 + 216 + 498 =  [FINAL]  4500 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  414 + 747 + 902 + 264 + 869 + 987 + 474 + 637 =  [FINAL]  5006 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  547 + 767 + 735 + 911 + 233 + 461 + 633 + 231 =  [FINAL]  4600 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  051 + 146 + 045 + 657 + 635 + 006 + 851 + 309 =  [FINAL]  3149 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  900 + 466 + 000 + 011 + 512 + 720 + 381 + 706 =  [FINAL]  3776 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  407 + 005 + 761 + 402 + 486 + 065 + 050 + 428 =  [FINAL]  2744 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  051 + 063 + 649 + 032 + 923 + 367 + 611 + 659 =  [FINAL]  3366 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  584 + 787 + 195 + 159 + 123 + 689 + 504 + 790 =  [FINAL]  4131 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  011 + 195 + 322 + 381 + 499 + 438 + 806 + 515 =  [FINAL]  3501 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  698 + 668 + 748 + 571 + 415 + 642 + 940 + 564 =  [FINAL]  4996 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  705 + 442 + 560 + 374 + 151 + 600 + 765 + 196 =  [FINAL]  3903 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  267 + 914 + 435 + 617 + 915 + 774 + 095 + 609 =  [FINAL]  4522 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  920 + 516 + 060 + 077 + 146 + 918 + 962 + 017 =  [FINAL]  4606 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  049 + 092 + 028 + 935 + 038 + 772 + 427 + 769 =  [FINAL]  3006 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input  \\\n0  493 + 977 + 303 + 057 + 638 + 955 + 888 + 433 =   \n\n                 full_response  generated_tokens  \n0  [FINAL]  493 + 977 + 303 +                 16  \n                                        test_input        full_response  \\\n0  454 + 778 + 686 + 023 + 636 + 643 + 795 + 855 =  [FINAL]  5100 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  053 + 488 + 755 + 501 + 311 + 550 + 817 + 010 =  [FINAL]  3945 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  009 + 047 + 869 + 631 + 053 + 959 + 232 + 872 =  [FINAL]  4103 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  776 + 399 + 359 + 331 + 775 + 726 + 121 + 218 =  [FINAL]  3707 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  796 + 947 + 910 + 257 + 273 + 298 + 597 + 357 =  [FINAL]  4106 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  656 + 706 + 100 + 289 + 467 + 602 + 281 + 005 =  [FINAL]  2706 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  557 + 194 + 690 + 177 + 089 + 902 + 136 + 226 =  [FINAL]  3329 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  713 + 138 + 720 + 469 + 931 + 476 + 518 + 127 =  [FINAL]  4502 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  078 + 558 + 483 + 685 + 413 + 069 + 596 + 420 =  [FINAL]  3402 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  406 + 413 + 275 + 085 + 295 + 425 + 270 + 879 =  [FINAL]  3603 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  585 + 423 + 475 + 648 + 730 + 574 + 846 + 872 =  [FINAL]  4623 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  446 + 126 + 806 + 456 + 451 + 253 + 666 + 865 =  [FINAL]  4001 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  463 + 884 + 454 + 848 + 097 + 098 + 782 + 182 =  [FINAL]  4426 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  251 + 801 + 993 + 188 + 996 + 239 + 247 + 422 =  [FINAL]  4027 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  477 + 398 + 539 + 568 + 355 + 721 + 575 + 790 =  [FINAL]  4233 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  111 + 425 + 331 + 881 + 978 + 988 + 026 + 072 =  [FINAL]  4633 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  143 + 761 + 520 + 784 + 157 + 150 + 048 + 847 =  [FINAL]  3600 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  394 + 536 + 176 + 781 + 632 + 588 + 391 + 687 =  [FINAL]  4105 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  398 + 427 + 319 + 266 + 576 + 921 + 813 + 585 =  [FINAL]  4305 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  281 + 432 + 137 + 579 + 709 + 873 + 336 + 541 =  [FINAL]  3908 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  024 + 909 + 597 + 365 + 351 + 656 + 319 + 278 =  [FINAL]  3503 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  454 + 465 + 985 + 702 + 209 + 246 + 917 + 942 =  [FINAL]  5000 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  734 + 295 + 531 + 772 + 377 + 202 + 674 + 582 =  [FINAL]  3903 [END]   \n\n   generated_tokens  \n0                 8  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                        test_input        full_response  \\\n0  013 + 895 + 627 + 516 + 344 + 420 + 062 + 216 =  [FINAL]  3109 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  964 + 076 + 621 + 795 + 544 + 687 + 477 + 626 =  [FINAL]  4934 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  924 + 391 + 219 + 326 + 951 + 737 + 180 + 135 =  [FINAL]  4303 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  803 + 393 + 635 + 539 + 730 + 517 + 791 + 568 =  [FINAL]  4726 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  432 + 783 + 240 + 854 + 536 + 987 + 830 + 818 =  [FINAL]  5000 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  391 + 191 + 054 + 317 + 042 + 998 + 656 + 949 =  [FINAL]  4638 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  422 + 374 + 941 + 522 + 582 + 515 + 186 + 535 =  [FINAL]  3503 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  673 + 391 + 408 + 200 + 485 + 413 + 620 + 392 =  [FINAL]  3572 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  533 + 666 + 072 + 664 + 996 + 482 + 925 + 058 =  [FINAL]  5000 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  692 + 078 + 440 + 654 + 942 + 503 + 662 + 798 =  [FINAL]  5003 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  359 + 996 + 494 + 738 + 120 + 494 + 383 + 547 =  [FINAL]  4124 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  449 + 914 + 990 + 745 + 900 + 668 + 664 + 799 =  [FINAL]  5629 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  889 + 300 + 015 + 832 + 187 + 245 + 088 + 219 =  [FINAL]  3255 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  988 + 428 + 602 + 488 + 584 + 094 + 391 + 556 =  [FINAL]  4031 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  226 + 935 + 242 + 121 + 746 + 420 + 509 + 761 =  [FINAL]  3600 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  915 + 984 + 445 + 793 + 594 + 856 + 939 + 281 =  [FINAL]  5303 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  146 + 485 + 856 + 969 + 169 + 542 + 492 + 054 =  [FINAL]  4007 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  380 + 129 + 297 + 685 + 733 + 124 + 019 + 762 =  [FINAL]  3239 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  904 + 429 + 425 + 688 + 983 + 577 + 002 + 830 =  [FINAL]  4739 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  980 + 800 + 591 + 614 + 609 + 034 + 560 + 424 =  [FINAL]  4512 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  191 + 112 + 817 + 665 + 789 + 996 + 460 + 083 =  [FINAL]  5002 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  649 + 030 + 046 + 385 + 705 + 148 + 421 + 795 =  [FINAL]  3993 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  108 + 124 + 453 + 211 + 496 + 780 + 126 + 576 =  [FINAL]  3264 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  021 + 443 + 717 + 277 + 577 + 836 + 837 + 884 =  [FINAL]  4560 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  060 + 377 + 220 + 000 + 100 + 074 + 342 + 984 =  [FINAL]  2292 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  112 + 230 + 649 + 419 + 342 + 090 + 318 + 243 =  [FINAL]  2953 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  705 + 333 + 921 + 003 + 758 + 029 + 766 + 833 =  [FINAL]  4802 [END]   \n\n   generated_tokens  \n0                 8  \n                                        test_input        full_response  \\\n0  657 + 931 + 051 + 262 + 396 + 636 + 569 + 968 =  [FINAL]  4924 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  085 + 924 + 145 + 640 + 527 + 413 + 521 + 882 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  984 + 560 + 114 + 017 + 357 + 889 + 871 + 113 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  833 + 419 + 255 + 046 + 661 + 914 + 304 + 243 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  402 + 995 + 554 + 518 + 358 + 844 + 595 + 818 ...  [FINAL]  6323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  322 + 689 + 818 + 298 + 583 + 183 + 428 + 164 ...  [FINAL]  6723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  346 + 213 + 349 + 719 + 255 + 900 + 297 + 949 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  443 + 613 + 284 + 623 + 568 + 338 + 254 + 603 ...  [FINAL]  5000 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  965 + 263 + 585 + 763 + 776 + 962 + 178 + 320 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  032 + 402 + 257 + 449 + 458 + 623 + 427 + 515 ...  [FINAL]  6322 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  169 + 142 + 718 + 456 + 937 + 263 + 950 + 889 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  836 + 104 + 859 + 667 + 726 + 748 + 402 + 953 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  126 + 916 + 896 + 122 + 964 + 544 + 223 + 182 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input         full_response  \\\n0  685 + 694 + 910 + 744 + 841 + 371 + 118 + 466 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  316 + 019 + 342 + 974 + 548 + 201 + 019 + 294 ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input        full_response  \\\n0  098 + 900 + 376 + 982 + 140 + 638 + 278 + 153 ...  [FINAL]  7320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  785 + 085 + 511 + 167 + 739 + 269 + 461 + 409 ...  [FINAL]  7323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  209 + 089 + 844 + 762 + 665 + 385 + 336 + 177 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  351 + 394 + 828 + 081 + 732 + 144 + 161 + 792 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  713 + 091 + 128 + 914 + 005 + 412 + 774 + 899 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  870 + 212 + 670 + 073 + 079 + 980 + 796 + 671 ...  [FINAL]  7320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  551 + 670 + 657 + 325 + 492 + 957 + 251 + 205 ...  [FINAL]  6390 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  413 + 217 + 999 + 010 + 996 + 451 + 399 + 490 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  693 + 385 + 289 + 501 + 871 + 772 + 738 + 575 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  783 + 194 + 850 + 311 + 678 + 239 + 618 + 026 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  664 + 228 + 775 + 076 + 323 + 516 + 291 + 460 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  242 + 464 + 321 + 501 + 389 + 846 + 729 + 433 ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input        full_response  \\\n0  033 + 911 + 728 + 873 + 703 + 646 + 273 + 824 ...  [FINAL]  6390 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  765 + 973 + 822 + 013 + 200 + 717 + 158 + 155 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  267 + 777 + 738 + 985 + 401 + 474 + 558 + 749 ...  [FINAL]  6723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  292 + 359 + 895 + 695 + 004 + 479 + 255 + 083 ...  [FINAL]  6320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  934 + 069 + 847 + 780 + 324 + 997 + 349 + 907 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  583 + 212 + 261 + 230 + 915 + 132 + 494 + 380 ...  [FINAL]  6720 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  908 + 805 + 872 + 181 + 775 + 894 + 598 + 878 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  159 + 696 + 236 + 295 + 840 + 667 + 110 + 013 ...  [FINAL]  7323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  280 + 532 + 918 + 223 + 179 + 251 + 600 + 267 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  148 + 644 + 271 + 251 + 921 + 671 + 927 + 620 ...  [FINAL]  6320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  317 + 098 + 534 + 535 + 980 + 806 + 489 + 060 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  830 + 371 + 826 + 597 + 544 + 079 + 243 + 857 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  551 + 939 + 981 + 255 + 144 + 980 + 873 + 126 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  065 + 106 + 408 + 900 + 759 + 738 + 760 + 475 ...  [FINAL]  7320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  359 + 950 + 410 + 879 + 300 + 789 + 120 + 021 ...  [FINAL]  7320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  081 + 467 + 390 + 053 + 059 + 902 + 768 + 411 ...  [FINAL]  6320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  097 + 651 + 367 + 547 + 611 + 469 + 738 + 580 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  420 + 548 + 596 + 608 + 563 + 759 + 985 + 780 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  721 + 390 + 562 + 571 + 038 + 706 + 431 + 928 ...  [FINAL]  6723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  659 + 088 + 213 + 896 + 457 + 149 + 050 + 279 ...  [FINAL]  7300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input  \\\n0  732 + 804 + 153 + 039 + 682 + 731 + 760 + 906 ...   \n\n                 full_response  generated_tokens  \n0  [FINAL]  732 + 804 + 153 +                 16  \n                                          test_input         full_response  \\\n0  331 + 992 + 143 + 193 + 232 + 883 + 540 + 510 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  726 + 402 + 642 + 168 + 177 + 483 + 599 + 225 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  679 + 632 + 124 + 986 + 641 + 862 + 947 + 769 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  277 + 382 + 084 + 201 + 917 + 422 + 870 + 173 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input        full_response  \\\n0  261 + 535 + 612 + 482 + 467 + 579 + 563 + 337 ...  [FINAL]  7723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  643 + 548 + 698 + 087 + 565 + 396 + 010 + 921 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  358 + 289 + 132 + 231 + 994 + 659 + 654 + 326 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  566 + 489 + 894 + 874 + 488 + 151 + 673 + 570 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  658 + 041 + 243 + 774 + 399 + 506 + 530 + 619 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  145 + 557 + 345 + 036 + 667 + 067 + 704 + 959 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  855 + 030 + 004 + 173 + 528 + 267 + 600 + 570 ...  [FINAL]  6000 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  056 + 012 + 344 + 506 + 712 + 557 + 226 + 311 ...  [FINAL]  7323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  117 + 291 + 330 + 419 + 440 + 538 + 812 + 143 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  824 + 213 + 135 + 083 + 271 + 327 + 829 + 403 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  828 + 545 + 582 + 361 + 314 + 699 + 197 + 717 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  879 + 662 + 523 + 757 + 336 + 926 + 375 + 307 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  574 + 926 + 060 + 756 + 167 + 864 + 948 + 510 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  586 + 599 + 354 + 683 + 392 + 120 + 772 + 782 ...  [FINAL]  6723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  233 + 690 + 246 + 714 + 139 + 035 + 249 + 195 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  015 + 450 + 860 + 735 + 449 + 342 + 269 + 975 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  344 + 155 + 993 + 130 + 487 + 883 + 982 + 838 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  012 + 154 + 385 + 963 + 257 + 701 + 757 + 388 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  662 + 275 + 315 + 345 + 602 + 660 + 233 + 833 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  935 + 155 + 180 + 958 + 804 + 250 + 023 + 155 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  837 + 828 + 394 + 612 + 176 + 426 + 024 + 267 ...  [FINAL]  6323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  745 + 830 + 494 + 658 + 955 + 040 + 568 + 595 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  619 + 716 + 716 + 100 + 996 + 102 + 840 + 479 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  452 + 513 + 544 + 397 + 113 + 699 + 937 + 991 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  315 + 655 + 752 + 562 + 941 + 150 + 538 + 168 ...  [FINAL]  6723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  119 + 054 + 299 + 843 + 564 + 164 + 829 + 681 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  525 + 312 + 765 + 162 + 197 + 015 + 047 + 130 ...  [FINAL]  7123 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  996 + 477 + 030 + 933 + 495 + 515 + 215 + 338 ...  [FINAL]  7200 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  859 + 340 + 912 + 041 + 788 + 043 + 233 + 038 ...  [FINAL]  6322 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  463 + 679 + 074 + 969 + 986 + 534 + 161 + 447 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  257 + 105 + 799 + 559 + 362 + 047 + 262 + 105 ...  [FINAL]  6000 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  499 + 669 + 792 + 527 + 491 + 989 + 775 + 551 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  119 + 709 + 680 + 933 + 515 + 131 + 477 + 634 ...  [FINAL]  7300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  896 + 630 + 479 + 313 + 276 + 505 + 376 + 558 ...  [FINAL]  7323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  057 + 408 + 117 + 572 + 355 + 339 + 997 + 329 ...  [FINAL]  6000 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  565 + 063 + 743 + 926 + 948 + 077 + 249 + 943 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  317 + 196 + 239 + 016 + 014 + 984 + 665 + 943 ...  [FINAL]  7323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  163 + 331 + 847 + 295 + 733 + 848 + 773 + 560 ...  [FINAL]  6300 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  198 + 535 + 628 + 478 + 816 + 412 + 130 + 110 ...  [FINAL]  6323 [END]   \n\n   generated_tokens  \n0                 8  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input        full_response  \\\n0  321 + 990 + 854 + 000 + 471 + 302 + 640 + 427 ...  [FINAL]  6000 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  772 + 935 + 820 + 218 + 750 + 446 + 653 + 493 ...  [FINAL]  6700 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  095 + 023 + 008 + 721 + 951 + 722 + 995 + 432 ...  [FINAL]  7320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  264 + 045 + 788 + 948 + 627 + 129 + 899 + 386 ...  [FINAL]  7323 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  032 + 869 + 405 + 698 + 677 + 009 + 723 + 361 ...  [FINAL]  6322 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input        full_response  \\\n0  988 + 653 + 147 + 170 + 310 + 096 + 245 + 370 ...  [FINAL]  6723 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  857 + 772 + 608 + 760 + 176 + 168 + 174 + 533 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  082 + 836 + 054 + 179 + 990 + 522 + 825 + 813 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input        full_response  \\\n0  579 + 642 + 899 + 131 + 352 + 800 + 345 + 937 ...  [FINAL]  7320 [END]   \n\n   generated_tokens  \n0                 8  \n                                          test_input         full_response  \\\n0  831 + 398 + 571 + 280 + 956 + 847 + 901 + 140 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  273 + 968 + 948 + 409 + 091 + 904 + 627 + 405 ...  [FINAL]  12345 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  281 + 060 + 396 + 663 + 752 + 190 + 080 + 191 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  869 + 002 + 082 + 670 + 467 + 362 + 329 + 304 ...  [FINAL]  10234 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  239 + 678 + 065 + 880 + 638 + 814 + 766 + 445 ...  [FINAL]  13232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  156 + 941 + 524 + 545 + 855 + 230 + 715 + 810 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  921 + 001 + 157 + 770 + 715 + 141 + 400 + 221 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  029 + 264 + 204 + 966 + 061 + 729 + 873 + 803 ...  [FINAL]  13200 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  900 + 271 + 747 + 740 + 196 + 614 + 176 + 213 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  479 + 395 + 041 + 395 + 893 + 130 + 963 + 059 ...  [FINAL]  11323 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  167 + 045 + 626 + 650 + 587 + 896 + 999 + 696 ...  [FINAL]  13232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  329 + 900 + 996 + 942 + 068 + 986 + 137 + 636 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  936 + 982 + 473 + 672 + 570 + 706 + 552 + 450 ...  [FINAL]  12345 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  260 + 942 + 430 + 970 + 489 + 817 + 922 + 116 ...  [FINAL]  13230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  175 + 559 + 009 + 153 + 318 + 248 + 959 + 595 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  676 + 142 + 140 + 532 + 725 + 240 + 858 + 072 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  188 + 921 + 244 + 599 + 331 + 108 + 945 + 448 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  399 + 634 + 559 + 207 + 690 + 336 + 851 + 956 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  819 + 489 + 345 + 239 + 848 + 106 + 138 + 337 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  604 + 870 + 156 + 147 + 961 + 385 + 430 + 126 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  712 + 018 + 141 + 250 + 927 + 342 + 260 + 749 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  354 + 941 + 567 + 451 + 020 + 355 + 886 + 429 ...  [FINAL]  10323 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  911 + 960 + 443 + 360 + 164 + 182 + 185 + 573 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  813 + 952 + 189 + 011 + 657 + 840 + 719 + 819 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  263 + 847 + 212 + 549 + 899 + 004 + 849 + 240 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  676 + 658 + 444 + 643 + 122 + 972 + 288 + 298 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  778 + 645 + 178 + 376 + 304 + 234 + 044 + 141 ...  [FINAL]  13230 [END]   \n\n   generated_tokens  \n0                 9  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input  \\\n0  164 + 436 + 297 + 628 + 722 + 479 + 954 + 841 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  458 + 483 + 913 + 253 + 673 + 534 + 047 + 412 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  826 + 961 + 190 + 705 + 295 + 865 + 036 + 518 ...  [FINAL]  13200 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  639 + 014 + 120 + 241 + 617 + 374 + 798 + 144 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  007 + 025 + 540 + 547 + 473 + 482 + 979 + 776 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  255 + 420 + 166 + 629 + 474 + 567 + 166 + 807 ...  [FINAL]  10231 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  693 + 910 + 594 + 416 + 422 + 441 + 171 + 569 ...  [FINAL]  11232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  356 + 669 + 911 + 217 + 405 + 510 + 701 + 109 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  564 + 102 + 056 + 737 + 012 + 144 + 831 + 297 ...  [FINAL]  10323 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  556 + 167 + 699 + 727 + 002 + 887 + 500 + 774 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  359 + 256 + 745 + 685 + 297 + 636 + 883 + 103 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  668 + 879 + 926 + 297 + 235 + 051 + 667 + 234 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  137 + 817 + 306 + 013 + 197 + 266 + 021 + 443 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  700 + 957 + 455 + 627 + 563 + 744 + 190 + 064 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  720 + 636 + 968 + 975 + 582 + 916 + 870 + 290 ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input         full_response  \\\n0  494 + 909 + 724 + 407 + 599 + 282 + 150 + 940 ...  [FINAL]  11230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  111 + 011 + 386 + 591 + 066 + 307 + 076 + 758 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  981 + 376 + 113 + 058 + 951 + 031 + 293 + 184 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  749 + 925 + 495 + 979 + 543 + 628 + 919 + 544 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  122 + 210 + 872 + 383 + 018 + 171 + 459 + 758 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  242 + 773 + 672 + 939 + 200 + 575 + 116 + 417 ...  [FINAL]  12345 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  030 + 811 + 778 + 839 + 986 + 430 + 508 + 293 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  175 + 280 + 328 + 807 + 786 + 945 + 371 + 033 ...  [FINAL]  13230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  071 + 043 + 599 + 713 + 952 + 860 + 940 + 966 ...  [FINAL]  13200 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  395 + 003 + 590 + 963 + 293 + 153 + 187 + 243 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  315 + 635 + 731 + 313 + 664 + 559 + 253 + 654 ...  [FINAL]  10800 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  190 + 200 + 352 + 859 + 992 + 038 + 125 + 767 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  999 + 122 + 831 + 022 + 176 + 549 + 187 + 904 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  561 + 660 + 516 + 295 + 860 + 056 + 232 + 339 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  329 + 604 + 026 + 708 + 627 + 642 + 885 + 253 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  520 + 130 + 123 + 613 + 942 + 507 + 451 + 748 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  193 + 262 + 829 + 648 + 042 + 201 + 247 + 905 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  071 + 797 + 695 + 961 + 928 + 324 + 637 + 445 ...  [FINAL]  10923 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  339 + 694 + 339 + 604 + 837 + 191 + 909 + 296 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  536 + 592 + 240 + 155 + 061 + 533 + 113 + 675 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input         full_response  \\\n0  640 + 676 + 305 + 500 + 500 + 070 + 853 + 631 ...  [FINAL]  13230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  677 + 374 + 713 + 503 + 937 + 382 + 379 + 717 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  430 + 073 + 441 + 368 + 281 + 087 + 679 + 105 ...  [FINAL]  12345 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  772 + 526 + 069 + 606 + 299 + 861 + 739 + 233 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  145 + 111 + 980 + 659 + 145 + 487 + 996 + 863 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  888 + 257 + 467 + 152 + 696 + 256 + 839 + 590 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  919 + 513 + 674 + 455 + 510 + 455 + 639 + 797 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  633 + 192 + 736 + 830 + 407 + 666 + 772 + 235 ...  [FINAL]  12345 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  550 + 508 + 019 + 126 + 230 + 314 + 395 + 837 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  101 + 206 + 517 + 707 + 724 + 042 + 864 + 754 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  226 + 855 + 022 + 051 + 118 + 569 + 943 + 919 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  797 + 949 + 611 + 220 + 286 + 289 + 343 + 226 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  282 + 902 + 891 + 450 + 012 + 365 + 304 + 411 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  958 + 403 + 112 + 363 + 577 + 570 + 563 + 856 ...  [FINAL]  13230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  825 + 889 + 393 + 166 + 764 + 371 + 856 + 332 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  924 + 881 + 040 + 981 + 151 + 956 + 311 + 239 ...  [FINAL]  13212 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  698 + 993 + 794 + 289 + 975 + 981 + 539 + 513 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  994 + 603 + 643 + 419 + 472 + 644 + 167 + 940 ...  [FINAL]  12345 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  099 + 693 + 561 + 315 + 358 + 182 + 223 + 208 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  101 + 794 + 292 + 613 + 340 + 775 + 290 + 119 ...  [FINAL]  10140 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  164 + 115 + 024 + 386 + 297 + 754 + 423 + 161 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  592 + 054 + 140 + 307 + 454 + 031 + 661 + 167 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  246 + 100 + 213 + 568 + 587 + 987 + 095 + 522 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  288 + 030 + 034 + 441 + 798 + 863 + 418 + 918 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  698 + 367 + 769 + 655 + 708 + 029 + 527 + 279 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  233 + 009 + 480 + 540 + 472 + 680 + 495 + 475 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  011 + 079 + 653 + 931 + 390 + 426 + 511 + 613 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input  \\\n0  484 + 442 + 660 + 945 + 329 + 982 + 324 + 659 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  082 + 828 + 690 + 343 + 981 + 336 + 805 + 906 ...  [FINAL]  11322 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  683 + 053 + 765 + 153 + 001 + 000 + 802 + 956 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  288 + 045 + 357 + 284 + 546 + 706 + 771 + 445 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  570 + 358 + 885 + 570 + 239 + 933 + 279 + 061 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  280 + 375 + 609 + 018 + 389 + 650 + 918 + 979 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  011 + 770 + 330 + 642 + 090 + 611 + 212 + 385 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input         full_response  \\\n0  691 + 464 + 358 + 700 + 593 + 242 + 750 + 374 ...  [FINAL]  10230 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input         full_response  \\\n0  335 + 128 + 534 + 481 + 775 + 754 + 777 + 011 ...  [FINAL]  10232 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  667 + 721 + 174 + 351 + 021 + 827 + 064 + 818 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n                                          test_input         full_response  \\\n0  009 + 337 + 068 + 920 + 685 + 027 + 247 + 827 ...  [FINAL]  10000 [END]   \n\n   generated_tokens  \n0                 9  \n                                          test_input  \\\n0  055 + 640 + 366 + 643 + 541 + 729 + 918 + 261 ...   \n\n              full_response  generated_tokens  \n0  [FINAL]  123456789012345                16  \n\n──────────────────────────────────────────────────────────────────────\nSummary for N_ARY\n──────────────────────────────────────────────────────────────────────\nAccuracy:             28.00% (140/500)\nAvg Gen Time:         7.699s\nAvg Tokens:             8.7\n──────────────────────────────────────────────────────────────────────\n\nSample Results for N_ARY (first 10):\n──────────────────────────────────────────────────────────────────────\n test_input       full_response generated_tokens  is_correct  is_degenerate\n871 + 556 = [FINAL]  1427 [END]                8        True          False\n888 + 759 = [FINAL]  1647 [END]                8        True          False\n670 + 418 = [FINAL]  1088 [END]                8        True          False\n661 + 544 = [FINAL]  1205 [END]                8        True          False\n328 + 902 = [FINAL]  1230 [END]                8        True          False\n696 + 243 =  [FINAL]  939 [END]                7        True          False\n810 + 357 = [FINAL]  1167 [END]                8        True          False\n191 + 780 =  [FINAL]  971 [END]                7        True          False\n933 + 652 = [FINAL]  1585 [END]                8        True          False\n995 + 551 = [FINAL]  1546 [END]                8        True          False\n\n\n──────────────────────────────────────────────────────────────────────\nTask: P_HOP\n──────────────────────────────────────────────────────────────────────\nTotal Samples: 300\nBatch Size: 1\nStrategy: Sequential Processing\n\nProcessing 300 items sequentially...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   p_hop:   0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"156aae77b59747519bafa39a177e01a5"}},"metadata":{}},{"name":"stdout","text":"                                          test_input     full_response  \\\n0  Sequence: B C C B D C B A C A B B B D A A D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B D C B C C D C D C D D B D B D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A D D A B B D B C A D D B C D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B C C D A C D C D C C C C B B B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A A C B B D C B C A D A B B D D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C B C D D A A D C A A B A D A B A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B B A B B A B A B D B D D A D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D C C C D B A D B C B B D B D D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D C A D B A C C C A A C B B C B A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C C A B C B D C D A C C C C C B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D B C D D C D B B A D D A C C C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B B B C B D B A A A B B B A A C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D C A D D D C B C A D A A A C C C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B C C C B B B A C A D C B C C A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B B B D C C B C C C C B D D D D B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C D A B D C D A A B A D B C B C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D A D B B A C B D B D B B B D A B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D C B C B A A B A B A C B C C A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D A A D D D B D B B B A C D C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C C B C B D D B D C C B B D B B C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D C A A D D A A D B B C C A B D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D B C B B B C C A B D B C C A A C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C B A B C B C D D D D B C A A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C D A C C A D D D B D A C D D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C C A A D A D C C A C A C D C B D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D B A D B A C C C B D C D C C B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D C A B B B B C C D C C B B D A D ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B C B B A A D C C B B D A B D B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B A C D B C C C B B D D B D C B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D D B D C A B C D A C C B C D B C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A A B A C B C D A A D D B A D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D C C A D B C B B A C A D C D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C B D A D D C C A D C A A C B C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A D A C A A D D C C D D B B B C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A A A B A A D D B C C D D C B B D C ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: C C C C B B B C B A C A B A A C C C ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input     full_response  \\\n0  Sequence: B A B C C C C A A B A B C C D B C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B C D D D A B C A C B B D B C D A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A B A D D B D D C A B B B C A C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B A B A A C D A A D D A A D A A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A A A C D C B B B D D A B D A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D A C B C D B B B C D D C A A D C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D C C B A B D B D C A C A C B D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D B D A C B B A B B C C C C B B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D D D A B A D C C C D C C C C A C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C D C D D C C B C B A A A D A B C ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D A D A B C C C A C B D C B B C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B A A D A A A B A D D B C A A D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C D C A A A B B D C C A C D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A B B A A A D A D B C D D D C D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C B D B C C B B A C B C B B C D B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D A A B C B A C C C D D B A B C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: B D D B D D C A A A B A D C B C C A ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input     full_response  \\\n0  Sequence: D B B D D C B A C B B D A B A D C C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B B A D D D B C C B C A C B B B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C B B B D C B C A C B A C D C D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B B C A A C D B C C C D C B B D B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C B B A B B B C A A A C A B D C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A C A D A D A C D A A C A D A D C B ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A B C B C C B B B D D B A C B A A D ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input     full_response  \\\n0  Sequence: D A C A C D C B D A D B D A B C C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C D B B C D D C B A B B A B D B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C D D A B B B B C A D B D B C B D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C C C B B B D C A D D D C D A A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C A D B B B D C B A A A D B C D A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C A D B A B B D D D B C A A B C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B C D C B A B C A A A B C D C C B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B D B A D A B D D B B C D D B C A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D C B C B B D B D C C B C B A C D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C D A B D D A C A C D B C A C A D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D B C D C B A B B B C A B D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D A B B C A C D B B A D C D A B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A C B D C B D A A D A B D D D A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C A C A D C C C B A A A D C C B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C A B D B C A D A B D D B A A D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C C A B A C C D A B A C C A A D A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n                                          test_input     full_response  \\\n0  Sequence: D D C D B B C D C D A A A A D B C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C D D C D D D A D C B B A D C B D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A B A B B C A D D C C B D B B C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \nAborting due to repeated outputs...\nWarning: Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: C D B C D A D B C B C D D C C A D B ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input     full_response  \\\n0  Sequence: C D A B B A B B B A A D A C C B A C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B A C D C B D C A B D C B C C C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C C A C A A A A D D A C B A D C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A B B C D D A B D D B B B B C D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D B A B D C A A D D A B D D B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A C A A D C D A A D D D D D D A D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A C D B B C A A A A B A C C D D D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A C C D B C C D B B D D B C D D D ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A B D D A A B A A C A D B C D B A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A D A A D D B C D C C A B C D B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D A A D B B D D D A A B C A D C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D D D C D C C B B A A A C A B D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B B A A C D B A B D C D A C C C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A D A C D D B D B C C C C C B C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B A D C B A D A D D B D C A A D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D B A B B C C D B D C A B B C A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C D D B D C C B D D B C A A D B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D B C A A A A A D D B B C D D A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D C A C A C B C B C D A D A A C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D C A B A A D A D B C D C A C D D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D C A B C B C B D A C C D B B B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A A C A B B B B D A D D B C D C D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D A D B C B B B B A B D C A B A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B C B C D A B B D A D B B B D A C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C D A B A C B D A A A B C D D B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C A C C D D A A D A D B D C C D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A C B D D B D A B B C A D B D B B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B C D A D A C D D C D B C C D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D D B C A A A C A C C D A A D A D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n\n======================================================================\nEXPERIMENT INTERRUPTED BY USER\n======================================================================\nFinalizing W&B...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>n_ary/accuracy</td><td>▁</td></tr><tr><td>n_ary/avg_generation_time</td><td>▁</td></tr><tr><td>n_ary/avg_tokens</td><td>▁</td></tr><tr><td>n_ary/num_degenerate</td><td>▁</td></tr><tr><td>n_ary/num_samples</td><td>▁</td></tr><tr><td>n_ary/throughput</td><td>▁</td></tr><tr><td>perplexity</td><td>▁</td></tr><tr><td>ut_steps</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>n_ary/accuracy</td><td>0.28</td></tr><tr><td>n_ary/avg_generation_time</td><td>7.69868</td></tr><tr><td>n_ary/avg_tokens</td><td>8.744</td></tr><tr><td>n_ary/num_degenerate</td><td>0</td></tr><tr><td>n_ary/num_samples</td><td>500</td></tr><tr><td>n_ary/throughput</td><td>0</td></tr><tr><td>perplexity</td><td>0.23606</td></tr><tr><td>ut_steps</td><td>4</td></tr><tr><td>val_loss</td><td>1.26625</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rare-sunset-159</strong> at: <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/w0lf8jb7' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/w0lf8jb7</a><br> View project at: <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>/kaggle/working/wandb/run-20251226_162529-w0lf8jb7/logs</code>"},"metadata":{}},{"name":"stdout","text":"W&B session closed\n======================================================================\nCleaning up GPU memory...\nGPU memory freed\n======================================================================\n\n✅ Periodic save: simple reasoning results to ../results_20251226_162535_UT_4/simple_reasoning.csv\n✅ Periodic save: perplexity results to ../results_20251226_162535_UT_4/perplexity.csv\n✅ Configuration saved to ../results_20251226_162535_UT_4/config.json\n✅ Task templates saved to ../results_20251226_162535_UT_4/task_templates.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport glob\nimport zipfile\nfrom typing import List\ndef find_result_folders(base_path: str) -> List[str]:\n    \"\"\"\n    Return a list of absolute paths to all directories under `base_path`\n    whose names start with 'results_'.\n    \"\"\"\n    pattern = os.path.join(base_path, \"results_*\")\n    # glob returns both files and directories; filter to directories only\n    return [p for p in glob.glob(pattern) if os.path.isdir(p)]\ndef zip_folder(folder_path: str, output_base_path: str) -> bool:\n    \"\"\"\n    Zip the contents of `folder_path` into a file named\n    <folder_name>.zip` inside `output_base_path`.\n\n    Returns True on success, False otherwise.\n    \"\"\"\n    folder_name = os.path.basename(folder_path)\n    zip_path = os.path.join(output_base_path, f\"{folder_name}.zip\")\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(\n            zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED\n        ) as zipf:\n            for root, _, files in os.walk(folder_path):\n                for file in files:\n                    full_path = os.path.join(root, file)\n                    # Preserve relative path inside the zip\n                    arcname = os.path.relpath(full_path, os.path.dirname(folder_path))\n                    zipf.write(full_path, arcname)\n        print(f\"   ✅ Created ZIP: {os.path.basename(zip_path)}\")\n        return True\n    except Exception as exc:\n        print(f\"   ❌ Failed to zip {folder_name}: {exc}\")\n        return False\ndef zip_stats_results_folders(output_base_path: str) -> None:\n    \"\"\"\n    Main driver: locate all result folders and zip each one.\n    \"\"\"\n    # Ensure the output directory exists\n    os.makedirs(output_base_path, exist_ok=True)\n    result_folders = find_result_folders(output_base_path)\n    if not result_folders:\n        print(f\"⚠️ No folders starting with 'results_' found in '{output_base_path}'.\")\n        return\n    print(f\"🔍 Found {len(result_folders)} result folder(s) to zip.\")\n    successful = 0\n    for folder in result_folders:\n        if zip_folder(folder, output_base_path):\n            successful += 1\n    print(\n        f\"\\n✅ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\"\n    )\nif __name__ == \"__main__\":\n    try:\n        # Prefer an environment variable; fall back to a global if defined\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        # The script expects a sub‑folder named 'OuroTrace' under OUTPUT_PATH\n        target_path = os.path.join(output_root, \"\")\n        zip_stats_results_folders(target_path)\n    except Exception as e:\n        print(f\"❌ An error occurred: {e}\")","metadata":{"id":"8inXWmVwnzBC","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:45:35.557423Z","iopub.execute_input":"2025-12-26T17:45:35.557623Z","iopub.status.idle":"2025-12-26T17:45:35.5833Z","shell.execute_reply.started":"2025-12-26T17:45:35.557608Z","shell.execute_reply":"2025-12-26T17:45:35.582717Z"}},"outputs":[{"name":"stdout","text":"🔍 Found 3 result folder(s) to zip.\n   -> Zipping folder: results_20251226_161418_UT_12...\n   ✅ Created ZIP: results_20251226_161418_UT_12.zip\n   -> Zipping folder: results_20251226_160923_UT_12...\n   ✅ Created ZIP: results_20251226_160923_UT_12.zip\n   -> Zipping folder: results_20251226_162535_UT_4...\n   ✅ Created ZIP: results_20251226_162535_UT_4.zip\n\n✅ DONE! Successfully zipped 3 out of 3 folder(s).\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"df_simple = pd.DataFrame(simple_reasoning_results)\ndf_ppl = pd.DataFrame(ppl_results)\n\nprint(\"Final Inspection:\\n\")\nprint(\"Top 20 Accuracy Report:\\n\")\nprint(df_simple.head(20))\nprint(f\"Full Response:\\n\")\nprint(df_simple[\"full_response\"])\nprint(\"Perplexity Report:\\n\")\nprint(df_ppl.head(20))","metadata":{"id":"3zpz9ccInzBD","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:45:35.583941Z","iopub.execute_input":"2025-12-26T17:45:35.584248Z","iopub.status.idle":"2025-12-26T17:45:35.598298Z","shell.execute_reply.started":"2025-12-26T17:45:35.584231Z","shell.execute_reply":"2025-12-26T17:45:35.597686Z"}},"outputs":[{"name":"stdout","text":"Final Inspection:\n\nTop 20 Accuracy Report:\n\n   task_type difficulty   test_input expected_answer prediction  is_correct  \\\n0      n_ary      2_ops  871 + 556 =            1427       1427        True   \n1      n_ary      2_ops  888 + 759 =            1647       1647        True   \n2      n_ary      2_ops  670 + 418 =            1088       1088        True   \n3      n_ary      2_ops  661 + 544 =            1205       1205        True   \n4      n_ary      2_ops  328 + 902 =            1230       1230        True   \n5      n_ary      2_ops  696 + 243 =             939        939        True   \n6      n_ary      2_ops  810 + 357 =            1167       1167        True   \n7      n_ary      2_ops  191 + 780 =             971        971        True   \n8      n_ary      2_ops  933 + 652 =            1585       1585        True   \n9      n_ary      2_ops  995 + 551 =            1546       1546        True   \n10     n_ary      2_ops  227 + 885 =            1112       1112        True   \n11     n_ary      2_ops  395 + 913 =            1308       1308        True   \n12     n_ary      2_ops  661 + 800 =            1461       1461        True   \n13     n_ary      2_ops  262 + 254 =             516        516        True   \n14     n_ary      2_ops  244 + 977 =            1221       1221        True   \n15     n_ary      2_ops  433 + 105 =             538        538        True   \n16     n_ary      2_ops  594 + 781 =            1375       1375        True   \n17     n_ary      2_ops  587 + 573 =            1160       1160        True   \n18     n_ary      2_ops  191 + 618 =             809        809        True   \n19     n_ary      2_ops  682 + 984 =            1666       1666        True   \n\n     test_id  ut_steps        full_response  generation_time  \\\n0   79c641e4         4  [FINAL]  1427 [END]         7.343845   \n1   5ca9e316         4  [FINAL]  1647 [END]         7.282736   \n2   f45d66a6         4  [FINAL]  1088 [END]         7.396809   \n3   d333d682         4  [FINAL]  1205 [END]         7.325545   \n4   508bcc7b         4  [FINAL]  1230 [END]         7.398365   \n5   7d6f48ef         4   [FINAL]  939 [END]         7.536695   \n6   a04564cd         4  [FINAL]  1167 [END]         7.381354   \n7   2beef17d         4   [FINAL]  971 [END]         7.264401   \n8   ae954ab6         4  [FINAL]  1585 [END]         7.418374   \n9   cf933cbf         4  [FINAL]  1546 [END]         7.425260   \n10  3c7a8694         4  [FINAL]  1112 [END]         7.397378   \n11  1534f4e1         4  [FINAL]  1308 [END]         7.358744   \n12  acea4092         4  [FINAL]  1461 [END]         7.310169   \n13  c6d77350         4   [FINAL]  516 [END]         7.505051   \n14  7d21bd53         4  [FINAL]  1221 [END]         7.407103   \n15  7366764f         4   [FINAL]  538 [END]         7.256018   \n16  5af05db5         4  [FINAL]  1375 [END]         7.364811   \n17  f91c0ede         4  [FINAL]  1160 [END]         7.335002   \n18  be0bc17a         4   [FINAL]  809 [END]         7.207986   \n19  9c5642c0         4  [FINAL]  1666 [END]         7.375404   \n\n    generated_tokens  input_tokens  is_degenerate  \n0                  8           846          False  \n1                  8           846          False  \n2                  8           846          False  \n3                  8           846          False  \n4                  8           846          False  \n5                  7           846          False  \n6                  8           846          False  \n7                  7           846          False  \n8                  8           846          False  \n9                  8           846          False  \n10                 8           846          False  \n11                 8           846          False  \n12                 8           846          False  \n13                 7           846          False  \n14                 8           846          False  \n15                 7           846          False  \n16                 8           846          False  \n17                 8           846          False  \n18                 7           846          False  \n19                 8           846          False  \nFull Response:\n\n0      [FINAL]  1427 [END]\n1      [FINAL]  1647 [END]\n2      [FINAL]  1088 [END]\n3      [FINAL]  1205 [END]\n4      [FINAL]  1230 [END]\n              ...         \n604       [FINAL]  C [END]\n605       [FINAL]  D [END]\n606       [FINAL]  C [END]\n607       [FINAL]  C [END]\n608       [FINAL]  C [END]\nName: full_response, Length: 609, dtype: object\nPerplexity Report:\n\n   ut_steps  perplexity  avg_loss\n0         4     0.23606   1.26625\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(df_simple[[\"full_response\", \"generated_tokens\"]])","metadata":{"id":"EDWCUkMqnzBD","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:45:35.598916Z","iopub.execute_input":"2025-12-26T17:45:35.599211Z","iopub.status.idle":"2025-12-26T17:45:35.604936Z","shell.execute_reply.started":"2025-12-26T17:45:35.599188Z","shell.execute_reply":"2025-12-26T17:45:35.6044Z"}},"outputs":[{"name":"stdout","text":"           full_response  generated_tokens\n0    [FINAL]  1427 [END]                 8\n1    [FINAL]  1647 [END]                 8\n2    [FINAL]  1088 [END]                 8\n3    [FINAL]  1205 [END]                 8\n4    [FINAL]  1230 [END]                 8\n..                   ...               ...\n604     [FINAL]  C [END]                 4\n605     [FINAL]  D [END]                 4\n606     [FINAL]  C [END]                 4\n607     [FINAL]  C [END]                 4\n608     [FINAL]  C [END]                 4\n\n[609 rows x 2 columns]\n","output_type":"stream"}],"execution_count":11}]}