{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9fbf39d241464c88a2aadf9770c3d25c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7763ac32c74d4b03adb7cedf1a01246f","IPY_MODEL_6bbc043e134349dbb96be7b10808e228","IPY_MODEL_35edfcdd1e43499da64fe380fc65658d"],"layout":"IPY_MODEL_d2f91bbd0d824a5da986b5e862d4e3e6"}},"7763ac32c74d4b03adb7cedf1a01246f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73686c8852cf41ea8051ecb77bc7bfd2","placeholder":"​","style":"IPY_MODEL_c077b8a03915489e8d1190068d71ca77","value":"Calculating PPL (UT=2): 100%"}},"6bbc043e134349dbb96be7b10808e228":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1b0cf62dd2c48cf930f4edee17b3ae4","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_123cfefb7c3f42c08b4b273705cf7021","value":8}},"35edfcdd1e43499da64fe380fc65658d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a4139187f994638afb4c3dd16bd6075","placeholder":"​","style":"IPY_MODEL_43d49bb07ee94a13a396534b5b5f06c2","value":" 8/8 [00:32&lt;00:00,  2.98s/it]"}},"d2f91bbd0d824a5da986b5e862d4e3e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73686c8852cf41ea8051ecb77bc7bfd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c077b8a03915489e8d1190068d71ca77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1b0cf62dd2c48cf930f4edee17b3ae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123cfefb7c3f42c08b4b273705cf7021":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a4139187f994638afb4c3dd16bd6075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43d49bb07ee94a13a396534b5b5f06c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70ebaf718892484d838a274922e30b7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20ec6fa57cff4be0b65f4c9ff2605fb5","IPY_MODEL_35d0ac3608f14a7d983789d8923aece3","IPY_MODEL_ef140b21c65a4cd1a52a812f707e161e"],"layout":"IPY_MODEL_43adbc78740f4bdcae72652b6a856576"}},"20ec6fa57cff4be0b65f4c9ff2605fb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_713bb57df93b4f29bba2ae85a0cc3c83","placeholder":"​","style":"IPY_MODEL_fbf6849623a240ccafab471e71348b7e","value":"   n_ary: 100%"}},"35d0ac3608f14a7d983789d8923aece3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebe86fea791345e6bf1cb1c19def7be8","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fb164d6942e4f908a2e7c04f0ac1b17","value":63}},"ef140b21c65a4cd1a52a812f707e161e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22d5fa4877894391963a77c1389f7d64","placeholder":"​","style":"IPY_MODEL_43f2d20321494f4eaf5f100d39274815","value":" 63/63 [58:46&lt;00:00, 64.64s/it]"}},"43adbc78740f4bdcae72652b6a856576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"713bb57df93b4f29bba2ae85a0cc3c83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbf6849623a240ccafab471e71348b7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebe86fea791345e6bf1cb1c19def7be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb164d6942e4f908a2e7c04f0ac1b17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22d5fa4877894391963a77c1389f7d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f2d20321494f4eaf5f100d39274815":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7fbe1164613430cadbb70093eb6e3ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66d8438629254aabb0fdd938f71fe2e5","IPY_MODEL_1ff292986cb54ee8855e478a9a396114","IPY_MODEL_66b2423933234055904e1a74a993dfa9"],"layout":"IPY_MODEL_8e7206af70fa4b05aad6dd4bc00740eb"}},"66d8438629254aabb0fdd938f71fe2e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e089f88b17554494adb665c7b0581de4","placeholder":"​","style":"IPY_MODEL_ec2b08a1ca4e4c7fb950f63b1e93b850","value":"   p_hop:   1%"}},"1ff292986cb54ee8855e478a9a396114":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f82910cbbb5049398a11ced25a48c4fe","max":75,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c9b01e8c9994fd2b44c9016147ff048","value":1}},"66b2423933234055904e1a74a993dfa9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c0f9fb7a8f14061a7c6b9e2dc19bebf","placeholder":"​","style":"IPY_MODEL_6f2bfe2428bc46f8a7f6a104e22831df","value":" 1/75 [01:08&lt;1:11:36, 58.06s/it]"}},"8e7206af70fa4b05aad6dd4bc00740eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e089f88b17554494adb665c7b0581de4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec2b08a1ca4e4c7fb950f63b1e93b850":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f82910cbbb5049398a11ced25a48c4fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c9b01e8c9994fd2b44c9016147ff048":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c0f9fb7a8f14061a7c6b9e2dc19bebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f2bfe2428bc46f8a7f6a104e22831df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup libraries","metadata":{"id":"S0M-JZCdnzA6"}},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip uninstall -y transformers tokenizers accelerate -q\n!pip install \"transformers==4.56.0\" \"protobuf==5.29.3\" -q\n!pip install torch datasets -q\n!pip install pandas matplotlib seaborn tqdm wandb pyyaml\n!pip install bitsandbytes accelerate\n# !pip install -r requirements.txt\n!pip install --force-reinstall --no-cache-dir \"numpy<2.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"tjC_YOBlnzA-","outputId":"fd42e401-98d7-41f5-be54-4646405a4703","execution":{"iopub.status.busy":"2025-12-20T09:46:55.641478Z","iopub.execute_input":"2025-12-20T09:46:55.641718Z","iopub.status.idle":"2025-12-20T09:48:33.092965Z","shell.execute_reply.started":"2025-12-20T09:46:55.641688Z","shell.execute_reply":"2025-12-20T09:48:33.091820Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 5.29.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.3.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.5.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.12.4)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.15.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.3)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.36.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\nDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m125.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\nInstalling collected packages: bitsandbytes, accelerate\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [accelerate]2\u001b[0m [accelerate]\n\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0\nCollecting numpy<2.0\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Supress warnings","metadata":{}},{"cell_type":"code","source":"# Suppress warnings for clean output\nimport warnings\nimport os\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nos.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\nprint(\"✅ Packages installed successfully!\")","metadata":{"trusted":true,"id":"t3KSZamlnzA_","outputId":"522161e6-1868-4a71-ea99-e86bb812b3ff","execution":{"iopub.status.busy":"2025-12-20T09:48:33.095005Z","iopub.execute_input":"2025-12-20T09:48:33.095336Z","iopub.status.idle":"2025-12-20T09:48:33.103109Z","shell.execute_reply.started":"2025-12-20T09:48:33.095300Z","shell.execute_reply":"2025-12-20T09:48:33.102278Z"}},"outputs":[{"name":"stdout","text":"✅ Packages installed successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"code","source":"\"Built-in libraries\"\nimport re\nimport sys\nimport gc\nimport time\nimport json\nimport hashlib\nimport glob\nimport zipfile\nfrom io import StringIO\nfrom datetime import datetime\nfrom typing import Dict, List, Optional, Tuple, Any\nimport yaml\nimport logging\nimport random\n\n\"Deep learning and NLP libraries\"\nimport torch\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    GenerationConfig,\n    logging as hf_logging\n)\n\n\"Data processing libraries\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport wandb\nfrom tqdm.auto import tqdm\nfrom IPython import get_ipython\n\n# Configure logging\nlogging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\nhf_logging.set_verbosity_error()\n\n\nprint(f\"Python Version: {sys.version}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA Version: {torch.version.cuda}\")\n!nvidia-smi","metadata":{"trusted":true,"id":"vW3-Anw9nzBA","outputId":"498fcb76-e384-4afe-8c0c-23b4e0dc79e8","execution":{"iopub.status.busy":"2025-12-20T09:48:33.103572Z","iopub.execute_input":"2025-12-20T09:48:33.103724Z","iopub.status.idle":"2025-12-20T09:48:44.212360Z","shell.execute_reply.started":"2025-12-20T09:48:33.103711Z","shell.execute_reply":"2025-12-20T09:48:44.211408Z"}},"outputs":[{"name":"stdout","text":"Python Version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch Version: 2.6.0+cu124\nCUDA Available: True\nCUDA Version: 12.4\nSat Dec 20 09:48:44 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   45C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   47C    P8             12W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"✅ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"✅ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"⚠️ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"⚠️ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"📂 Data Path: {base_data_path}\")\n    print(f\"📦 Output Path: {base_output_path}\")\n\n    return base_data_path, base_output_path, environment_name\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T09:48:44.213392Z","iopub.execute_input":"2025-12-20T09:48:44.213657Z","iopub.status.idle":"2025-12-20T09:48:44.221214Z","shell.execute_reply.started":"2025-12-20T09:48:44.213632Z","shell.execute_reply":"2025-12-20T09:48:44.220530Z"}},"outputs":[{"name":"stdout","text":"✅ Environment: Kaggle\n📂 Data Path: /kaggle/input/\n📦 Output Path: /kaggle/working/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Setup WANDB","metadata":{}},{"cell_type":"code","source":"import os\nimport wandb\n\nif \"colab\" in ENV_NAME:\n    from google.colab import userdata\n    try:\n        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n        wandb_key = userdata.get('WANDB_API_KEY')\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n\n# 2. Check if running in Kaggle\nelif \"kaggle\" in ENV_NAME:\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")","metadata":{"trusted":true,"id":"UaOteqd3nzBA","outputId":"369dec93-b504-4e04-ce1f-25ab2f601812","execution":{"iopub.status.busy":"2025-12-20T09:48:44.221971Z","iopub.execute_input":"2025-12-20T09:48:44.222857Z","iopub.status.idle":"2025-12-20T09:48:51.356468Z","shell.execute_reply.started":"2025-12-20T09:48:44.222832Z","shell.execute_reply":"2025-12-20T09:48:51.355701Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Config input/output path and clone latest repo","metadata":{"id":"wDA1HyzsnzA_"}},{"cell_type":"code","source":"# Clone the latest github repo version\n%cd {OUTPUT_PATH}\ntorch.cuda.empty_cache()\n!rm -r -f OuroTrace\n!git clone --branch claude https://github.com/dzungphieuluuky/OuroTrace.git\n%cd OuroTrace","metadata":{"trusted":true,"id":"qyaPdq3RnzA8","outputId":"a4660379-f32f-43c2-bb67-5e8127ce5016","execution":{"iopub.status.busy":"2025-12-20T09:48:51.357116Z","iopub.execute_input":"2025-12-20T09:48:51.357520Z","iopub.status.idle":"2025-12-20T09:48:52.276156Z","shell.execute_reply.started":"2025-12-20T09:48:51.357500Z","shell.execute_reply":"2025-12-20T09:48:52.275408Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'OuroTrace'...\nremote: Enumerating objects: 1148, done.\u001b[K\nremote: Counting objects: 100% (158/158), done.\u001b[K\nremote: Compressing objects: 100% (112/112), done.\u001b[K\nremote: Total 1148 (delta 100), reused 92 (delta 46), pack-reused 990 (from 2)\u001b[K\nReceiving objects: 100% (1148/1148), 1.63 MiB | 11.69 MiB/s, done.\nResolving deltas: 100% (765/765), done.\n/kaggle/working/OuroTrace\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Run Benchmark","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom src.config_loader import load_config_from_json, post_process_config\n\n# this is the fused version when single and batch use the same predict function\nfrom src.new_runner import run_batch_experiment\n\n# this is the original version when single and batch use different functions\n# from src.runner import run_batch_experiment\n\nfrom src.evaluation import analyze_experiment_results\n\n\n# 1. Load Configuration from JSON\nconfig = load_config_from_json('configs/batch_ouro_1.4b_thinking.json')\n\n# 2. Post-process (Convert 'torch.float16' string to object, generate timestamps)\nconfig = post_process_config(config)\n\nconfig[\"INFERENCE_STEPS\"] = [2]\n# 4. Execute\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nprint(f\"🕒 Timestamp: {timestamp}\")\nprint(\"🚀 Starting Experiment...\")\ntry:\n  acc_results, ppl_results, hol_results = run_batch_experiment(config)\nexcept Exception as e:\n  print(f\"An unexpected error occurred: {e}\")","metadata":{"trusted":true,"id":"CKc8czt-nzBB","outputId":"e0556823-e947-4297-d039-6202d1dfd2f6","execution":{"iopub.status.busy":"2025-12-20T09:48:52.278645Z","iopub.execute_input":"2025-12-20T09:48:52.279343Z","iopub.status.idle":"2025-12-20T09:52:55.704880Z","shell.execute_reply.started":"2025-12-20T09:48:52.279309Z","shell.execute_reply":"2025-12-20T09:52:55.704141Z"}},"outputs":[{"name":"stdout","text":"🕒 Timestamp: 20251220_094852\n🚀 Starting Experiment...\n🔗 Initializing W&B (timeout: 30s)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251220_094852-kz3yxzl1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/kz3yxzl1' target=\"_blank\">dandy-paper-11</a></strong> to <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/kz3yxzl1' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/kz3yxzl1</a>"},"metadata":{}},{"name":"stdout","text":"✅ W&B initialized\n\n======================================================================\n🔧 EXPERIMENT CONFIGURATION\n======================================================================\nModel Path: ByteDance/Ouro-1.4B-Thinking\nUT Steps to Test: [2]\nData Type: torch.bfloat16\n4-bit Quantization: False\nTorch Compile: False\nMax Batch Size: 12\nMax New Tokens: 512\nBatching: True\nCalculate Perplexity: True\nEarly Exit: 1.0\n======================================================================\n\n[+] Quality monitor initialized:\n    → Garbage threshold: 30%\n    → Example similarity threshold: 85%\n    → Min samples before check: 10\n🎲 Random seed set to 42\n\n======================================================================\n📦 LOADING TEST DATASETS\n======================================================================\n⚙️ Generating new test datasets...\n✅ Generated test datasets\n\nDataset Summary:\n   n_ary       :  500 samples\n   p_hop       :  300 samples\n   igsm        :  100 samples\n======================================================================\n\n\n======================================================================\n📋 PAPER COMPLIANCE CHECK\n======================================================================\nTask Alignment: {'has_n_ary': True, 'has_p_hop': True, 'has_igsm': True, 'all_paper_tasks': True}\nUT Steps Coverage: {'min_ut': 2, 'max_ut': 2, 'covers_baseline': False, 'covers_paper_range': False, 'recommended_range': [1, 2, 4, 8]}\n======================================================================\n\n📚 Preparing perplexity evaluation data...\n✅ Prepared 50 samples for PPL\n\n✅ Configuration saved to ./results_20251220_094858/config.yaml\n\n======================================================================\n🧪 EXPERIMENT 1/1: UT Steps = 2\n======================================================================\n\n⚙️  AUTO-OPTIMIZATION SETTINGS:\n   Batch Processing: ✅ ENABLED\n   Torch Compile: ❌ DISABLED\n   NOTE: torch.compile is not the culprit, batching with generate(), not with generate_batch() function.\n\n\n============================================================\n⚙️  LOADING MODEL CONFIGURATION\n============================================================\nModel Path: ByteDance/Ouro-1.4B-Thinking\nRequested UT Steps: 2\nData Type: torch.bfloat16\n4-bit Quantization: False\nTorch Compile: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a449be4a340c429a9cd7327a480dc2b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_ouro.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71294bc2687b4355b9c974b40633978f"}},"metadata":{}},{"name":"stdout","text":"\n→ Base config loaded\n   Original UT steps: 4\n   Original early exit: 1.0\n\n→ Modified config:\n   New UT steps: 2\n   Early exit threshold: 1.0 (from default)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc3ab90e3a254b9bb5d0cb4c4cd8e596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f7d9896ac64781aa86ae0d4079994b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779a868b08fa43598fd808c287f56fba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1eb4e77d839437089d49f3be3b39439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3683de55fc4255bedd4a66fc5a91a1"}},"metadata":{}},{"name":"stdout","text":"\n→ Tokenizer loaded\n   Vocab size: 49152\n   PAD token: <|im_end|>\n   EOS token: <|im_end|>\n\n→ Loading model weights...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_ouro.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fead0b1d708c476a9d6681fc60c2780f"}},"metadata":{}},{"name":"stderr","text":"2025-12-20 09:49:02.624852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766224142.802798      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766224142.855007      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26412211bf264830bf3f5144efb6f744"}},"metadata":{}},{"name":"stdout","text":"\n────────────────────────────────────────────────────────────\n🚀 APPLYING SAFE OPTIMIZATIONS (UT > 1)\n────────────────────────────────────────────────────────────\n   ✓ Flash Attention / SDPA enabled\n   ✓ TF32 enabled for matmul\n   ✓ cuDNN auto-tuning enabled\n   ✓ Memory pool optimized\n   → Running 3 warmup passes...\n   ✓ Warmup complete\n────────────────────────────────────────────────────────────\n\n============================================================\n✅ MODEL LOADED SUCCESSFULLY\n============================================================\nDevice: cuda:0\nModel dtype: torch.bfloat16\nVERIFIED UT steps: 2\nVERIFIED early exit: 1.0\n============================================================\n\n🔧 Building task templates...\n[+] Task templates (strict hybrid) pre-computed.\n✅ Task templates built\n\n\n======================================================================\n📉 PERPLEXITY EVALUATION\n======================================================================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating PPL (UT=2):   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ade4f24c5ca44585ab6d761e25d0cf45"}},"metadata":{}},{"name":"stdout","text":"\n✅ Perplexity Results:\n   Perplexity: 0.5556\n   Avg Loss:   1.7430\n\n======================================================================\n🎯 ACCURACY EVALUATION\n======================================================================\n\n\n──────────────────────────────────────────────────────────────────────\n📝 Task: N_ARY\n──────────────────────────────────────────────────────────────────────\nTotal Samples: 500\nBatch Size: 8\nStrategy: Batched Processing\n\nRunning 63 batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   n_ary:   0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"994753504d6442f898714253711334f9"}},"metadata":{}},{"name":"stdout","text":"DEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n428 + 297 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n815 + 917 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n364 + 845 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n494 + 032 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n889 + 304 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n348 + 218 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n575 + 474 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n393 + 052 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\n    test_input                                      full_response  \\\n0  428 + 297 =  0. Sum: 0\\n 1. Add 428: 428 + 277 = 705\\n2. Ad...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  815 + 917 =  0. Sum: 0\\n 1. Add 815: 815 + 815 = 1630\\n2. A...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  364 + 845 =  0. Sum: 0\\n 1. Add 364: 364 + 0 = 364\\n2. Add ...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  494 + 032 =  0. Sum: 0\\n 1. Add 494: 0 + 494 = 494\\n2. Add ...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  889 + 304 =  0. Sum: 0\\n 1. Add 899: 0 + 899 = 899\\n2. Add ...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  348 + 218 =  0. Sum: 0\\n 1. Add 348: 348\\n2. Add 218: 566\\n...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  575 + 474 =  0. Sum: 0\\n 1. Add 575: 575 + 474 = 1049\\n2. A...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  393 + 052 =  0. Sum: 0\\n 1. Add 393: 0 + 393 = 393\\n2. Add ...   \n\n   generated_tokens  \n0               256  \nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n685 + 144 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n271 + 675 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n567 + 156 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n462 + 307 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n777 + 709 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n634 + 981 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n564 + 243 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n494 + 949 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\n    test_input                                      full_response  \\\n0  685 + 144 =  0. Sum: 0\\n 1. Add 685: 685\\n2. Add 144: 739\\n...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  271 + 675 =  0. Sum: 0\\n 1. Add 211: 211\\n2. Add 675: 211 +...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  567 + 156 =  0. Sum: 0\\n 1. Add 567: 567 + 567 = 1134\\n2. A...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  462 + 307 =  0. Sum: 0\\n 1. Add 462: 462 + 307 = 769\\n2. Ad...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  777 + 709 =  0. Sum: 0\\n 1. Add 777: 0 + 777 = 777\\n2. Add ...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  634 + 981 =  0. Sum: 0\\n 1. Add 634: 634 + 981 = 1615\\n2. A...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  564 + 243 =  0. Sum: 0\\n 1. Add 564: 564 + 233 = 797\\n2. Ad...   \n\n   generated_tokens  \n0               256  \n    test_input                                      full_response  \\\n0  494 + 949 =  0. Sum: 0\\n 1. Add 494: 494 + 494 = 988\\n2. Ad...   \n\n   generated_tokens  \n0               256  \nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n578 + 575 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n493 + 152 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n303 + 068 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n924 + 651 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n627 + 842 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n644 + 249 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n627 + 825 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\nDEBUG: Full prompt for 'n_ary':\n<|im_start|>system\nYou are a mechanical calculation engine.Given an addition problem with {number of numbers given in the input} numbers (e.g., '{number_1} + {number_2} + ... + {number_N} ='), Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps. For each number, add it to the running total and show the calculation. Only perform calculation for {number of numbers given in the input} steps. Output only the final sum on a new line in this format: [FINAL] {final_sum}.\nDO NOT COPY EXACTLY EXAMPLE, SUBSTITUTE WITH PROVIDED NUMBERS AND STEPS ONLY.\nExample:\nInput: {number_1} + {number_2} + ... + {number_N} =\nOutput:\n0. Sum: 0\n...\n{i}. Add {number_i}: {sum_{i-1}} + {number_i} = {sum_i}\n{i + 1}. Add {number_{i+1}}: {sum_i} + {number_{i+1}} = {sum_{i+1}}\n{i + 2}. Add {number_{i+2}}: {sum_{i+1}} + {number_{i+2}} = {sum_{i+2}}\n...\n{final step}. Add {number_N}: {sum_{N-1}} + {number_N} = {final_sum}\n[FINAL] {final_sum}<|im_end|>\n<|im_start|>user\n032 + 630 =<|im_end|>\n<|im_start|>assistant\n0. Sum: 0\n\n\n   ✓ Chat format verified for input.\n\n======================================================================\n❌ EXPERIMENT INTERRUPTED BY USER\n======================================================================\n\n✅ Periodic save: all results to ./results_20251220_094858/all_latest.csv\n✅ Periodic save: perplexity results to ./results_20251220_094858/perplexity_latest.csv\n✅ Configuration saved to ./results_20251220_094858/config.yaml\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport glob\nimport zipfile\n\ndef zip_all_results_folders(output_base_path: str):\n    os.makedirs(output_base_path, exist_ok=True)\n\n    search_pattern = os.path.join(output_base_path, \"results_*\")\n    results_folders = glob.glob(search_pattern)\n    results_directories = [d for d in results_folders if os.path.isdir(d)]\n\n    if not results_directories:\n        print(f\"⚠️ Không tìm thấy thư mục nào bắt đầu bằng 'results_' trong '{output_base_path}'.\")\n        return\n\n    print(f\"🔍 Tìm thấy {len(results_directories)} thư mục kết quả để nén.\")\n\n    successful_zips = 0\n\n    for folder_path in results_directories:\n        folder_name = os.path.basename(folder_path)\n        zip_filename = os.path.join(output_base_path, f\"{folder_name}.zip\")\n\n        try:\n            print(f\"\\n   -> Đang nén thư mục: {folder_name}...\")\n\n            with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n                for root, _, files in os.walk(folder_path):\n                    for file in files:\n                        file_path = os.path.join(root, file)\n                        arcname = os.path.relpath(file_path, os.path.dirname(folder_path))\n                        zipf.write(file_path, arcname)\n\n            print(f\"   ✅ Đã tạo file ZIP: {os.path.basename(zip_filename)}\")\n            successful_zips += 1\n\n        except Exception as e:\n            print(f\"   ❌ Lỗi khi nén thư mục {folder_name}: {e}\")\n\n    print(f\"\\n✅ HOÀN TẤT! Đã nén thành công {successful_zips} trên {len(results_directories)} thư mục kết quả.\")\n\n\ntry:\n    if 'OUTPUT_PATH' in globals():\n        zip_all_results_folders(os.path.join(OUTPUT_PATH, \"OuroTrace\"))\n    else:\n        print(\"OUTPUT_PATH not defined.\")\n\nexcept NameError:\n    print(\"OUTPUT_PATH not defined.\")\nexcept Exception as e:\n    print(f\"Đã xảy ra lỗi trong quá trình nén: {e}\")","metadata":{"trusted":true,"id":"8inXWmVwnzBC","outputId":"9416f1d8-5521-4860-f432-9ddcd4c6f2c1","execution":{"iopub.status.busy":"2025-12-20T09:52:55.706429Z","iopub.execute_input":"2025-12-20T09:52:55.706654Z","iopub.status.idle":"2025-12-20T09:52:55.718084Z","shell.execute_reply.started":"2025-12-20T09:52:55.706635Z","shell.execute_reply":"2025-12-20T09:52:55.717419Z"}},"outputs":[{"name":"stdout","text":"🔍 Tìm thấy 1 thư mục kết quả để nén.\n\n   -> Đang nén thư mục: results_20251220_094858...\n   ✅ Đã tạo file ZIP: results_20251220_094858.zip\n\n✅ HOÀN TẤT! Đã nén thành công 1 trên 1 thư mục kết quả.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 3. Save Results\ndf_acc = pd.DataFrame(acc_results)\ndf_ppl = pd.DataFrame(ppl_results)\ndf_hol = pd.DataFrame(hol_results)\n# 4. Visualization & Reporting\nif not df_acc.empty:\n    print(\"\\n\" + \"=\"*50 + \"\\n📊 VISUALIZATION\\n\" + \"=\"*50)\n\n    # Summary Tables\n    # NOTE: The variable 'results_acc' is used here, assuming it holds the raw data\n    # (list of dicts) required by 'analyze_experiment_results'.\n    summary = analyze_experiment_results(acc_results)\n    print(\"\\n--- Summary Statistics ---\")\n    print(summary)\n\n    # Plotting\n    try:\n        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n        # Plot 1: Accuracy\n        acc_summary = df_acc.groupby(['task_type', 'ut_steps'])['is_correct'].mean().reset_index()\n        sns.barplot(data=acc_summary, x='ut_steps', y='is_correct', hue='task_type', ax=axes[0])\n        axes[0].set_title('Accuracy by UT Steps')\n        axes[0].set_ylabel('Accuracy')\n        axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n\n        # Plot 2: Time\n        time_summary = df_acc.groupby(['task_type', 'ut_steps'])['generation_time'].mean().reset_index()\n        sns.barplot(data=time_summary, x='ut_steps', y='generation_time', hue='task_type', ax=axes[1])\n        axes[1].set_title('Inference Time (s) by UT Steps')\n\n        # Plot 3: Token Count\n        sns.boxplot(data=df_acc, x='ut_steps', y='generated_tokens', hue='task_type', ax=axes[2])\n        axes[2].set_title('Generated Tokens Distribution')\n\n        plt.tight_layout()\n        plt.show()\n\n    except Exception as e:\n        print(f\"⚠️ Visualization error: {e}\")\nelse:\n    print(\"⚠️ No results to visualize.\")\n\nprint(\"\\n🏁 Experiment Complete.\\n\")","metadata":{"trusted":true,"id":"0p4QBYsDnzBB","outputId":"99bd859f-1dcd-4a45-9d67-ad7805642c5b","execution":{"iopub.status.busy":"2025-12-20T09:52:55.718864Z","iopub.execute_input":"2025-12-20T09:52:55.719379Z","iopub.status.idle":"2025-12-20T09:52:56.196305Z","shell.execute_reply.started":"2025-12-20T09:52:55.719356Z","shell.execute_reply":"2025-12-20T09:52:56.195557Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\n📊 VISUALIZATION\n==================================================\n\n--- Summary Statistics ---\n                    is_correct_mean  is_correct_count  is_correct_std  \\\nut_steps task_type                                                      \n2        n_ary                  0.0                16             0.0   \n\n                    generation_time_mean  generation_time_min  \\\nut_steps task_type                                              \n2        n_ary                     8.941                 8.89   \n\n                    generation_time_max  generated_tokens_mean  \nut_steps task_type                                              \n2        n_ary                    8.993                  256.0  \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:645: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  g_vals = grouped_vals.get_group(g)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x500 with 3 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n🏁 Experiment Complete.\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(\"Final Inspection:\\n\")\nprint(\"Top 20 Accuracy Report:\\n\")\nprint(df_acc.head(20))\nprint(f\"Full Response:\\n\")\nprint(df_acc['full_response'])\nprint(\"Perplexity Report:\\n\")\nprint(df_ppl.head(20))","metadata":{"trusted":true,"id":"3zpz9ccInzBD","execution":{"iopub.status.busy":"2025-12-20T09:52:56.197123Z","iopub.execute_input":"2025-12-20T09:52:56.197415Z","iopub.status.idle":"2025-12-20T09:52:56.210232Z","shell.execute_reply.started":"2025-12-20T09:52:56.197397Z","shell.execute_reply":"2025-12-20T09:52:56.209556Z"}},"outputs":[{"name":"stdout","text":"Final Inspection:\n\nTop 20 Accuracy Report:\n\n   task_type difficulty   test_input expected_answer prediction  is_correct  \\\n0      n_ary      2_ops  428 + 297 =             725        277       False   \n1      n_ary      2_ops  815 + 917 =            1732       4399       False   \n2      n_ary      2_ops  364 + 845 =            1209          0       False   \n3      n_ary      2_ops  494 + 032 =             526         12       False   \n4      n_ary      2_ops  889 + 304 =            1193        158       False   \n5      n_ary      2_ops  348 + 218 =             566        687       False   \n6      n_ary      2_ops  575 + 474 =            1049          4       False   \n7      n_ary      2_ops  393 + 052 =             445         12       False   \n8      n_ary      2_ops  685 + 144 =             829       2909       False   \n9      n_ary      2_ops  271 + 675 =             946         11       False   \n10     n_ary      2_ops  567 + 156 =             723      10320       False   \n11     n_ary      2_ops  462 + 307 =             769         30       False   \n12     n_ary      2_ops  777 + 709 =            1486      14540       False   \n13     n_ary      2_ops  634 + 981 =            1615         11       False   \n14     n_ary      2_ops  564 + 243 =             807        233       False   \n15     n_ary      2_ops  494 + 949 =            1443      25292       False   \n\n     test_id  ut_steps                                      full_response  \\\n0   32c2a55f         2  0. Sum: 0\\n 1. Add 428: 428 + 277 = 705\\n2. Ad...   \n1   8021f982         2  0. Sum: 0\\n 1. Add 815: 815 + 815 = 1630\\n2. A...   \n2   224fc664         2  0. Sum: 0\\n 1. Add 364: 364 + 0 = 364\\n2. Add ...   \n3   da02d8d8         2  0. Sum: 0\\n 1. Add 494: 0 + 494 = 494\\n2. Add ...   \n4   0fcc152e         2  0. Sum: 0\\n 1. Add 899: 0 + 899 = 899\\n2. Add ...   \n5   cf3f4d60         2  0. Sum: 0\\n 1. Add 348: 348\\n2. Add 218: 566\\n...   \n6   d5419870         2  0. Sum: 0\\n 1. Add 575: 575 + 474 = 1049\\n2. A...   \n7   6fce64a7         2  0. Sum: 0\\n 1. Add 393: 0 + 393 = 393\\n2. Add ...   \n8   5ffb1a83         2  0. Sum: 0\\n 1. Add 685: 685\\n2. Add 144: 739\\n...   \n9   908f458d         2  0. Sum: 0\\n 1. Add 211: 211\\n2. Add 675: 211 +...   \n10  09e96ac8         2  0. Sum: 0\\n 1. Add 567: 567 + 567 = 1134\\n2. A...   \n11  a7cee393         2  0. Sum: 0\\n 1. Add 462: 462 + 307 = 769\\n2. Ad...   \n12  33e3d764         2  0. Sum: 0\\n 1. Add 777: 0 + 777 = 777\\n2. Add ...   \n13  7efd4a53         2  0. Sum: 0\\n 1. Add 634: 634 + 981 = 1615\\n2. A...   \n14  f6b4a5c9         2  0. Sum: 0\\n 1. Add 564: 564 + 233 = 797\\n2. Ad...   \n15  2032c1ad         2  0. Sum: 0\\n 1. Add 494: 494 + 494 = 988\\n2. Ad...   \n\n    generation_time  generated_tokens  input_tokens  is_degenerate  \n0          8.889529               256           365          False  \n1          8.889529               256           365          False  \n2          8.889529               256           365          False  \n3          8.889529               256           365          False  \n4          8.889529               256           365          False  \n5          8.889529               256           365          False  \n6          8.889529               256           365          False  \n7          8.889529               256           365          False  \n8          8.992988               256           365          False  \n9          8.992988               256           365          False  \n10         8.992988               256           365          False  \n11         8.992988               256           365          False  \n12         8.992988               256           365          False  \n13         8.992988               256           365          False  \n14         8.992988               256           365          False  \n15         8.992988               256           365          False  \nFull Response:\n\n0     0. Sum: 0\\n 1. Add 428: 428 + 277 = 705\\n2. Ad...\n1     0. Sum: 0\\n 1. Add 815: 815 + 815 = 1630\\n2. A...\n2     0. Sum: 0\\n 1. Add 364: 364 + 0 = 364\\n2. Add ...\n3     0. Sum: 0\\n 1. Add 494: 0 + 494 = 494\\n2. Add ...\n4     0. Sum: 0\\n 1. Add 899: 0 + 899 = 899\\n2. Add ...\n5     0. Sum: 0\\n 1. Add 348: 348\\n2. Add 218: 566\\n...\n6     0. Sum: 0\\n 1. Add 575: 575 + 474 = 1049\\n2. A...\n7     0. Sum: 0\\n 1. Add 393: 0 + 393 = 393\\n2. Add ...\n8     0. Sum: 0\\n 1. Add 685: 685\\n2. Add 144: 739\\n...\n9     0. Sum: 0\\n 1. Add 211: 211\\n2. Add 675: 211 +...\n10    0. Sum: 0\\n 1. Add 567: 567 + 567 = 1134\\n2. A...\n11    0. Sum: 0\\n 1. Add 462: 462 + 307 = 769\\n2. Ad...\n12    0. Sum: 0\\n 1. Add 777: 0 + 777 = 777\\n2. Add ...\n13    0. Sum: 0\\n 1. Add 634: 634 + 981 = 1615\\n2. A...\n14    0. Sum: 0\\n 1. Add 564: 564 + 233 = 797\\n2. Ad...\n15    0. Sum: 0\\n 1. Add 494: 494 + 494 = 988\\n2. Ad...\nName: full_response, dtype: object\nPerplexity Report:\n\n   ut_steps  perplexity  avg_loss\n0         2    0.555596   1.74298\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(df_acc[['full_response', 'generated_tokens']])","metadata":{"trusted":true,"id":"EDWCUkMqnzBD","execution":{"iopub.status.busy":"2025-12-20T09:52:56.210961Z","iopub.execute_input":"2025-12-20T09:52:56.211264Z","iopub.status.idle":"2025-12-20T09:52:56.220857Z","shell.execute_reply.started":"2025-12-20T09:52:56.211241Z","shell.execute_reply":"2025-12-20T09:52:56.220101Z"}},"outputs":[{"name":"stdout","text":"                                        full_response  generated_tokens\n0   0. Sum: 0\\n 1. Add 428: 428 + 277 = 705\\n2. Ad...               256\n1   0. Sum: 0\\n 1. Add 815: 815 + 815 = 1630\\n2. A...               256\n2   0. Sum: 0\\n 1. Add 364: 364 + 0 = 364\\n2. Add ...               256\n3   0. Sum: 0\\n 1. Add 494: 0 + 494 = 494\\n2. Add ...               256\n4   0. Sum: 0\\n 1. Add 899: 0 + 899 = 899\\n2. Add ...               256\n5   0. Sum: 0\\n 1. Add 348: 348\\n2. Add 218: 566\\n...               256\n6   0. Sum: 0\\n 1. Add 575: 575 + 474 = 1049\\n2. A...               256\n7   0. Sum: 0\\n 1. Add 393: 0 + 393 = 393\\n2. Add ...               256\n8   0. Sum: 0\\n 1. Add 685: 685\\n2. Add 144: 739\\n...               256\n9   0. Sum: 0\\n 1. Add 211: 211\\n2. Add 675: 211 +...               256\n10  0. Sum: 0\\n 1. Add 567: 567 + 567 = 1134\\n2. A...               256\n11  0. Sum: 0\\n 1. Add 462: 462 + 307 = 769\\n2. Ad...               256\n12  0. Sum: 0\\n 1. Add 777: 0 + 777 = 777\\n2. Add ...               256\n13  0. Sum: 0\\n 1. Add 634: 634 + 981 = 1615\\n2. A...               256\n14  0. Sum: 0\\n 1. Add 564: 564 + 233 = 797\\n2. Ad...               256\n15  0. Sum: 0\\n 1. Add 494: 494 + 494 = 988\\n2. Ad...               256\n","output_type":"stream"}],"execution_count":11}]}