{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0M-JZCdnzA6"
   },
   "source": [
    "# Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:03.431251Z",
     "iopub.status.busy": "2025-12-25T11:17:03.431023Z",
     "iopub.status.idle": "2025-12-25T11:17:34.827259Z",
     "shell.execute_reply": "2025-12-25T11:17:34.826531Z",
     "shell.execute_reply.started": "2025-12-25T11:17:03.431233Z"
    },
    "id": "tjC_YOBlnzA-",
    "outputId": "165b0cba-ea3d-4e15-c4a1-0954e75fd821",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 116ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 272ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 224ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 32ms\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 325ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m95 packages\u001b[0m \u001b[2min 2.71s\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m21 packages\u001b[0m \u001b[2min 5.60s\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m21 packages\u001b[0m \u001b[2min 385ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.49.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdataproperty\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonlines\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlm-eval\u001b[0m\u001b[2m==0.4.9.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmbstrdecoder\u001b[0m\u001b[2m==1.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpathvalidate\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mportalocker\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpybind11\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytablewriter\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrouge-score\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msacrebleu\u001b[0m\u001b[2m==2.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlitedict\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabledata\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtcolorpy\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm-multiprocess\u001b[0m\u001b[2m==0.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtypepy\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mword2number\u001b[0m\u001b[2m==1.1\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `lm-eval==0.4.9.2` does not have an extra named `hf`\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 71ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 571ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 30ms\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --upgrade pip\n",
    "!uv pip uninstall transformers tokenizers accelerate -q\n",
    "\n",
    "!uv pip install \"transformers==4.56.0\" \"protobuf==5.29.3\" -q\n",
    "!uv pip install torch datasets -q\n",
    "!uv pip install pandas matplotlib seaborn tqdm wandb pyyaml\n",
    "!uv pip install bitsandbytes accelerate optimum lm_eval\n",
    "# !uv pip install -r requirements.txt\n",
    "!uv pip install --force-reinstall --no-cache-dir \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t_XpUsOs_my"
   },
   "source": [
    "# Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:34.829419Z",
     "iopub.status.busy": "2025-12-25T11:17:34.829187Z",
     "iopub.status.idle": "2025-12-25T11:17:34.834381Z",
     "shell.execute_reply": "2025-12-25T11:17:34.833647Z",
     "shell.execute_reply.started": "2025-12-25T11:17:34.829397Z"
    },
    "id": "t3KSZamlnzA_",
    "outputId": "e3a7fd5d-40bf-49e4-81fe-96bad3ed24da",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings for clean output\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abWE_VV3s_my"
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:34.835684Z",
     "iopub.status.busy": "2025-12-25T11:17:34.835396Z",
     "iopub.status.idle": "2025-12-25T11:17:47.230684Z",
     "shell.execute_reply": "2025-12-25T11:17:47.229853Z",
     "shell.execute_reply.started": "2025-12-25T11:17:34.835659Z"
    },
    "id": "vW3-Anw9nzBA",
    "outputId": "72b3ea8c-a30a-4f87-e580-59b5b4a7a5ae",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "PyTorch Version: 2.9.0+cu126\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.6\n",
      "Thu Dec 25 13:26:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\"Built-in libraries\"\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import glob\n",
    "import zipfile\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import yaml\n",
    "import logging\n",
    "import random\n",
    "\n",
    "\"Deep learning and NLP libraries\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    "    logging as hf_logging,\n",
    ")\n",
    "\n",
    "\"Data processing libraries\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Configure logging\n",
    "logging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.231998Z",
     "iopub.status.busy": "2025-12-25T11:17:47.231679Z",
     "iopub.status.idle": "2025-12-25T11:17:47.239769Z",
     "shell.execute_reply": "2025-12-25T11:17:47.239092Z",
     "shell.execute_reply.started": "2025-12-25T11:17:47.231969Z"
    },
    "id": "NxqV6hTMs_mz",
    "outputId": "9b99e289-e5a7-47d6-e8cd-c60745dd46db",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment: Google Colab\n",
      "üìÇ Data Path: /content/\n",
      "üì¶ Output Path: /content/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def configure_environment_paths():\n",
    "    \"\"\"Detect environment and configure paths\"\"\"\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            print(\"‚úÖ Environment: Google Colab\")\n",
    "            base_data_path = \"/content/\"\n",
    "            base_output_path = \"/content/\"\n",
    "            environment_name = \"colab\"\n",
    "        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "            print(\"‚úÖ Environment: Kaggle\")\n",
    "            base_data_path = \"/kaggle/input/\"\n",
    "            base_output_path = \"/kaggle/working/\"\n",
    "            environment_name = \"kaggle\"\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n",
    "            base_data_path = \"./data/\"\n",
    "            base_output_path = \"./output/\"\n",
    "            environment_name = \"local\"\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n",
    "        base_data_path = \"./data/\"\n",
    "        base_output_path = \"./output/\"\n",
    "        environment_name = \"local\"\n",
    "\n",
    "    os.makedirs(base_output_path, exist_ok=True)\n",
    "    print(f\"üìÇ Data Path: {base_data_path}\")\n",
    "    print(f\"üì¶ Output Path: {base_output_path}\")\n",
    "\n",
    "    return base_data_path, base_output_path, environment_name\n",
    "\n",
    "\n",
    "INPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0HV8HMrs_mz"
   },
   "source": [
    "# Setup WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:47.240709Z",
     "iopub.status.busy": "2025-12-25T11:17:47.240471Z",
     "iopub.status.idle": "2025-12-25T11:17:54.415266Z",
     "shell.execute_reply": "2025-12-25T11:17:54.414638Z",
     "shell.execute_reply.started": "2025-12-25T11:17:47.240693Z"
    },
    "id": "UaOteqd3nzBA",
    "outputId": "6cb717ca-fdce-47c6-c21c-0e693a1c64cd",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "if \"colab\" in ENV_NAME:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    try:\n",
    "        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n",
    "        wandb_key = userdata.get(\"WANDB_API_KEY\")\n",
    "        wandb.login(key=wandb_key)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n",
    "\n",
    "# 2. Check if running in Kaggle\n",
    "elif \"kaggle\" in ENV_NAME:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "        user_secrets = UserSecretsClient()\n",
    "        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "        wandb.login(key=wandb_key)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDA1HyzsnzA_"
   },
   "source": [
    "# Config input/output path and clone latest repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:54.416439Z",
     "iopub.status.busy": "2025-12-25T11:17:54.415975Z",
     "iopub.status.idle": "2025-12-25T11:17:54.549805Z",
     "shell.execute_reply": "2025-12-25T11:17:54.549139Z",
     "shell.execute_reply.started": "2025-12-25T11:17:54.416419Z"
    },
    "id": "qyaPdq3RnzA8",
    "outputId": "e31b5d1f-273e-4e55-c94e-cf3cbc4e0392",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "# Clone the latest github repo version\n",
    "%cd {OUTPUT_PATH}\n",
    "torch.cuda.empty_cache()\n",
    "!rm -rf OuroTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:54.552662Z",
     "iopub.status.busy": "2025-12-25T11:17:54.552387Z",
     "iopub.status.idle": "2025-12-25T11:17:55.598028Z",
     "shell.execute_reply": "2025-12-25T11:17:55.597311Z",
     "shell.execute_reply.started": "2025-12-25T11:17:54.552627Z"
    },
    "id": "3S4kc_Vjs_m0",
    "outputId": "15608f16-454e-4601-852d-d398cba2ae5b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'OuroTrace'...\n",
      "remote: Enumerating objects: 2131, done.\u001b[K\n",
      "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 2131 (delta 6), reused 9 (delta 3), pack-reused 2118 (from 2)\u001b[K\n",
      "Receiving objects: 100% (2131/2131), 3.66 MiB | 8.63 MiB/s, done.\n",
      "Resolving deltas: 100% (1363/1363), done.\n",
      "/content/OuroTrace\n"
     ]
    }
   ],
   "source": [
    "!git clone --branch claude https://github.com/dzungphieuluuky/OuroTrace.git\n",
    "%cd OuroTrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmJUVG32s_m0"
   },
   "source": [
    "# Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "edfb3980cc964ddcab8e6ad051f57918",
      "4bd67410be064937a0af997b6eebde7b",
      "dfbc1053c2e84bfb8d05d7e5f88b89f5",
      "6bf1a8026cd04f23828f448622b3531a",
      "e2622ff0f2bf42268e31c725498658d9",
      "9c4e01259c6a4cb7a6f063af39249dd4",
      "3a8b36867d5a4796a8351280dc3a9a4b",
      "d2080b903a80478da504a7fa6fde8cfb",
      "680f12fe070a490e9a01c67f48ffa21b",
      "1ef9126e931d491fa5619dd299830c89",
      "0eef5f77c30d4586a0b029c4f73ee8b7",
      "af7342dcf91c4ad49f1515d5011991fc",
      "1d69deb69f16485887b8aa7eced8175e",
      "f27fa9d55d324b8ba5b5684b321fd63d",
      "f8c8fa759c764996a4e20505eef8ae8a",
      "1e180467f1fd4a6b9febca2bf2d8f9e9",
      "a0d7fc737c674bc8905f3eca84877dd5",
      "12eb202be4a942a6ba12537d10622460",
      "df9b669447944921be88020e1a3b49ef",
      "1238ab2d40f744958a700d06534cfb81",
      "cd11c1fd898c484a8ffd770004f67066",
      "fe97b2c6f4b5474392ef8406a4e9ea4d",
      "bdc46d40d0624f6fb779480f30505992",
      "0a6b79e0705248228b39371effe2a4f8",
      "c506b78df32d4e0385aeff435f9f0573",
      "0eb7ae3617be4994aa24212e5f456b44",
      "0940b5445b4c4a4a9be7ca85e0de2639",
      "cd7b08f9fdb34d0fb21d136ac53036f1",
      "128f9484db2d4e19a44b4fb42e634c44",
      "a6999d1edf6d4b2b953ebf8a969e6df3",
      "6fe15a1762f647d2bef3444557848e17",
      "2c77830d137740499fd5cbc00b8e605a",
      "fac34a603e4e4d31b53ca192a0acfa0d",
      "2291ff5734ec4ba1911d6e943ae1f9a4",
      "f066616f5e0a4362bfd31bf99dd0f93b",
      "c8c38c84eb2647e8bfd686f99fcd8d64",
      "b2b7e3dcda4c44658ce6cfd0ff754ab3",
      "02f0fa76199841c5977583e53fdaa8e4",
      "a58cb076794e42a3bffef58a8641b529",
      "6006d76bed564d53ad11b8dbe2875171",
      "9b6b40b787b748dcaee129a002da764b",
      "1f36784a96704d46943899b88d4428ee",
      "e2cfc03dfba844818e707df380c1764b",
      "586e419c4199491abdf9f335f394fccf",
      "3c8fad91575649d89bbc4931c102aad3",
      "43e7ff0df93041118e6a268913eca96e",
      "eef7ab4c24d24171bc4a0b14ef329c42",
      "8ad6e8c890e0494680a2f29c73185547",
      "4feb5dd1d8a644c087017f78b31dd48f",
      "c97106b431fb4bfeb3efee815237acc4",
      "bcd89ce5674d413eadab34e7f5130baa",
      "243040275475440a9ef530817299f9eb",
      "5b4d6ab30d0a4cf68cf9d5429a449555",
      "d3e2a7f67db94fae8ce893ad901fac1a",
      "1dc962b0847a48d591a671c33f60e7a1",
      "00e636d24a1243bba1af2976e5f2a351",
      "ff520aa3e391400581f63a3263013554",
      "d3b973bb7a974c2e9e74ff7952651f21",
      "255351f21e8b434c9723c81e7b5a325b",
      "2b0f6ebbae2b49d1980455b75e0389d6",
      "5e5d820b85bf45aa8cb2ff85afa477d1",
      "5b144326bc074fb186d70ba2c6357bfe",
      "2b72136554ca4a8f9555779e0f6cca12",
      "265a55436ae14b5e9c9733f439968ac6",
      "7c0fa98798d246789842b401f5e7a991",
      "77e5990db89f48d29d986eed7d5b9776",
      "39d6523408794ddcb010e2e9382b9249",
      "2eb1ce648b244803a75ec172579f2293",
      "b609829825a44f4a9ca93a3c6dc8502b",
      "3149cf61638a481b845a6bb18e4997ab",
      "901128df3b0d419992db002393bf70bc",
      "170060331edb442e9256fec6644ccbbd",
      "3c27f75092bc4a6b81ef2af0436e55a0",
      "1da91bf625f74079992e1329235a185b",
      "6e6a5c83577e4b53b9e1de6a0676e540",
      "49f1107fe58249588bc0b598ccdf03bc",
      "d91aef84ddbe4cbaa3141f0400fb1728",
      "0a4841d4045a4790bddcfbb30baf4609",
      "8b695f73bc164545bc789335bf81baef",
      "23ebc544202e48898690f47a3369a4e3",
      "1c4b37ea6cb3414c831264c95fb67d56",
      "f13e34e7d2704839ac8a24057bdd13d7",
      "ae1c0af3d107451fb772ba90bbc7fde0",
      "73ca724e8eba42ad9f766d42343fa1f2",
      "0fe25d33cdc54c468fd6be7e12853787",
      "cf825b79d93c4814b38ed50bf4703bd6",
      "cc56705b4a85494bbf9c55f86906c2a2",
      "c042fc57f3534773898d9022683216de",
      "c9853f28d4a34033ab4381503e7ba9d3",
      "b26f309881184bea8c466d93f5272bda",
      "0377003ca31a4243a1fc05e16ee04e8a",
      "defad53d63a743579977e43ca6934d24",
      "e3fd5d05c0de4d608d5f79e727cc9f38",
      "b09e7737f46b49d49d53385ed4452efe",
      "32d64f7859d0495087977a8163873269",
      "a47140d632ad4658aeb600860dea1b8a",
      "9ff9fa63aa39421991add3abf091fe2d",
      "591065db87054ba687f0f7ebdf824e3e",
      "00bff0f8b54c4197ab187fcd6e588e39",
      "287fd97e376145d592117779c56df99a",
      "34f0e68584b541939d3e07a76ebe2e04",
      "3f61c26020a9411ba9131c79b6069d3d",
      "2302a1d65c2540218df9b9023d3b49ce",
      "ed351b21ef5e4fa293a0afb033ede290",
      "d600c6f93656424c80e65a79edc0a70e",
      "9f9f6b24d95541bb844ec84196280a97",
      "ecbdf29cc83e4d92b35f0812ca11b004",
      "3bbcf2e880ea4913a294a8ef2bbe4545",
      "3173a511c1d845ea985508eb179e330a",
      "279451c430c245c7b0886608d1e56d93",
      "75e2e19ee06c4fe39fb605f82e7671f7",
      "766ab922a2ca4fdc8cd5aa2fcd403267",
      "1cd9b4059f464b2e9241d03337c333c0",
      "39893eb67d6740108ceb4cd8ec90fd4b",
      "5d30538a9c734c93b9e3f2f68e7f6fc8",
      "e690a92329f3404d889307e627f108c3",
      "a6dec74354744c40bca4cab11c0cfb23",
      "86a409e057ca45ebbf38e80bfa7da470",
      "c27ac76c8ecc41f38139b2cd3c38f939",
      "2c8a972d0e374bb6b78a50fbdbb591ce",
      "aedd6e462be241fbbf80c71d69f28e6b",
      "b2f2c8a0874543c0974a0b1e29ada8ce",
      "bad6e2e9aa6743a197a23cbb69f7beb2",
      "6be8d40f8ff94e1e98eae3dd8f124696",
      "087cab126dd44468b3ef1d5b394d0f13",
      "0d878ea979d84aa5947a25012ac0261d",
      "02ac4778ccdd4802be47212eaba2a1d0",
      "df40151cabad423aad29237f0ff28254",
      "9045ddb139c54c298d8effcbfed4a09b",
      "d3508523bd7a46aa9073cd0b468dd3d6",
      "924bf862d4c04627afe9872513104de3",
      "0eaca6b136024916b5ac13970a66ae39",
      "ba47e4a401b3479692807b9e21295bcf",
      "6c0aeb82560145f3999cce68fd888546",
      "14044963aa0a4337b5a4f80e9cfeb8fa",
      "12983b08161342b7a07c26c4514b4faf",
      "d023d11ec64e4d50b2a6facabdcfaf11",
      "7e5c1211f58a455f9c6232afcec02e2f",
      "d0cf358ecb74425f9663d69d30aef4b1",
      "e03d79995f4a4f7080c42bf0a8c04698",
      "6189ea16af96404986a327189de50fe3",
      "ded889acb0954c5cba7087912b92d21d",
      "ac2242c775c34fda9eea450dffdd8dce",
      "92c99b9eef0948f8898ce03d022c80e1",
      "9cbb14496b9a4ab3960bbb46f8584312",
      "3fc57b16685f4158a935c653c992b7a1",
      "7b86ab3075094e4d924c32cf77dc8b15",
      "3ee883bce4c04f99a4194c6381e14db9",
      "5f5b4525963441ea904d91f5b4fd544b",
      "b1e72c05c5494b8981ac2a06ba687ffa",
      "0d5ee60de5594e18b3126a5fa071193c",
      "66795aad1ac046df81d4771e597b8dda",
      "174d54aed8444f59b8079c277a4be223",
      "43da7795a14f45af849d3bab0c619e3d",
      "6dff8ee1e8574823bfd40521758fe6c4",
      "fca1084afb5845279b083ad832e77416",
      "82871130571744708bdd69db2c4556ed",
      "2afe9861bbb641e6b69ed4a458bacb77",
      "2e49f6ed7ae54d97a70743215a962167",
      "cca0c3d6164b4fe98ffd9d4301a73fde",
      "657e721703484b88bb066c97d40c0cab",
      "9cb6c3f88dd346b499d7c00f4f3bf6ce",
      "4c2715e08e074ae686836ea170599808",
      "c17054c81cb84fa9b9946dbb8e954ca6",
      "891b67a5b11b411f9ee5ab0603549e60",
      "9e2fcd2684994c86b3d2cb6b5671fad3",
      "5b724a79e703474baa97c846d547afa7",
      "ae896314d0da4fb693199e0197144f81",
      "d38b03c312c64d0699d9add3d16b9449",
      "7dda006b7a2f414f916e6ab423c1a5d9",
      "528bf418a11747a094e43adf12be7728",
      "a2ef69d8474c4f0fb9e537d6b6862b4a",
      "d5b4463b3bab43d29bb9427ebcb4b5df",
      "d2ea13681cc8476c8d2d0f6ed00e00b4",
      "d5d8ec708995480c99ef8dc1d1806475",
      "308c4bfab2b044b6b927ca155ed9ce49",
      "c307767c53984c7b821b73c66dc778f0",
      "e2c7dcaea33f4b0c9a00ae0612d88ea7",
      "30277af41e624effb1c6db107b6b0410",
      "0ffb44153c0343c792b52c08c7b9aa29",
      "d548bf72e90243eab3a845d961d0eead",
      "f687f481d4434014b18071565099df95",
      "80c094f4a3f540d7b6bc27bcef5fbaec",
      "30e5e9df1cc9410a8bba297f9f9800c7",
      "66b7abaa9fba48f988805741129c3011",
      "127e2867ebbc4d4f97f5e2e18dea976c",
      "c08a74cde5a84274bb9b4a854a21d5ba",
      "4580bfe8487c4aa09a73b6b18e6aeed1",
      "f664bd54b79c4b75b1744fa4364747bb",
      "fe80ab4ed279469aae889f0c8fa368eb",
      "1a2b4e6e6d094331b5d4c1e90fa3d85b",
      "d7eadca85cee45b9982a2e5929003a41",
      "c1e0ea4bec734f6d8a5b95f78befcc91",
      "59f04750571246d5adf68403d3b54fd9",
      "b3b8f0b5d6944f129ea48094f15c42a4",
      "e7d94bb4eefe48e98f5571cea360d804",
      "2346f06b7b7540779ee90a260fc3d3ac",
      "a000075646d043e8818541eba57dd200",
      "334009881da948eb9a14ce51d95495ad",
      "7f780bfbb1ec4da7bce17feec07e6cf2",
      "78211784f6d3442c9a09a60dd3c63d7f",
      "9241e16aa3f9470481e8b0e2ffc4c415",
      "a025bc8e6e504b928a794f77659c9119",
      "6dbfaa7d00a340cf8d947d0f502ca9c3",
      "b0d2d89d5bc64322ae7d9f885470b84d",
      "224c2b91e4e24d2088c6b7f33bfe1421",
      "f5d13e3ee0114ee19bd716e67302e899",
      "3de30de904f4473d9a18ec878c091a7c",
      "67551c1d99334956a320731c7986d8a1"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:17:55.599468Z",
     "iopub.status.busy": "2025-12-25T11:17:55.599180Z",
     "iopub.status.idle": "2025-12-25T11:20:53.149577Z",
     "shell.execute_reply": "2025-12-25T11:20:53.148803Z",
     "shell.execute_reply.started": "2025-12-25T11:17:55.599441Z"
    },
    "id": "CKc8czt-nzBB",
    "outputId": "3060099b-2552-43fe-90fa-bba5ddb4bbe6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Experiment...\n",
      "üîó Initializing W&B (timeout: 30s)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251225_132652-40fxlq9i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/40fxlq9i' target=\"_blank\">pious-wave-152</a></strong> to <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/40fxlq9i' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/40fxlq9i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ W&B initialized\n",
      "\n",
      "======================================================================\n",
      "üîß EXPERIMENT CONFIGURATION\n",
      "======================================================================\n",
      "Model Path: ByteDance/Ouro-1.4B-Thinking\n",
      "UT Steps to Test: [3]\n",
      "Data Type: torch.bfloat16\n",
      "4-bit Quantization: False\n",
      "Torch Compile: False\n",
      "Max Batch Size: 8\n",
      "Max New Tokens: 16\n",
      "Batching: False\n",
      "Calculate Perplexity: True\n",
      "Early Exit: 1.0\n",
      "======================================================================\n",
      "\n",
      "[+] Quality monitor initialized:\n",
      "    ‚Üí Garbage threshold: 30%\n",
      "    ‚Üí Example similarity threshold: 85%\n",
      "    ‚Üí Min samples before check: 10\n",
      "üé≤ Random seed set to 42\n",
      "\n",
      "======================================================================\n",
      "üì¶ LOADING TEST DATASETS\n",
      "======================================================================\n",
      "‚öôÔ∏è Generating new test datasets...\n",
      "‚úÖ Generated test datasets\n",
      "\n",
      "Dataset Summary:\n",
      "   n_ary       :  500 samples\n",
      "   p_hop       :  300 samples\n",
      "   igsm        :  100 samples\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìã PAPER COMPLIANCE CHECK\n",
      "======================================================================\n",
      "Task Alignment: {'has_n_ary': True, 'has_p_hop': True, 'has_igsm': True, 'all_paper_tasks': True}\n",
      "UT Steps Coverage: {'min_ut': 3, 'max_ut': 3, 'covers_baseline': False, 'covers_paper_range': False, 'recommended_range': [1, 2, 4, 8]}\n",
      "======================================================================\n",
      "\n",
      "üìö Preparing perplexity evaluation data...\n",
      "‚úÖ Prepared 50 samples for PPL\n",
      "\n",
      "‚úÖ Configuration saved to ../results_20251225_132657_UT_3/config.json\n",
      "‚úÖ Task templates saved to ../results_20251225_132657_UT_3/task_templates.json\n",
      "\n",
      "======================================================================\n",
      "üß™ EXPERIMENT 1/1: UT Steps = 3\n",
      "======================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚öôÔ∏è  LOADING MODEL CONFIGURATION\n",
      "============================================================\n",
      "Model Path: ByteDance/Ouro-1.4B-Thinking\n",
      "Requested UT Steps: 3\n",
      "Data Type: torch.bfloat16\n",
      "4-bit Quantization: False\n",
      "Torch Compile: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfb3980cc964ddcab8e6ad051f57918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7342dcf91c4ad49f1515d5011991fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_ouro.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Üí Base config loaded\n",
      "   Original UT steps: 4\n",
      "   Original early exit: 1.0\n",
      "\n",
      "‚Üí Modified config:\n",
      "   New UT steps: 3\n",
      "   Early exit threshold: 1.0 (from default)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc46d40d0624f6fb779480f30505992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2291ff5734ec4ba1911d6e943ae1f9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8fad91575649d89bbc4931c102aad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e636d24a1243bba1af2976e5f2a351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d6523408794ddcb010e2e9382b9249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Üí Tokenizer loaded\n",
      "   Vocab size: 49152\n",
      "   PAD token: <|im_end|>\n",
      "   EOS token: <|im_end|>\n",
      "\n",
      "‚Üí Loading model weights...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4841d4045a4790bddcfbb30baf4609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_ouro.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9853f28d4a34033ab4381503e7ba9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üöÄ APPLYING SAFE OPTIMIZATIONS\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   ‚úì Flash Attention / SDPA enabled\n",
      "   ‚úì TF32 enabled for matmul\n",
      "   ‚úì cuDNN auto-tuning enabled\n",
      "   ‚úì Memory pool optimized\n",
      "   ‚Üí Running 3 warmup passes...\n",
      "   ‚úì Warmup complete\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "============================================================\n",
      "‚úÖ MODEL LOADED SUCCESSFULLY\n",
      "============================================================\n",
      "Device: cuda:0\n",
      "Model dtype: torch.bfloat16\n",
      "VERIFIED UT steps: 3\n",
      "VERIFIED early exit: 1.0\n",
      "============================================================\n",
      "\n",
      "üîß Building task templates...\n",
      "[+] Task templates with pre-tokenized components computed.\n",
      "    System prompt N_ary tokens: 821 tokens\n",
      "    System prompt P_hop tokens: 686 tokens\n",
      "    System prompt IGSM tokens: 1140 tokens\n",
      "    User prefix tokens: 14 tokens\n",
      "    User suffix tokens: 6 tokens\n",
      "    Force start tokens: 4 tokens\n",
      "‚úÖ Task templates built\n",
      "\n",
      "‚úÖ Configuration saved to ../results_20251225_132657_UT_3/config.json\n",
      "‚úÖ Task templates saved to ../results_20251225_132657_UT_3/task_templates.json\n",
      "‚úÖ Experiment configuration saved with task templates\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìâ PERPLEXITY EVALUATION\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287fd97e376145d592117779c56df99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating PPL (UT=3):   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Perplexity Results:\n",
      "   Perplexity: 0.2411\n",
      "   Avg Loss:   1.2726\n",
      "\n",
      "======================================================================\n",
      "üéØ ACCURACY EVALUATION\n",
      "======================================================================\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìù Task: N_ARY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Total Samples: 500\n",
      "Batch Size: 1 (Sequential)\n",
      "Strategy: Sequential Processing\n",
      "\n",
      "Batch size < 1 or not enough items, processing sequentially.\n",
      "Processing 500 items sequentially...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e2e19ee06c4fe39fb605f82e7671f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   n_ary:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test_input        full_response  generated_tokens\n",
      "0  625 + 449 =  [FINAL]  1074 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  976 + 756 =  [FINAL]  1732 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  722 + 324 =  [FINAL]  1046 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  490 + 643 =  [FINAL]  1133 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  118 + 710 =  [FINAL]  828 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  075 + 884 =  [FINAL]  959 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  133 + 213 =  [FINAL]  346 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  092 + 549 =  [FINAL]  641 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  825 + 702 =  [FINAL]  1527 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  855 + 658 =  [FINAL]  1513 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  192 + 673 =  [FINAL]  865 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  727 + 874 =  [FINAL]  1501 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  863 + 029 =  [FINAL]  892 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  451 + 305 =  [FINAL]  756 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  375 + 942 =  [FINAL]  1317 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  639 + 073 =  [FINAL]  712 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  515 + 314 =  [FINAL]  829 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  494 + 155 =  [FINAL]  649 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  458 + 340 =  [FINAL]  798 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  861 + 371 =  [FINAL]  1232 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  269 + 761 =  [FINAL]  1030 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  065 + 577 =  [FINAL]  642 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  306 + 541 =  [FINAL]  847 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  225 + 008 =  [FINAL]  233 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  162 + 452 =  [FINAL]  614 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  985 + 369 =  [FINAL]  1354 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  954 + 347 =  [FINAL]  1301 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  026 + 136 =  [FINAL]  162 [END]                 7\n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "    test_input       full_response  generated_tokens\n",
      "0  562 + 208 =  [FINAL]  770 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  540 + 211 =  [FINAL]  751 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  299 + 815 =  [FINAL]  1114 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  426 + 407 =  [FINAL]  833 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  687 + 290 =  [FINAL]  977 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  733 + 584 =  [FINAL]  1317 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  733 + 872 =  [FINAL]  1605 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  791 + 381 =  [FINAL]  1172 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  528 + 495 =  [FINAL]  1023 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  562 + 080 =  [FINAL]  642 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  680 + 482 =  [FINAL]  1162 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  035 + 691 =  [FINAL]  726 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  805 + 783 =  [FINAL]  1588 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  644 + 833 =  [FINAL]  1477 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  944 + 763 =  [FINAL]  1707 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  996 + 373 =  [FINAL]  1369 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  758 + 731 =  [FINAL]  1489 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  694 + 382 =  [FINAL]  1076 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  534 + 598 =  [FINAL]  1132 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  203 + 487 =  [FINAL]  690 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  329 + 055 =  [FINAL]  384 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  476 + 637 =  [FINAL]  1113 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  752 + 469 =  [FINAL]  1221 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  867 + 863 =  [FINAL]  1730 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  156 + 534 =  [FINAL]  690 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  153 + 190 =  [FINAL]  343 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  895 + 893 =  [FINAL]  1788 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  709 + 603 =  [FINAL]  1312 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  868 + 161 =  [FINAL]  1029 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  547 + 202 =  [FINAL]  749 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  494 + 252 =  [FINAL]  746 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  761 + 118 =  [FINAL]  879 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  811 + 649 =  [FINAL]  1460 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  194 + 620 =  [FINAL]  814 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  247 + 916 =  [FINAL]  1163 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  581 + 075 =  [FINAL]  656 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  561 + 577 =  [FINAL]  1138 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  125 + 463 =  [FINAL]  588 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  816 + 270 =  [FINAL]  1086 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  281 + 431 =  [FINAL]  712 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  108 + 013 =  [FINAL]  121 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  225 + 043 =  [FINAL]  268 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  821 + 641 =  [FINAL]  1462 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  839 + 589 =  [FINAL]  1428 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  125 + 026 =  [FINAL]  151 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  054 + 628 =  [FINAL]  682 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  927 + 279 =  [FINAL]  1206 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  981 + 320 =  [FINAL]  1301 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  292 + 547 =  [FINAL]  839 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  591 + 333 =  [FINAL]  924 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  463 + 234 =  [FINAL]  697 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  735 + 084 =  [FINAL]  819 [END]                 7\n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "    test_input        full_response  generated_tokens\n",
      "0  761 + 911 =  [FINAL]  1672 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  943 + 431 =  [FINAL]  1374 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  895 + 209 =  [FINAL]  1004 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  256 + 366 =  [FINAL]  622 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  805 + 633 =  [FINAL]  1438 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  499 + 273 =  [FINAL]  772 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  739 + 795 =  [FINAL]  1534 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  476 + 272 =  [FINAL]  748 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  995 + 513 =  [FINAL]  1508 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  263 + 424 =  [FINAL]  687 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  048 + 494 =  [FINAL]  542 [END]                 7\n",
      "    test_input       full_response  generated_tokens\n",
      "0  226 + 136 =  [FINAL]  362 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  125 + 917 =  [FINAL]  1042 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  713 + 055 =  [FINAL]  768 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  502 + 522 =  [FINAL]  1024 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  200 + 562 =  [FINAL]  762 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  399 + 703 =  [FINAL]  1102 [END]                 8\n",
      "    test_input        full_response  generated_tokens\n",
      "0  861 + 782 =  [FINAL]  1643 [END]                 8\n",
      "    test_input       full_response  generated_tokens\n",
      "0  043 + 727 =  [FINAL]  770 [END]                 7\n",
      "    test_input        full_response  generated_tokens\n",
      "0  618 + 725 =  [FINAL]  1343 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  029 + 608 + 492 + 948 =  [FINAL]  2157 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  900 + 306 + 192 + 205 =  [FINAL]  1603 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  288 + 469 + 538 + 855 =  [FINAL]  2140 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  023 + 348 + 199 + 697 =  [FINAL]  1267 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  369 + 044 + 882 + 252 =  [FINAL]  1547 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  029 + 147 + 797 + 225 =  [FINAL]  1298 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  072 + 473 + 589 + 046 =  [FINAL]  1630 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  859 + 857 + 568 + 599 =  [FINAL]  2973 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  943 + 423 + 392 + 357 =  [FINAL]  1915 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  470 + 841 + 475 + 319 =  [FINAL]  2005 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  511 + 015 + 856 + 385 =  [FINAL]  1767 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  900 + 217 + 497 + 940 =  [FINAL]  2554 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  310 + 349 + 692 + 997 =  [FINAL]  2348 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  152 + 683 + 769 + 799 =  [FINAL]  2323 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  894 + 048 + 980 + 163 =  [FINAL]  2925 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  431 + 533 + 178 + 327 =  [FINAL]  1469 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  213 + 622 + 202 + 244 =  [FINAL]  1281 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  655 + 538 + 312 + 123 =  [FINAL]  1628 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  475 + 132 + 633 + 198 =  [FINAL]  1438 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  372 + 930 + 381 + 334 =  [FINAL]  1917 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  109 + 885 + 515 + 411 =  [FINAL]  1910 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  728 + 484 + 906 + 350 =  [FINAL]  2468 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  128 + 287 + 986 + 685 =  [FINAL]  2086 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  841 + 260 + 723 + 334 =  [FINAL]  2158 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  197 + 666 + 066 + 153 =  [FINAL]  1072 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  164 + 429 + 653 + 647 =  [FINAL]  2433 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  096 + 202 + 605 + 253 =  [FINAL]  1606 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  952 + 316 + 173 + 715 =  [FINAL]  2156 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  932 + 505 + 698 + 106 =  [FINAL]  2291 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  419 + 113 + 392 + 571 =  [FINAL]  1595 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  962 + 054 + 365 + 834 =  [FINAL]  2695 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  298 + 560 + 620 + 861 =  [FINAL]  2339 [END]                 8\n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                test_input        full_response  generated_tokens\n",
      "0  939 + 399 + 345 + 942 =  [FINAL]  2525 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  913 + 936 + 620 + 276 =  [FINAL]  2745 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  563 + 816 + 821 + 112 =  [FINAL]  2312 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  120 + 348 + 989 + 653 =  [FINAL]  2110 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  598 + 677 + 638 + 157 =  [FINAL]  2060 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  263 + 195 + 148 + 533 =  [FINAL]  1149 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  325 + 802 + 598 + 309 =  [FINAL]  2034 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  522 + 872 + 247 + 065 =  [FINAL]  1606 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  407 + 105 + 759 + 509 =  [FINAL]  1870 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  936 + 561 + 690 + 229 =  [FINAL]  2416 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  905 + 843 + 621 + 914 =  [FINAL]  3283 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  228 + 403 + 172 + 606 =  [FINAL]  1409 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  826 + 043 + 922 + 146 =  [FINAL]  1937 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  997 + 245 + 086 + 496 =  [FINAL]  2724 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  902 + 556 + 877 + 105 =  [FINAL]  2430 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  761 + 184 + 828 + 714 =  [FINAL]  3287 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  527 + 957 + 212 + 928 =  [FINAL]  2624 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  868 + 763 + 234 + 369 =  [FINAL]  2234 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  351 + 295 + 929 + 649 =  [FINAL]  2224 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  274 + 227 + 676 + 513 =  [FINAL]  1780 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  954 + 238 + 091 + 600 =  [FINAL]  1883 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  507 + 303 + 230 + 609 =  [FINAL]  1650 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  773 + 791 + 638 + 971 =  [FINAL]  3173 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  290 + 236 + 378 + 169 =  [FINAL]  1073 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  187 + 362 + 893 + 865 =  [FINAL]  3007 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  393 + 500 + 573 + 689 =  [FINAL]  2355 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  604 + 500 + 925 + 944 =  [FINAL]  2973 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  768 + 796 + 129 + 772 =  [FINAL]  2965 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  024 + 485 + 883 + 578 =  [FINAL]  2030 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  125 + 319 + 529 + 831 =  [FINAL]  2004 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  826 + 826 + 165 + 791 =  [FINAL]  2508 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  252 + 069 + 515 + 076 =  [FINAL]  1312 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  229 + 402 + 315 + 386 =  [FINAL]  1422 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  045 + 477 + 135 + 681 =  [FINAL]  1338 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  166 + 972 + 181 + 202 =  [FINAL]  1421 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  907 + 492 + 890 + 944 =  [FINAL]  3233 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  756 + 955 + 471 + 626 =  [FINAL]  2708 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  636 + 140 + 840 + 091 =  [FINAL]  1667 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  648 + 375 + 772 + 849 =  [FINAL]  2544 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  945 + 588 + 954 + 830 =  [FINAL]  3217 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  179 + 594 + 160 + 792 =  [FINAL]  1725 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  572 + 565 + 698 + 301 =  [FINAL]  2136 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  131 + 494 + 051 + 951 =  [FINAL]  2887 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  941 + 962 + 537 + 852 =  [FINAL]  3292 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  379 + 433 + 250 + 904 =  [FINAL]  1966 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  299 + 635 + 562 + 181 =  [FINAL]  1677 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  730 + 458 + 204 + 961 =  [FINAL]  2353 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  092 + 331 + 776 + 857 =  [FINAL]  2956 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  099 + 312 + 904 + 701 =  [FINAL]  2916 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  096 + 258 + 932 + 652 =  [FINAL]  2838 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  092 + 852 + 497 + 596 =  [FINAL]  2457 [END]                 8\n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                test_input        full_response  generated_tokens\n",
      "0  284 + 224 + 800 + 424 =  [FINAL]  1732 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  356 + 722 + 130 + 388 =  [FINAL]  1596 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  483 + 147 + 660 + 530 =  [FINAL]  1820 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  091 + 537 + 160 + 742 =  [FINAL]  1530 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  888 + 231 + 878 + 358 =  [FINAL]  2355 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  400 + 822 + 914 + 602 =  [FINAL]  2738 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  557 + 655 + 362 + 159 =  [FINAL]  1733 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  437 + 073 + 419 + 305 =  [FINAL]  1214 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  621 + 423 + 337 + 994 =  [FINAL]  2275 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  237 + 515 + 140 + 508 =  [FINAL]  1400 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  376 + 948 + 626 + 236 =  [FINAL]  2286 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  148 + 954 + 339 + 627 =  [FINAL]  2008 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  002 + 413 + 150 + 981 =  [FINAL]  1546 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  052 + 463 + 224 + 122 =  [FINAL]  1251 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  815 + 047 + 029 + 230 =  [FINAL]  1311 [END]                 8\n",
      "                test_input        full_response  generated_tokens\n",
      "0  923 + 753 + 167 + 065 =  [FINAL]  2408 [END]                 8\n",
      "                test_input       full_response  generated_tokens\n",
      "0  100 + 037 + 220 + 255 =  [FINAL]  612 [END]                 7\n",
      "                                        test_input        full_response  \\\n",
      "0  892 + 016 + 423 + 853 + 200 + 703 + 773 + 563 =  [FINAL]  4753 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  508 + 140 + 957 + 285 + 648 + 821 + 548 + 528 =  [FINAL]  4403 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  165 + 409 + 382 + 807 + 797 + 680 + 885 + 253 =  [FINAL]  4609 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  669 + 674 + 908 + 918 + 274 + 063 + 792 + 492 =  [FINAL]  4756 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  927 + 096 + 677 + 298 + 877 + 470 + 881 + 211 =  [FINAL]  4789 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  075 + 497 + 019 + 727 + 521 + 763 + 309 + 844 =  [FINAL]  4109 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  148 + 568 + 926 + 527 + 151 + 779 + 321 + 180 =  [FINAL]  3500 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  302 + 280 + 316 + 861 + 774 + 840 + 973 + 290 =  [FINAL]  4906 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  149 + 892 + 905 + 794 + 098 + 504 + 728 + 970 =  [FINAL]  5704 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  316 + 266 + 774 + 215 + 420 + 242 + 877 + 634 =  [FINAL]  3700 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  695 + 010 + 225 + 662 + 265 + 422 + 904 + 920 =  [FINAL]  4073 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  950 + 227 + 378 + 498 + 823 + 757 + 539 + 869 =  [FINAL]  4907 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  370 + 410 + 491 + 571 + 707 + 416 + 817 + 722 =  [FINAL]  4764 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  539 + 832 + 165 + 495 + 365 + 827 + 701 + 218 =  [FINAL]  4032 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  091 + 691 + 861 + 337 + 435 + 336 + 043 + 631 =  [FINAL]  3765 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  755 + 667 + 317 + 335 + 665 + 739 + 212 + 431 =  [FINAL]  3701 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  828 + 264 + 381 + 967 + 834 + 533 + 681 + 812 =  [FINAL]  5508 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  329 + 317 + 257 + 536 + 525 + 646 + 781 + 020 =  [FINAL]  3505 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  283 + 707 + 103 + 991 + 827 + 393 + 998 + 104 =  [FINAL]  5537 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  897 + 075 + 147 + 830 + 643 + 029 + 777 + 341 =  [FINAL]  4559 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  395 + 546 + 466 + 508 + 330 + 753 + 268 + 001 =  [FINAL]  3547 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  166 + 994 + 654 + 211 + 300 + 072 + 480 + 673 =  [FINAL]  3430 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  467 + 356 + 421 + 261 + 069 + 810 + 645 + 932 =  [FINAL]  4091 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  945 + 541 + 299 + 512 + 858 + 460 + 131 + 673 =  [FINAL]  4490 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  652 + 222 + 771 + 279 + 457 + 468 + 565 + 988 =  [FINAL]  4508 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  632 + 478 + 909 + 122 + 588 + 253 + 398 + 227 =  [FINAL]  3506 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  356 + 417 + 225 + 212 + 746 + 753 + 309 + 810 =  [FINAL]  3798 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  426 + 089 + 428 + 728 + 207 + 064 + 068 + 936 =  [FINAL]  3407 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  535 + 304 + 192 + 759 + 352 + 317 + 668 + 323 =  [FINAL]  3306 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  774 + 077 + 413 + 344 + 665 + 725 + 822 + 887 =  [FINAL]  5025 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  681 + 197 + 334 + 767 + 890 + 361 + 343 + 967 =  [FINAL]  4901 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  153 + 064 + 166 + 960 + 251 + 790 + 333 + 555 =  [FINAL]  3502 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  203 + 222 + 990 + 441 + 330 + 241 + 318 + 986 =  [FINAL]  3600 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  463 + 696 + 224 + 637 + 827 + 571 + 989 + 172 =  [FINAL]  5569 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  171 + 372 + 849 + 737 + 304 + 854 + 593 + 328 =  [FINAL]  4008 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                        test_input        full_response  \\\n",
      "0  109 + 358 + 567 + 559 + 047 + 607 + 996 + 665 =  [FINAL]  4449 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  062 + 096 + 089 + 665 + 201 + 092 + 021 + 582 =  [FINAL]  2183 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  729 + 707 + 785 + 206 + 929 + 542 + 488 + 327 =  [FINAL]  4508 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  358 + 190 + 828 + 961 + 016 + 007 + 597 + 314 =  [FINAL]  3749 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  571 + 774 + 834 + 015 + 929 + 146 + 090 + 026 =  [FINAL]  4295 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  970 + 286 + 927 + 197 + 557 + 079 + 850 + 276 =  [FINAL]  4551 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  622 + 974 + 057 + 211 + 476 + 317 + 267 + 573 =  [FINAL]  3403 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  532 + 310 + 399 + 572 + 858 + 103 + 338 + 906 =  [FINAL]  4008 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  771 + 471 + 539 + 797 + 601 + 264 + 095 + 362 =  [FINAL]  3950 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  001 + 843 + 923 + 072 + 515 + 992 + 076 + 525 =  [FINAL]  4075 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  929 + 771 + 822 + 945 + 886 + 658 + 434 + 316 =  [FINAL]  5600 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  356 + 082 + 899 + 748 + 522 + 884 + 461 + 249 =  [FINAL]  4701 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  609 + 917 + 781 + 196 + 526 + 449 + 122 + 057 =  [FINAL]  3509 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  334 + 599 + 134 + 558 + 276 + 170 + 046 + 836 =  [FINAL]  3055 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  161 + 739 + 052 + 014 + 165 + 659 + 254 + 148 =  [FINAL]  2402 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  651 + 468 + 362 + 563 + 028 + 163 + 129 + 691 =  [FINAL]  3405 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  080 + 979 + 463 + 447 + 285 + 271 + 331 + 012 =  [FINAL]  2759 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  571 + 303 + 799 + 983 + 086 + 730 + 605 + 535 =  [FINAL]  4993 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  714 + 100 + 978 + 106 + 706 + 298 + 598 + 467 =  [FINAL]  3549 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  983 + 322 + 940 + 276 + 973 + 972 + 813 + 818 =  [FINAL]  5768 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  986 + 136 + 615 + 704 + 503 + 933 + 518 + 204 =  [FINAL]  4502 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  416 + 104 + 559 + 062 + 526 + 963 + 742 + 088 =  [FINAL]  4006 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  268 + 820 + 632 + 202 + 200 + 537 + 019 + 759 =  [FINAL]  3198 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  335 + 344 + 043 + 917 + 737 + 603 + 750 + 592 =  [FINAL]  4999 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  983 + 481 + 586 + 460 + 941 + 455 + 211 + 667 =  [FINAL]  4304 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  725 + 315 + 992 + 449 + 821 + 470 + 895 + 046 =  [FINAL]  4704 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  248 + 289 + 046 + 009 + 472 + 060 + 951 + 923 =  [FINAL]  4498 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  883 + 129 + 416 + 563 + 692 + 786 + 112 + 295 =  [FINAL]  4302 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  311 + 231 + 130 + 949 + 299 + 835 + 440 + 974 =  [FINAL]  4099 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  895 + 483 + 898 + 867 + 368 + 087 + 792 + 481 =  [FINAL]  5107 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  062 + 924 + 292 + 965 + 036 + 824 + 177 + 281 =  [FINAL]  3599 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  061 + 626 + 551 + 455 + 726 + 720 + 209 + 611 =  [FINAL]  4165 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  979 + 531 + 746 + 023 + 975 + 468 + 271 + 144 =  [FINAL]  4109 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  904 + 135 + 732 + 162 + 133 + 893 + 445 + 077 =  [FINAL]  3507 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  913 + 213 + 755 + 179 + 843 + 876 + 033 + 845 =  [FINAL]  4755 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  924 + 026 + 747 + 200 + 766 + 647 + 601 + 258 =  [FINAL]  4063 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  220 + 886 + 766 + 159 + 431 + 514 + 045 + 047 =  [FINAL]  3458 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  962 + 556 + 310 + 467 + 280 + 700 + 528 + 951 =  [FINAL]  4514 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  620 + 126 + 716 + 866 + 435 + 861 + 687 + 283 =  [FINAL]  4500 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  728 + 398 + 167 + 265 + 738 + 521 + 879 + 952 =  [FINAL]  4908 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  150 + 037 + 984 + 515 + 667 + 800 + 578 + 805 =  [FINAL]  5500 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  947 + 941 + 117 + 215 + 823 + 235 + 395 + 868 =  [FINAL]  4605 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  752 + 353 + 410 + 334 + 552 + 849 + 340 + 734 =  [FINAL]  4005 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  868 + 164 + 433 + 165 + 227 + 761 + 843 + 082 =  [FINAL]  4008 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  256 + 469 + 284 + 670 + 717 + 802 + 928 + 153 =  [FINAL]  5108 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  703 + 686 + 222 + 090 + 180 + 552 + 103 + 532 =  [FINAL]  3406 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input  \\\n",
      "0  490 + 407 + 337 + 953 + 994 + 084 + 452 + 902 =   \n",
      "\n",
      "                 full_response  generated_tokens  \n",
      "0  [FINAL]  490 + 407 + 337 +                 16  \n",
      "                                        test_input        full_response  \\\n",
      "0  991 + 954 + 935 + 452 + 892 + 238 + 648 + 437 =  [FINAL]  5026 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  836 + 939 + 638 + 021 + 469 + 029 + 503 + 744 =  [FINAL]  4422 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  815 + 583 + 595 + 347 + 749 + 116 + 530 + 687 =  [FINAL]  4305 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  893 + 017 + 580 + 444 + 402 + 986 + 843 + 636 =  [FINAL]  4765 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                        test_input        full_response  \\\n",
      "0  626 + 634 + 914 + 165 + 339 + 455 + 426 + 488 =  [FINAL]  3835 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  434 + 934 + 277 + 621 + 515 + 687 + 879 + 592 =  [FINAL]  4859 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  811 + 433 + 680 + 370 + 386 + 418 + 355 + 723 =  [FINAL]  3750 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  110 + 029 + 201 + 712 + 743 + 527 + 025 + 464 =  [FINAL]  3529 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  518 + 019 + 310 + 494 + 559 + 553 + 757 + 189 =  [FINAL]  3905 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  892 + 659 + 964 + 262 + 929 + 920 + 545 + 898 =  [FINAL]  5508 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  779 + 059 + 145 + 402 + 138 + 845 + 460 + 090 =  [FINAL]  3078 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  236 + 430 + 844 + 999 + 033 + 562 + 025 + 632 =  [FINAL]  3761 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  450 + 360 + 584 + 904 + 311 + 943 + 476 + 978 =  [FINAL]  4706 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  825 + 748 + 400 + 760 + 652 + 562 + 677 + 896 =  [FINAL]  5400 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  824 + 242 + 034 + 110 + 014 + 464 + 472 + 562 =  [FINAL]  2794 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  969 + 488 + 543 + 037 + 791 + 567 + 254 + 783 =  [FINAL]  4068 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  799 + 279 + 452 + 675 + 074 + 647 + 665 + 042 =  [FINAL]  3493 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                        test_input        full_response  \\\n",
      "0  560 + 115 + 869 + 566 + 741 + 787 + 465 + 102 =  [FINAL]  4505 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  235 + 346 + 311 + 459 + 691 + 020 + 272 + 459 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  925 + 521 + 750 + 472 + 773 + 889 + 772 + 950 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  264 + 141 + 881 + 902 + 767 + 806 + 996 + 203 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  602 + 028 + 235 + 067 + 461 + 833 + 578 + 057 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  082 + 770 + 161 + 340 + 665 + 921 + 547 + 875 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  422 + 563 + 663 + 954 + 250 + 098 + 944 + 811 ...  [FINAL]  7320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  050 + 022 + 157 + 690 + 397 + 309 + 421 + 387 ...  [FINAL]  5903 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input  \\\n",
      "0  634 + 583 + 029 + 015 + 248 + 379 + 585 + 685 ...   \n",
      "\n",
      "                 full_response  generated_tokens  \n",
      "0  [FINAL]  634 + 583 + 029 +                 16  \n",
      "                                          test_input  \\\n",
      "0  750 + 578 + 170 + 062 + 632 + 223 + 795 + 523 ...   \n",
      "\n",
      "                 full_response  generated_tokens  \n",
      "0  [FINAL]  750 + 578 + 170 +                 16  \n",
      "                                          test_input  \\\n",
      "0  750 + 513 + 026 + 012 + 403 + 774 + 158 + 186 ...   \n",
      "\n",
      "                 full_response  generated_tokens  \n",
      "0  [FINAL]  750 + 513 + 026 +                 16  \n",
      "                                          test_input        full_response  \\\n",
      "0  554 + 339 + 401 + 626 + 957 + 400 + 183 + 792 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  195 + 794 + 601 + 168 + 270 + 837 + 805 + 398 ...  [FINAL]  7300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  875 + 439 + 925 + 668 + 488 + 455 + 089 + 827 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  449 + 582 + 787 + 235 + 779 + 430 + 327 + 438 ...  [FINAL]  5300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  991 + 791 + 829 + 606 + 764 + 051 + 504 + 397 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  611 + 611 + 850 + 774 + 186 + 412 + 310 + 945 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  472 + 969 + 793 + 226 + 088 + 144 + 067 + 167 ...  [FINAL]  10003 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  404 + 829 + 890 + 270 + 164 + 933 + 262 + 354 ...  [FINAL]  7303 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  298 + 637 + 779 + 088 + 075 + 116 + 233 + 717 ...  [FINAL]  5700 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input          full_response  \\\n",
      "0  388 + 203 + 914 + 461 + 855 + 404 + 588 + 674 ...  [FINAL]  10,000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input        full_response  \\\n",
      "0  067 + 128 + 532 + 992 + 661 + 478 + 337 + 057 ...  [FINAL]  7320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  176 + 437 + 903 + 357 + 359 + 001 + 871 + 219 ...  [FINAL]  5900 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  807 + 322 + 069 + 935 + 962 + 686 + 443 + 233 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input          full_response  \\\n",
      "0  972 + 414 + 871 + 996 + 564 + 127 + 974 + 680 ...  [FINAL]  10,000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input        full_response  \\\n",
      "0  894 + 234 + 070 + 998 + 581 + 893 + 614 + 235 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  633 + 144 + 151 + 563 + 668 + 756 + 526 + 050 ...  [FINAL]  7320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  047 + 529 + 078 + 812 + 089 + 581 + 980 + 781 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  338 + 513 + 828 + 957 + 255 + 039 + 141 + 515 ...  [FINAL]  7005 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  906 + 376 + 310 + 012 + 282 + 159 + 384 + 567 ...  [FINAL]  5300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  554 + 644 + 736 + 914 + 172 + 602 + 009 + 367 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  350 + 491 + 846 + 183 + 531 + 700 + 925 + 048 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  158 + 703 + 436 + 157 + 970 + 300 + 100 + 367 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  170 + 014 + 972 + 789 + 885 + 590 + 064 + 964 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  969 + 627 + 693 + 329 + 528 + 189 + 013 + 628 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  992 + 293 + 537 + 147 + 432 + 797 + 510 + 511 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  508 + 107 + 190 + 243 + 518 + 364 + 251 + 559 ...  [FINAL]  4923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input          full_response  \\\n",
      "0  567 + 824 + 264 + 765 + 848 + 251 + 895 + 457 ...  [FINAL]  10,300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input          full_response  \\\n",
      "0  397 + 582 + 799 + 915 + 379 + 877 + 801 + 789 ...  [FINAL]  10,000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input         full_response  \\\n",
      "0  009 + 454 + 067 + 061 + 692 + 556 + 607 + 157 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  412 + 307 + 127 + 382 + 251 + 062 + 517 + 324 ...  [FINAL]  5320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  485 + 391 + 705 + 618 + 888 + 953 + 331 + 480 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  184 + 121 + 843 + 210 + 768 + 608 + 902 + 731 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  160 + 988 + 873 + 952 + 064 + 791 + 218 + 151 ...  [FINAL]  6320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  880 + 952 + 671 + 096 + 088 + 006 + 458 + 781 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  616 + 112 + 808 + 085 + 816 + 614 + 988 + 114 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  112 + 963 + 320 + 457 + 114 + 285 + 670 + 616 ...  [FINAL]  5923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  115 + 308 + 446 + 882 + 534 + 621 + 196 + 045 ...  [FINAL]  5322 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  671 + 406 + 458 + 827 + 088 + 877 + 680 + 563 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  492 + 442 + 056 + 762 + 870 + 814 + 537 + 175 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  796 + 069 + 443 + 044 + 213 + 601 + 767 + 563 ...  [FINAL]  5920 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  077 + 878 + 104 + 701 + 269 + 144 + 818 + 584 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  776 + 290 + 491 + 350 + 903 + 486 + 746 + 227 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  440 + 122 + 195 + 119 + 494 + 240 + 459 + 024 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input          full_response  \\\n",
      "0  365 + 877 + 945 + 379 + 613 + 492 + 990 + 674 ...  [FINAL]  10,000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input         full_response  \\\n",
      "0  747 + 584 + 442 + 805 + 695 + 646 + 935 + 626 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  566 + 296 + 563 + 421 + 719 + 464 + 353 + 240 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  336 + 309 + 179 + 520 + 958 + 415 + 054 + 839 ...  [FINAL]  6323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  474 + 473 + 199 + 634 + 696 + 852 + 884 + 241 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input          full_response  \\\n",
      "0  813 + 726 + 383 + 872 + 517 + 995 + 133 + 963 ...  [FINAL]  10,000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input        full_response  \\\n",
      "0  473 + 051 + 242 + 767 + 750 + 077 + 312 + 608 ...  [FINAL]  5323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  579 + 592 + 884 + 062 + 700 + 204 + 242 + 547 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  502 + 991 + 324 + 332 + 245 + 320 + 121 + 526 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  710 + 581 + 311 + 170 + 692 + 389 + 046 + 402 ...  [FINAL]  6323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  843 + 417 + 786 + 431 + 592 + 738 + 350 + 778 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  529 + 365 + 714 + 323 + 691 + 691 + 011 + 271 ...  [FINAL]  5900 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  295 + 809 + 465 + 857 + 493 + 290 + 087 + 041 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  931 + 126 + 565 + 984 + 571 + 546 + 961 + 746 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  904 + 481 + 297 + 283 + 674 + 043 + 106 + 326 ...  [FINAL]  5920 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  431 + 113 + 392 + 384 + 984 + 302 + 375 + 349 ...  [FINAL]  6320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  316 + 705 + 223 + 394 + 409 + 897 + 360 + 214 ...  [FINAL]  5923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  874 + 474 + 162 + 014 + 639 + 185 + 028 + 682 ...  [FINAL]  7392 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  288 + 166 + 285 + 406 + 792 + 619 + 916 + 860 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  300 + 023 + 033 + 419 + 124 + 455 + 115 + 384 ...  [FINAL]  4300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  101 + 354 + 688 + 415 + 485 + 297 + 705 + 902 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input  \\\n",
      "0  636 + 992 + 251 + 118 + 939 + 277 + 284 + 760 ...   \n",
      "\n",
      "                 full_response  generated_tokens  \n",
      "0  [FINAL]  636 + 992 + 251 +                 16  \n",
      "                                          test_input        full_response  \\\n",
      "0  382 + 853 + 041 + 133 + 282 + 030 + 824 + 281 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  334 + 942 + 183 + 297 + 796 + 143 + 085 + 199 ...  [FINAL]  7320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  004 + 528 + 614 + 740 + 597 + 072 + 493 + 128 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  568 + 063 + 671 + 713 + 198 + 100 + 416 + 360 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  514 + 206 + 445 + 371 + 920 + 416 + 055 + 966 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  445 + 901 + 691 + 539 + 029 + 632 + 893 + 338 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  769 + 584 + 263 + 433 + 834 + 719 + 257 + 710 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input          full_response  \\\n",
      "0  453 + 575 + 330 + 806 + 408 + 911 + 406 + 881 ...  [FINAL]  10,500 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input        full_response  \\\n",
      "0  464 + 346 + 575 + 317 + 662 + 229 + 064 + 485 ...  [FINAL]  7000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  915 + 422 + 112 + 487 + 854 + 268 + 952 + 194 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input         full_response  \\\n",
      "0  366 + 664 + 097 + 835 + 910 + 455 + 720 + 575 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  525 + 304 + 503 + 931 + 127 + 998 + 092 + 983 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  468 + 053 + 582 + 690 + 531 + 270 + 950 + 694 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input          full_response  \\\n",
      "0  511 + 960 + 384 + 751 + 900 + 795 + 479 + 133 ...  [FINAL]  10,000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                10  \n",
      "                                          test_input        full_response  \\\n",
      "0  605 + 486 + 875 + 672 + 876 + 404 + 149 + 218 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  673 + 148 + 783 + 355 + 271 + 309 + 295 + 466 ...  [FINAL]  5000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  703 + 403 + 803 + 640 + 933 + 777 + 823 + 955 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  159 + 778 + 212 + 815 + 530 + 921 + 378 + 272 ...  [FINAL]  6370 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  469 + 591 + 459 + 656 + 598 + 761 + 493 + 666 ...  [FINAL]  5320 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  398 + 317 + 052 + 012 + 997 + 028 + 163 + 416 ...  [FINAL]  5800 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  627 + 396 + 258 + 178 + 651 + 552 + 892 + 611 ...  [FINAL]  6300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  194 + 930 + 610 + 952 + 980 + 387 + 582 + 979 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  447 + 680 + 145 + 327 + 191 + 242 + 438 + 798 ...  [FINAL]  5323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  587 + 980 + 060 + 226 + 948 + 634 + 598 + 722 ...  [FINAL]  10005 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  829 + 231 + 485 + 112 + 302 + 987 + 673 + 622 ...  [FINAL]  7323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  908 + 262 + 993 + 092 + 061 + 501 + 815 + 395 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  869 + 019 + 297 + 256 + 480 + 073 + 655 + 322 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  578 + 423 + 732 + 954 + 400 + 996 + 810 + 245 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  983 + 404 + 563 + 049 + 954 + 543 + 399 + 490 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  906 + 363 + 101 + 458 + 673 + 627 + 265 + 501 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  976 + 885 + 048 + 880 + 504 + 647 + 815 + 748 ...  [FINAL]  10230 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  572 + 062 + 215 + 012 + 890 + 201 + 712 + 048 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  416 + 001 + 742 + 648 + 314 + 591 + 881 + 442 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  972 + 614 + 387 + 026 + 986 + 320 + 584 + 484 ...  [FINAL]  10300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  057 + 350 + 758 + 429 + 363 + 529 + 891 + 723 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  696 + 674 + 219 + 172 + 324 + 283 + 943 + 522 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  016 + 215 + 826 + 905 + 758 + 931 + 819 + 879 ...  [FINAL]  10232 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  824 + 103 + 173 + 255 + 765 + 820 + 491 + 920 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  819 + 396 + 380 + 567 + 317 + 435 + 920 + 187 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  217 + 923 + 041 + 737 + 175 + 599 + 836 + 271 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  914 + 126 + 735 + 390 + 157 + 225 + 275 + 872 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  954 + 003 + 029 + 408 + 988 + 800 + 352 + 902 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  859 + 380 + 442 + 539 + 724 + 071 + 262 + 481 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  071 + 106 + 708 + 439 + 278 + 394 + 263 + 876 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  609 + 071 + 020 + 559 + 949 + 386 + 131 + 395 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  219 + 616 + 099 + 849 + 019 + 580 + 166 + 826 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  186 + 652 + 672 + 373 + 155 + 141 + 704 + 492 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  237 + 245 + 092 + 755 + 090 + 454 + 502 + 874 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  844 + 424 + 871 + 506 + 094 + 644 + 787 + 186 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input        full_response  \\\n",
      "0  312 + 279 + 997 + 156 + 875 + 186 + 166 + 406 ...  [FINAL]  9993 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  128 + 506 + 786 + 191 + 348 + 932 + 395 + 293 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  565 + 203 + 786 + 012 + 043 + 526 + 421 + 837 ...  [FINAL]  9990 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input        full_response  \\\n",
      "0  503 + 381 + 980 + 464 + 223 + 575 + 107 + 232 ...  [FINAL]  9323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  964 + 743 + 059 + 711 + 501 + 978 + 016 + 565 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  421 + 021 + 136 + 790 + 884 + 285 + 569 + 051 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  294 + 341 + 653 + 162 + 945 + 897 + 711 + 692 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  877 + 968 + 081 + 670 + 224 + 948 + 706 + 085 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  334 + 908 + 161 + 262 + 025 + 101 + 897 + 523 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input         full_response  \\\n",
      "0  556 + 609 + 348 + 710 + 742 + 961 + 438 + 519 ...  [FINAL]  10200 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  565 + 647 + 430 + 009 + 409 + 848 + 929 + 231 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  172 + 170 + 655 + 638 + 401 + 391 + 690 + 447 ...  [FINAL]  10700 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  464 + 944 + 316 + 315 + 729 + 222 + 297 + 016 ...  [FINAL]  10203 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  486 + 056 + 448 + 603 + 957 + 875 + 304 + 360 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  717 + 180 + 894 + 215 + 042 + 775 + 827 + 974 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  916 + 764 + 452 + 269 + 508 + 111 + 171 + 017 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  493 + 866 + 798 + 803 + 919 + 333 + 527 + 472 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  996 + 339 + 308 + 159 + 082 + 970 + 954 + 766 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  216 + 656 + 551 + 576 + 349 + 166 + 815 + 645 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  802 + 800 + 365 + 706 + 910 + 229 + 102 + 975 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input         full_response  \\\n",
      "0  885 + 415 + 615 + 189 + 724 + 353 + 312 + 497 ...  [FINAL]  10234 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  889 + 350 + 560 + 437 + 527 + 732 + 609 + 516 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  688 + 001 + 659 + 248 + 184 + 078 + 933 + 626 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  952 + 884 + 870 + 125 + 843 + 350 + 140 + 034 ...  [FINAL]  10200 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  380 + 531 + 058 + 056 + 328 + 689 + 233 + 755 ...  [FINAL]  10300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  936 + 570 + 402 + 677 + 829 + 779 + 012 + 273 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  945 + 184 + 083 + 913 + 897 + 818 + 196 + 702 ...  [FINAL]  10800 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  332 + 868 + 758 + 793 + 642 + 677 + 760 + 230 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  987 + 209 + 837 + 897 + 111 + 946 + 326 + 845 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  941 + 735 + 870 + 982 + 234 + 075 + 004 + 722 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  626 + 293 + 261 + 173 + 631 + 929 + 244 + 946 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  607 + 462 + 533 + 429 + 861 + 711 + 717 + 910 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  188 + 526 + 095 + 863 + 817 + 349 + 093 + 397 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  836 + 451 + 917 + 426 + 984 + 308 + 957 + 356 ...  [FINAL]  10200 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  818 + 148 + 462 + 581 + 186 + 433 + 939 + 709 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  327 + 051 + 469 + 514 + 624 + 531 + 580 + 405 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  327 + 998 + 676 + 125 + 273 + 882 + 658 + 417 ...  [FINAL]  10323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  928 + 102 + 184 + 235 + 252 + 716 + 316 + 390 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  940 + 491 + 967 + 532 + 625 + 698 + 137 + 475 ...  [FINAL]  10234 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  984 + 322 + 223 + 742 + 841 + 152 + 892 + 559 ...  [FINAL]  10800 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  475 + 339 + 170 + 626 + 891 + 942 + 625 + 431 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  149 + 194 + 690 + 122 + 520 + 259 + 036 + 009 ...  [FINAL]  10300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input        full_response  \\\n",
      "0  579 + 505 + 127 + 767 + 225 + 226 + 733 + 717 ...  [FINAL]  9970 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 8  \n",
      "                                          test_input         full_response  \\\n",
      "0  613 + 076 + 524 + 850 + 145 + 767 + 146 + 335 ...  [FINAL]  10303 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  139 + 669 + 264 + 419 + 504 + 522 + 366 + 193 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  967 + 121 + 785 + 921 + 528 + 032 + 423 + 148 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  923 + 902 + 143 + 858 + 129 + 971 + 373 + 848 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  397 + 185 + 418 + 670 + 410 + 109 + 773 + 697 ...  [FINAL]  10900 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  800 + 199 + 218 + 986 + 306 + 128 + 285 + 946 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  644 + 659 + 233 + 353 + 616 + 873 + 074 + 916 ...  [FINAL]  10300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  168 + 526 + 319 + 624 + 614 + 502 + 235 + 001 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  207 + 594 + 645 + 411 + 682 + 411 + 078 + 238 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  381 + 098 + 228 + 134 + 136 + 151 + 164 + 207 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  106 + 736 + 126 + 534 + 374 + 700 + 070 + 941 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  153 + 902 + 528 + 574 + 430 + 120 + 651 + 255 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  114 + 811 + 259 + 974 + 560 + 734 + 630 + 745 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  618 + 937 + 022 + 044 + 793 + 242 + 078 + 399 ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input         full_response  \\\n",
      "0  545 + 124 + 499 + 296 + 308 + 805 + 969 + 564 ...  [FINAL]  10232 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  577 + 282 + 386 + 452 + 539 + 236 + 039 + 756 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  838 + 892 + 402 + 289 + 064 + 860 + 074 + 408 ...  [FINAL]  10833 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  686 + 585 + 790 + 399 + 515 + 526 + 135 + 249 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  218 + 781 + 947 + 239 + 990 + 732 + 623 + 787 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  384 + 985 + 775 + 849 + 843 + 440 + 785 + 145 ...  [FINAL]  10230 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  104 + 365 + 395 + 161 + 430 + 272 + 346 + 827 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  027 + 416 + 983 + 155 + 677 + 537 + 221 + 276 ...  [FINAL]  10233 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  096 + 553 + 141 + 193 + 862 + 560 + 474 + 159 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  185 + 612 + 783 + 644 + 399 + 322 + 992 + 237 ...  [FINAL]  10300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  538 + 683 + 154 + 349 + 066 + 826 + 009 + 243 ...  [FINAL]  10700 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  619 + 468 + 325 + 254 + 853 + 834 + 462 + 326 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  921 + 970 + 150 + 795 + 525 + 294 + 753 + 599 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  442 + 141 + 649 + 723 + 485 + 185 + 447 + 602 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  643 + 115 + 818 + 779 + 655 + 859 + 448 + 088 ...  [FINAL]  10300 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  510 + 594 + 991 + 030 + 057 + 797 + 353 + 187 ...  [FINAL]  10200 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  252 + 374 + 872 + 045 + 562 + 600 + 881 + 809 ...  [FINAL]  10000 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  125 + 155 + 942 + 220 + 488 + 313 + 908 + 569 ...  [FINAL]  10323 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "                                          test_input         full_response  \\\n",
      "0  657 + 871 + 175 + 323 + 421 + 817 + 016 + 617 ...  [FINAL]  10923 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 9  \n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìä Summary for N_ARY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Accuracy:             29.40% (147/500)\n",
      "Avg Gen Time:         5.921s\n",
      "Avg Tokens:             8.1\n",
      "Total Duration:      3007.7s\n",
      "Throughput:            0.17 samples/sec\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Sample Results for N_ARY (first 10):\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      " test_input       full_response generated_tokens  is_correct  is_degenerate\n",
      "625 + 449 = [FINAL]  1074 [END]                8        True          False\n",
      "976 + 756 = [FINAL]  1732 [END]                8        True          False\n",
      "722 + 324 = [FINAL]  1046 [END]                8        True          False\n",
      "490 + 643 = [FINAL]  1133 [END]                8        True          False\n",
      "118 + 710 =  [FINAL]  828 [END]                7        True          False\n",
      "075 + 884 =  [FINAL]  959 [END]                7        True          False\n",
      "133 + 213 =  [FINAL]  346 [END]                7        True          False\n",
      "092 + 549 =  [FINAL]  641 [END]                7        True          False\n",
      "825 + 702 = [FINAL]  1527 [END]                8        True          False\n",
      "855 + 658 = [FINAL]  1513 [END]                8        True          False\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìù Task: P_HOP\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Total Samples: 300\n",
      "Batch Size: 1 (Sequential)\n",
      "Strategy: Sequential Processing\n",
      "\n",
      "Batch size < 1 or not enough items, processing sequentially.\n",
      "Processing 300 items sequentially...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f2c8a0874543c0974a0b1e29ada8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   p_hop:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D C A B D B C D A C A B A B A C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C A B A D B C A D A B D B A D A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C D D A D C C D A A B C A A A B C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A B A C C A A D C C B D D B D A D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B D C D D D D C C D D C B A C D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B D B B C C B B D B B D B B D B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B A C D A C D D D B B D B A B C ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C B C D A B C D D B C B D C D B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B A D A B D B D D C C B A D B C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B B C C B D B C B A C A A C C C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A B D B A C D D A B B C B A B C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D A B C A A B A D A C A C A B C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D D B C A D B D A C D B D A A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D A B D A A D B A A C B C C D D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D D B B C D A A D C A B C B C D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D A D C D A D C D B D D C D C C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D B B B C B D C C A A D A D D A B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A D A D C B C D C C A A D D A D B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A C B A B B C C D D D A B D D C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D D A B C A C D B C B A D D D C D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C B B C D B C B D C A B D D B D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D D C A A D D C B A B D A D C B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A C A D D A B C A C B A D C C B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A C C A D B A C D B D B C B B C C ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D A B D A A B B A C B D D A B B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A D D A B A D A C C B C A D D D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D C C A A A B D B D B A D C B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A D C B A C A A A B A A B B D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C C C C D C A D B D D A A C D B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D C D D A A A D A C A D B D B D A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D A C D A B B A D B C D D A B A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B A B B D C B C A D D B D D D B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D C A D D D D A A D D A A A D A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D B C D B D B A A D A D A D A B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B B D D B A A A B C D D A C D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D C B C A B C A D D C D D B C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B A A A C A A B C B D A C C C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B A D B B A A C A A D C B C B D C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B A A A C B C C B B D C A B A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D C B B A C B C D B C D D C A B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C C A C A A A A A A D B D D A D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A C C B B D D D C D D C B C D A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B A C D A A C A B C B A A A C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B C D D A B A C A A C C A D D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D A A A B A B B A C A C C A C D C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C A B B C A B A C A D C A B A B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A A A D C A B C D B A C A B B A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C B C C B D C B B A A C D B D A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C C A C B B A A B A B B C C A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C B C A A B D C A A A B D C B A A ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B B C A A D B B C D D B C A C A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D A A B D C B C D D D B A B D A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C C B A A A D C D C A B A C D C D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B B A B A C A B D C C B C C A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C A D D D A A D B C D C D D C D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B B A A A A B C A B D C C C B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B A A D B B C A D A A A A C B D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B A C C C B C B B C B B B A B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D B D D A D B A B C B C B C D D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D B B B A A D D A B B C A C A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D A C D A B A A D B A D A D D D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D A D D C A C D D C B A D C D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B D A A A A A A A B C A D B C A D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C B B C A B A B C D B B D C D B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Sequence: D C B B D A C B C D C D D C C D D B ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C C B C D B D C D B D D C B A A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A A C C D A D D C C D A B B C A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A D A A B D B C A B A B A A A B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C C D D D C D A B C D A B B C B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D A A A D D B D C B B D A C D C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A A B B A B A D C C C B C B B C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B A D A A D B C D D C A D B D A ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D B B A D D B B B B B D B B A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C A D C A A D C D B A C D D C B B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C B D A C A C B D D A A C B B D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D B B D C B B C B C B D D A C A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B B B B A A D D D A A C A C B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B D A C A A D C B C D B A B B B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A A C A C A A C D C D C D B A C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C A A B B D D A C A D C C A D A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D D B A B C C D A A B D D B C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C A D D C C D D C C D C C C C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B C B B D D A A B A C C A C D B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C C D A A D C D A B A C C A B B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C A D C C B A C A A C B A D B A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A A D A A B A B A C A B C A C A D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D C D B C B A B B B D D A B C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B C B C B D A B D C A B B D B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B C A C C A A D C B B D A A C C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B D A C A B C D D B B D B D D C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A B C D A B A D C C A A D C C C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C B C C D D A A B D D C D C B C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D C D A C D A D C A A C C B A B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A A A D A A C D B B B A C A A A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C A C C C B D A A C B C C B D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C D A D B B B C C C D B D D A C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C C C B C C D A B B C B D C B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C B B A A D D C C A B C C C C C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B B D A B B A A A B A A A D C C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B A B C D D C D D C D D C B D C A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A A C C D B B B C C D D D C A C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C C A C B C C B B D A A D B D B D ...  [FINAL]  D [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C D C C C D D C A B B A B B B B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A B D A A A B A B A A C B D D A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A D D B B D B A D A A A A D D C A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C B B B C C D D C A D B D C B B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A C A C D C C A B A A C D D C D A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D D D C B C C B A C D B C A A C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B A A D B B A A C B A B C A B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C D D A D C A B A D C B C C C B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A A B D A D D D D A C A D A C D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C D D B D A D A C D D A B D D A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D C D D A A A A B B B A D C C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C D D A A D C B A D B B C B C B A ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C A D D D C A C A C D A B B D D D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A C A B C B D D D B B D C D A A D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C C B B B D A A C C D A C A C D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B C D A C C A A C A A D B B A D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C D A B D B B D C B C C B A A D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C A C B C A D D C A C B C D B A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D D D A A B D C A B D A C C D B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C D D A C B A B C C B A C A C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A A D C A A D C C B A C C D A D B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B A B D C D A C B B C C A B D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D A D D B C B C A D D A D A D A ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B A C C A B D C B A C B B A B B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B B C C B B A B C C A C C C D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D C D D B B D D C C B A A D D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C A D B C B B D C D A A D D D D D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D D B C C D D B C D A D A A D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C D C C A B D D C B C C A D C D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A D C D A C D D C A D A C A C A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A B A A A B B B B A B A C C D A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A C A D B B D C D A D A A A D A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D A C C C A B C A C D C A C C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D C D C A A B B C C D A D C D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C C A C D A A C B C A C B D B A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C C A C D C D C C D D D C B D B D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C C D A B B A C A B B A A C B A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C C C B A A C A D C D D D D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D B B C A D D B C D B D C A B D A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D B B D C C C A C B D B D B D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C A A D C C B C D C D C D A C A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B A D C D B A A A A C B C C B D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B C B C C A D C A B D D C C B D D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B A D D B A B B C C C B B C D D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C B C D B D B C A B B A D D D B C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D C A D A A D A C A C C D B C B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B B A B C C B D D D A D D C C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C B B D D C C C C C C D A C B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B A D A B D B D A A B D C C C D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C C C A C C B C C A D A C B D A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C C D D C A A C C B B C B A B C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A B D B A B B C A A A B D A D C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C D D D B C C B D A C A A A B B C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B B B B B B C C B A A C A A C A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D A A C D A B B B A B B A D C B C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A A C C D B A C B B D D C D A B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C A A C A B A C A C B B B A B A C ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D D B B B C B D B B A B C C A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D D B A A B D C A D B D A D A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A A D D D A A B D C B B D A A D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C D D A A B B D D D A B A A C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C D A B C A C A B B C D B B D C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A B D A A C D A D B B B C C C A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A D B D A B C D B A D B A C D B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D A A B A A D D A A C D A C B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B C B B D A C B D A B B D A A D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D D D C D B D C A C A A A C D D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B B B C D C A A A D A A B C D C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D C C B A A C C C D B B A C C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B A A C D A C D B A A C C D C A B ...  [FINAL]  D [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A A C B C A D C C C C D D D B B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B C C C B D A C C A A A D D B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B D A D C D C D D B C C C C C B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C B D A C D A B B B D C C D C A D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A B A C C D C B D B C D C D A C C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C B C B A C C A D C A C C B A A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C C C C A A C A D B C A A B D A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C D C C D C C C D B B B A A A B B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C D D B A C A D A C B D C D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B A A C C A C A A D A C B B B D ...  [FINAL]  D [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D A A C B C A A D D B B B C B A D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A D B B A B C A B D D B D A C A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A B D A C B A A A B C B D C C D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D A A B A B A B D A D A C C C A A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D A D B C B C C B A C A D C A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D D D C C A B B B B B B D D D C C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C D B A B B D A B D D D D A D C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C B B D C D B B D A C C A C B D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D B C B A B B D C C A B D B A B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A B D D C C B C A D D C A A B C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C B A B D A D D A B C A D A C D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C D D A D A D D B B C A D B D C ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B B C D C B C A A A A D A D B D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D B D B B B B B B B B D D C C C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D D D B A C B B D D B A D C C C D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B A A D C A D B D A B B A B B D D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Sequence: D D A C D A B B D A A B D D C B B D ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Sequence: C A C C C B D A D B D D D A C D A B ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A A B D A A D A D A A A A A A D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C C C C C C A D C C B D D C C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C D D A A C A A C A B B C B A C ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D D A C C D D B B C C C D A D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A C B A D B B D C A B B B B C A B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B C D A A C C B C C B B B C B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B C C A B D B B D A D C C D D A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D B A C B C C B C D C A C C D A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B A B C D C D B B A C B B B D D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D A C D A C D D C B D D A B C C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D C B A A A C C B A C C C B C C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D C B B C C A D D A D A D D B C A ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B A A B A C A C A B D B C D B C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B B B D D A C C A C C A A C C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C B C B D D D B A C C D A C B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C C A D C A D B D A B D D C A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D C A A B A D D D C D D B B D B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A C A B A C C B B B B A D D A A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B B D D A A D D D B A C C B D C B A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C B C C B A C D B C D D A D D B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A D A D A B C B D D C C C B A D C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D B A A C B A D A C B C D B C D D ...  [FINAL]  D [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C A D A B D D B D B D C C A C B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A A C D C A A B A A B B C B C A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C B C B B A D D B B D A B A A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D C C C D B A C C B B B A C B C C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D B D D A D A A C C D A B D A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D A B C B D D C D C A C D C C A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C C B A C B C C B D A C A A A D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D D B D B C D A B B A A A D B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D D B A A C D B B A D C D C A B B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C A D B A B A A A C A C B C A A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D C A B B C A C B C C A D C A D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D C D D C D A C B D B B D D D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D A A D D C B C B B B C B B D C A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B B B D D D A B B C D B D D C A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B B C A D D C A B B D A B C A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A D A B D C D C B B A A C C B C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C C C D B D B A D D A B A A B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B D C A D D C A A D B B B A A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B B B C A B C C D B D A C C A C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B D A D C D D C C D A A B A C C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C B D A C A C C A B D B C D C A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A B D A A A C C A B D A C B A A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A A C B D C C D C B C A B C A C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B A A C B C A D A A C B D D A A C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Sequence: D A B D C B D C D A B B A B D A B A ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Sequence: D A A C A B A A B B A D D A D A A D ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D B A B B D D A D A D D B B D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C C C A B B D B C A A B D B C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D B A D B B D C C B A A B C D A B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A B D D B B D B B B A A D D A B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C D B B C D D B A B A A C B D D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C C A A D D B B D C D C A B A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B A B D B B B B B B D D D C D B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D D B B A D C B B C A B C C D A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C A C D C A A D C C C A D A B C D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A D B C D D B A A B A B A D D B D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C B A B C C A B A A B D D B D C C ...  [FINAL]  D [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A A D A B D D B B D D C D C A D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B B C B B C D B B B B C A C A B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D C C D C C C A A C C D A B A B A D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B A C C B C D D D A C A C A D C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D C B D D B C B C D B A D C D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D C A B B C A C C A A A D C D C B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D D D C A C B D D A D B A D B D ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B B C A B B A D D A D D A A A B B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C D D A D B C C B D C B A A D A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A D D B A C C D B A C D A B D D C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D C B A D C C D B C B C C B B B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B B D B A A D A B B C C C A A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B D A A A D A D B D D D D C D D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A B A C A B C D B B A C B B B C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A C A A A B A D D A D C C D C D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A C D A A A A C A D D C A D B C A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B C A D A C A C D A A A C C B B A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A D B C C C A D B B A D C C D A B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C A C C D D D D A D C C A B D B B C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C A C B A D D B D A C A B C B A D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D C D A C B D B B D D D C A B A B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B B C A B A C C A B C D C B D D C ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B C B B A D C D C A D D C D B A D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B D D A C A C C B D D D B B B D ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D A C D A B C D D C B C C D D C D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B C D C B D A B A C B B D D B A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A B D B C C C D D A A B A A C D D B ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B C D D B D B B D D B A C D C B B D ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C C D B B B B B A A C D D A C B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D D B B A A C B B C B B B C A B D A ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D B B D B C D A C A D B A A B C C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B B C B D B D A A B C A C B C B C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A C C C D D B C B C C B D A B A C A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C A A D B A A A B B A D D A D D B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C B D B A A B A D A A A C B B C B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B D D A A D C B B B A D D A D B A C ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: A A A D C B C B B C D C D A D D A A ...  [FINAL]  A [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: B A C B C C B B D B C A C B A A B B ...  [FINAL]  B [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: D B B C A B D A A A D B C B D C B B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C C D B A D D A C B C D C A D D A B ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "                                          test_input     full_response  \\\n",
      "0  Sequence: C D A D B B C C B D C D B B D C A C ...  [FINAL]  C [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 4  \n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìä Summary for P_HOP\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Accuracy:             28.00% (84/300)\n",
      "Avg Gen Time:         5.968s\n",
      "Avg Tokens:             3.9\n",
      "Total Duration:      1823.5s\n",
      "Throughput:            0.16 samples/sec\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Sample Results for P_HOP (first 10):\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "                                                  test_input    full_response generated_tokens  is_correct  is_degenerate\n",
      "Sequence: B D C A B D B C D A C A B A B A C D D A A D D C A  [FINAL]  C [END]                4       False          False\n",
      "Sequence: A C A B A D B C A D A B D B A D A A C A A B D A B  [FINAL]  A [END]                4       False          False\n",
      "Sequence: C C D D A D C C D A A B C A A A B C A B C A B D B  [FINAL]  A [END]                4       False          False\n",
      "Sequence: C A B A C C A A D C C B D D B D A D D D D B D C A  [FINAL]  B [END]                4       False          False\n",
      "Sequence: B A B D C D D D D C C D D C B A C D D A B C B A C  [FINAL]  A [END]                4       False          False\n",
      "Sequence: C B D B B C C B B D B B D B B D B D A C D B B D A  [FINAL]  A [END]                4       False          False\n",
      "Sequence: C C B A C D A C D D D B B D B A B C B B B D D D C  [FINAL]  B [END]                4        True          False\n",
      "Sequence: B C B C D A B C D D B C B D C D B D D D A C A B A  [FINAL]  A [END]                4       False          False\n",
      "Sequence: A B A D A B D B D D C C B A D B C B B C D D A D D  [FINAL]  C [END]                4        True          False\n",
      "Sequence: A B B C C B D B C B A C A A C C C A D C D C D D A  [FINAL]  A [END]                4       False          False\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìù Task: IGSM\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Total Samples: 100\n",
      "Batch Size: 1 (Sequential)\n",
      "Strategy: Sequential Processing\n",
      "\n",
      "Batch size < 1 or not enough items, processing sequentially.\n",
      "Processing 100 items sequentially...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba47e4a401b3479692807b9e21295bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   igsm:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          test_input     full_response  \\\n",
      "0  Question. J#F := I#L. F#D := E#K - E#K. H#K :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#G := E#C. C#F := J#K. J#K := O#L. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#N := A#O. N#H := H#C * L#A. O#O :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#F := J#O. I#P := G#A. E#L := H#P. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. C#M := 1. K#P := 2. K#N := D#F * P#H...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. A#G := K#F. K#K := P#K. K#F := F#F. ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#L := 2. L#A := A#B. E#N := H#A + K...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. H#L := E#H. B#H := E#H. H#O := B#A *...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. B#K := F#K * G#M. H#L := G#M. I#E :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#H := O#N - O#N. P#I := 2. A#P := D...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#P := 6. F#A := L#G. L#I := G#O - P...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. B#F := P#J. P#A := 2. C#K := P#J. N#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#M := K#P. E#M := D#C. G#E := J#M. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. B#B := O#D. O#D := 0. F#B := M#K. C#...  [FINAL]  0 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. C#N := P#H * P#H. F#J := O#N. K#J :=...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#I := A#N. F#N := 0. J#G := 0. F#K ...  [FINAL]  0 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. L#C := I#M. I#M := C#O. B#K := 2. O#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#M := N#F. L#N := L#H. E#D := N#F. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#O := L#A. J#I := E#E. C#C := 4. L#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. A#L := M#D. D#A := B#M * B#M. C#N :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. N#E := O#O * M#M. M#M := B#K - F#L. ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. M#H := 1. F#P := 4. L#A := B#D. F#M ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. H#I := I#D. D#F := J#K * J#K. N#M :=...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#F := 0. E#E := M#O. G#E := N#E. O#...  [FINAL]  3 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Question. H#E := 6. C#A := P#G * C#H. A#G := 5...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. B#K := B#G - B#G. F#K := B#G. C#E :=...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#A := G#A * G#A. F#C := B#A + D#K. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#K := H#J. C#B := H#J * K#O. I#J :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#P := P#I * K#M. F#L := K#M * K#M. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#M := M#M. H#P := G#B. O#P := O#B *...  [FINAL]  3 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. B#G := N#J. L#M := 2. E#G := 3. I#G ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#O := E#B. N#P := 6. F#O := O#A. E#...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#I := 0. C#L := D#D. E#N := P#H + P...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. H#J := 4. C#L := I#C. I#C := G#P. L#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#I := P#J. D#I := D#J. M#M := I#D -...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#G := 3. P#N := A#K * A#K. G#O := K...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. E#C := L#N. M#F := L#N - M#O. F#L :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#E := 3. C#O := D#L. G#G := B#P. H#...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. H#H := J#C + C#P. J#C := G#O. P#O :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. K#J := M#O. P#L := M#E - A#A. A#A :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#K := E#B + F#F. B#O := K#J * K#J. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. E#I := 1. P#O := E#C. M#J := K#O. M#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. B#A := 1. N#M := A#N. L#G := 0. G#I ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. C#I := 1. K#J := I#C - I#C. J#N := 1...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#P := L#L. C#K := 2. H#B := F#P. M#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. L#K := J#J * D#G. C#C := A#K. J#C :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. C#I := 4. L#J := G#A. F#I := L#N - L...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#J := H#L. J#A := O#D. M#C := 6. E#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#A := L#G - B#G. F#L := J#F. L#G :=...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#G := 0. K#P := O#A. C#G := 1. F#E ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#L := 5. D#E := G#I * H#J. G#I := 1...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#C := L#L. H#P := 0. D#H := 1. E#E ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#G := L#J. F#A := L#K. I#C := 3. L#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#O := 1. P#L := 2. G#J := M#C. D#H ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. N#H := M#D + G#C. G#C := E#M - B#N. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. M#I := M#A. P#M := 4. M#A := 3. B#B ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. K#F := K#A. C#A := D#C - N#E. K#B :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#J := J#D + H#A. M#B := M#L. G#C :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. A#E := N#G. B#I := 4. D#L := D#P - I...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#D := D#I. H#J := N#F. J#G := B#I +...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#C := I#G. H#I := 5. C#B := 6. A#M ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. O#J := 1. C#I := A#N - A#N. D#N := P...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. L#M := 2. M#O := O#J * M#L. N#C := 3...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#H := A#K. A#B := I#E. I#E := F#B. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#H := I#D + A#A. F#L := C#B + H#I. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. K#F := 5. E#J := O#J + P#J. L#P := B...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#L := N#P. E#B := J#L. P#N := D#M *...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. M#I := L#A + N#H. P#D := M#I. N#H :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. L#I := K#K * C#B. G#B := H#A * J#B. ...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#O := 6. E#L := B#A. L#P := N#H. L#...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. C#I := B#H. A#A := F#I - F#I. I#A :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. G#L := K#A - G#O. F#B := H#H. P#G :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. N#L := D#E - M#L. A#G := M#L. N#J :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#K := C#J. N#F := K#M * C#J. D#K :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. N#E := 2. M#E := K#L. C#G := N#E. M#...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#D := K#A + P#L. F#F := 1. O#A := 1...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. O#G := J#F - J#G. J#F := B#K - N#C. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#L := N#K. G#A := D#I. J#J := K#G. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. N#B := O#O - O#O. D#C := O#O. I#M :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#P := I#D. C#E := C#H. L#O := A#J. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. A#P := 2. N#M := 4. A#G := O#L - H#G...  [FINAL]  0 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. A#G := P#B. I#K := I#H. A#O := C#L -...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. H#A := 0. C#G := D#M * D#M. E#K := N...  [FINAL]  0 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#A := 6. J#I := M#P + E#G. N#F := 2...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. A#C := K#O. O#I := K#O. P#N := F#H. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#D := C#M. I#K := C#M. F#A := D#D. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#O := B#A * B#A. J#B := K#E. N#H :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. N#C := J#J - L#D. B#D := L#D. J#O :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#O := A#O * A#O. J#D := 5. D#A := M...  [FINAL]  6 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. K#I := 4. K#A := 1. M#H := E#M - C#L...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. L#A := D#K - D#K. O#N := G#F. G#F :=...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. C#J := G#P - L#I. M#E := L#I * G#P. ...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. J#G := D#F. C#D := 5. M#C := F#B. H#...  [FINAL]  2 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. L#D := G#H. N#A := P#D * H#C. F#I :=...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. F#G := A#I * G#I. G#P := 3. C#P := G...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. I#F := E#K. M#F := P#H + P#H. H#J :=...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. D#I := H#F + H#F. D#F := L#P + A#O. ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "‚ùå Aborting due to repeated outputs...\n",
      "‚ö†Ô∏è Item failed: Experiment failed: 5 repeated outputs\n",
      "                                          test_input  \\\n",
      "0  Question. B#I := 5. N#K := 1. B#N := J#B * D#K...   \n",
      "\n",
      "                           full_response  generated_tokens  \n",
      "0  Experiment failed: 5 repeated outputs                 0  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. B#C := A#C + P#N. P#C := 0. J#E := 0...  [FINAL]  0 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "                                          test_input     full_response  \\\n",
      "0  Question. P#C := C#E. H#F := 5. P#B := 0. D#B ...  [FINAL]  1 [END]   \n",
      "\n",
      "   generated_tokens  \n",
      "0                 5  \n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìä Summary for IGSM\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Accuracy:             12.00% (12/100)\n",
      "Avg Gen Time:         6.757s\n",
      "Avg Tokens:             4.7\n",
      "Total Duration:       727.5s\n",
      "Throughput:            0.14 samples/sec\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Sample Results for IGSM (first 10):\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "                                                  test_input                         full_response generated_tokens  is_correct  is_degenerate\n",
      "Question. J#F := I#L. F#D := E#K - E#K. H#K := 3. I#L := 0.                       [FINAL]  2 [END]                5       False          False\n",
      "Question. G#G := E#C. C#F := J#K. J#K := O#L. I#A := 6. D#C                       [FINAL]  2 [END]                5       False          False\n",
      "Question. P#N := A#O. N#H := H#C * L#A. O#O := H#N + H#C. H#                      [FINAL]  2 [END]                5        True          False\n",
      "Question. G#F := J#O. I#P := G#A. E#L := H#P. J#P := 3. D#L                       [FINAL]  2 [END]                5       False          False\n",
      "Question. C#M := 1. K#P := 2. K#N := D#F * P#H. M#B := N#P.  Experiment failed: 5 repeated outputs                0       False          False\n",
      "Question. A#G := K#F. K#K := P#K. K#F := F#F. J#C := P#F. K# Experiment failed: 5 repeated outputs                0       False          False\n",
      "Question. F#L := 2. L#A := A#B. E#N := H#A + K#L. A#B := I#F                      [FINAL]  1 [END]                5       False          False\n",
      "Question. H#L := E#H. B#H := E#H. H#O := B#A * I#D. L#P := 0                      [FINAL]  1 [END]                5       False          False\n",
      "Question. B#K := F#K * G#M. H#L := G#M. I#E := A#L - H#L. A#                      [FINAL]  2 [END]                5       False          False\n",
      "Question. D#H := O#N - O#N. P#I := 2. A#P := D#H - A#L. B#I                       [FINAL]  2 [END]                5        True          False\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéØ REASONING PRIMITIVES EVALUATION\n",
      "======================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üß† Running Reasoning Primitives (5-shot)\n",
      "============================================================\n",
      "\n",
      "üìã Task: var_assign_depth_0_code (100 samples)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c99b9eef0948f8898ce03d022c80e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  var_assign_depth_0_code:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Accuracy: 97.00% (97/100)\n",
      "\n",
      "üìã Task: var_assign_depth_0_math (100 samples)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dff8ee1e8574823bfd40521758fe6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  var_assign_depth_0_math:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Accuracy: 100.00% (100/100)\n",
      "\n",
      "üìã Task: var_assign_depth_0_equation (100 samples)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2fcd2684994c86b3d2cb6b5671fad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  var_assign_depth_0_equation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Accuracy: 100.00% (100/100)\n",
      "\n",
      "üìã Task: var_assign_depth_1_code (100 samples)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c307767c53984c7b821b73c66dc778f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  var_assign_depth_1_code:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Accuracy: 89.00% (89/100)\n",
      "\n",
      "üìã Task: var_assign_depth_1_math (100 samples)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4580bfe8487c4aa09a73b6b18e6aeed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  var_assign_depth_1_math:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Accuracy: 93.00% (93/100)\n",
      "\n",
      "üìã Task: var_assign_depth_1_equation (100 samples)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334009881da948eb9a14ce51d95495ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  var_assign_depth_1_equation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Accuracy: 88.00% (88/100)\n",
      "‚úÖ Reasoning primitives evaluation completed\n",
      "\n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "‚úÖ Periodic save: reasoning primitives results to ../results_20251225_132657_UT_3/reasoning_primitives.csv\n",
      "======================================================================\n",
      "üßπ Cleaning up GPU memory...\n",
      "‚úÖ GPU memory freed\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä FINAL EXPERIMENT SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìà Overall Accuracy by Task Type:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "          Accuracy    N\n",
      "task_type              \n",
      "igsm        12.00%  100\n",
      "n_ary       29.40%  500\n",
      "p_hop       28.00%  300\n",
      "\n",
      "üìà Accuracy by UT Steps:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "         Accuracy    N\n",
      "ut_steps              \n",
      "3          27.00%  900\n",
      "\n",
      "üìà Accuracy by Task Type and UT Steps:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "ut_steps      3\n",
      "task_type      \n",
      "igsm       12.0\n",
      "n_ary      29.4\n",
      "p_hop      28.0\n",
      "\n",
      "üìâ Perplexity by UT Steps:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      " ut_steps  perplexity  avg_loss\n",
      "        3    0.241078  1.272621\n",
      "\n",
      "======================================================================\n",
      "üîó Finalizing W&B...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>igsm/accuracy</td><td>‚ñÅ</td></tr><tr><td>igsm/avg_generation_time</td><td>‚ñÅ</td></tr><tr><td>igsm/avg_tokens</td><td>‚ñÅ</td></tr><tr><td>igsm/num_degenerate</td><td>‚ñÅ</td></tr><tr><td>igsm/num_samples</td><td>‚ñÅ</td></tr><tr><td>igsm/throughput</td><td>‚ñÅ</td></tr><tr><td>n_ary/accuracy</td><td>‚ñÅ</td></tr><tr><td>n_ary/avg_generation_time</td><td>‚ñÅ</td></tr><tr><td>n_ary/avg_tokens</td><td>‚ñÅ</td></tr><tr><td>n_ary/num_degenerate</td><td>‚ñÅ</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>igsm/accuracy</td><td>0.12</td></tr><tr><td>igsm/avg_generation_time</td><td>6.75733</td></tr><tr><td>igsm/avg_tokens</td><td>4.65</td></tr><tr><td>igsm/num_degenerate</td><td>0</td></tr><tr><td>igsm/num_samples</td><td>100</td></tr><tr><td>igsm/throughput</td><td>0.13746</td></tr><tr><td>n_ary/accuracy</td><td>0.294</td></tr><tr><td>n_ary/avg_generation_time</td><td>5.92126</td></tr><tr><td>n_ary/avg_tokens</td><td>8.12</td></tr><tr><td>n_ary/num_degenerate</td><td>0</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-wave-152</strong> at: <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/40fxlq9i' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/40fxlq9i</a><br> View project at: <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/content/wandb/run-20251225_132652-40fxlq9i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ W&B session closed\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Periodic save: simple reasoning results to ../results_20251225_132657_UT_3/simple_reasoning.csv\n",
      "‚úÖ Periodic save: perplexity results to ../results_20251225_132657_UT_3/perplexity.csv\n",
      "‚úÖ Periodic save: reasoning primitives results to ../results_20251225_132657_UT_3/reasoning_primitives.csv\n",
      "‚úÖ Configuration saved to ../results_20251225_132657_UT_3/config.json\n",
      "‚úÖ Task templates saved to ../results_20251225_132657_UT_3/task_templates.json\n",
      "An unexpected error occurred: too many values to unpack (expected 3)\n"
     ]
    }
   ],
   "source": [
    "from src.config_loader import load_config_from_json, post_process_config\n",
    "from src.new_runner import run_batch_experiment\n",
    "from src.evaluation_metrics import analyze_experiment_results\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)                          # Python random\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Python hash seed\n",
    "    np.random.seed(seed)                      # NumPy\n",
    "    torch.manual_seed(seed)                   # PyTorch CPU & GPU\n",
    "\n",
    "    # Additional GPU-specific settings\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)      # For multi-GPU\n",
    "\n",
    "set_all_seeds(1415)\n",
    "# 1. Load Configuration from JSON\n",
    "config = load_config_from_json(\"configs/ouro_1.4b_thinking.json\")\n",
    "\n",
    "# 2. Post-process (Convert 'torch.float16' string to object, generate timestamps)\n",
    "config = post_process_config(config)\n",
    "\n",
    "config[\"INFERENCE_STEPS\"] = [3]\n",
    "config[\"OPTIMIZATION\"][\"enable_batch\"] = False\n",
    "# config[\"EVAL_SETTINGS\"][\"calculate_perplexity\"] = False\n",
    "# config[\"DATA\"][\"n_ary\"][\"num_samples_per_level\"] = 0\n",
    "# config[\"DATA\"][\"p_hop\"][\"num_samples_per_level\"] = 0\n",
    "# config[\"DATA\"][\"igsm\"][\"num_samples\"] = 0\n",
    "# config[\"DATA\"][\"reasoning_primitives\"][\"num_samples\"] = 0\n",
    "# config[\"ENABLE_HEAVY_BENCHMARKS\"] = True\n",
    "# 4. Execute\n",
    "print(\"üöÄ Starting Experiment...\")\n",
    "try:\n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    simple_reasoning_results, ppl_results, primitives_results, benchmark_results = run_batch_experiment(config)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:20:53.151440Z",
     "iopub.status.busy": "2025-12-25T11:20:53.151208Z",
     "iopub.status.idle": "2025-12-25T11:20:53.163326Z",
     "shell.execute_reply": "2025-12-25T11:20:53.162701Z",
     "shell.execute_reply.started": "2025-12-25T11:20:53.151421Z"
    },
    "id": "8inXWmVwnzBC",
    "outputId": "d4bf6448-967b-466b-87b6-ae89dd2dfae2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 result folder(s) to zip.\n",
      "   -> Zipping folder: results_20251225_132657_UT_3...\n",
      "   ‚úÖ Created ZIP: results_20251225_132657_UT_3.zip\n",
      "\n",
      "‚úÖ DONE! Successfully zipped 1 out of 1 folder(s).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "from typing import List\n",
    "def find_result_folders(base_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return a list of absolute paths to all directories under `base_path`\n",
    "    whose names start with 'results_'.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(base_path, \"results_*\")\n",
    "    # glob returns both files and directories; filter to directories only\n",
    "    return [p for p in glob.glob(pattern) if os.path.isdir(p)]\n",
    "def zip_folder(folder_path: str, output_base_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Zip the contents of `folder_path` into a file named\n",
    "    <folder_name>.zip` inside `output_base_path`.\n",
    "\n",
    "    Returns True on success, False otherwise.\n",
    "    \"\"\"\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    zip_path = os.path.join(output_base_path, f\"{folder_name}.zip\")\n",
    "    try:\n",
    "        print(f\"   -> Zipping folder: {folder_name}...\")\n",
    "        with zipfile.ZipFile(\n",
    "            zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED\n",
    "        ) as zipf:\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    # Preserve relative path inside the zip\n",
    "                    arcname = os.path.relpath(full_path, os.path.dirname(folder_path))\n",
    "                    zipf.write(full_path, arcname)\n",
    "        print(f\"   ‚úÖ Created ZIP: {os.path.basename(zip_path)}\")\n",
    "        return True\n",
    "    except Exception as exc:\n",
    "        print(f\"   ‚ùå Failed to zip {folder_name}: {exc}\")\n",
    "        return False\n",
    "def zip_stats_results_folders(output_base_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Main driver: locate all result folders and zip each one.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "    result_folders = find_result_folders(output_base_path)\n",
    "    if not result_folders:\n",
    "        print(f\"‚ö†Ô∏è No folders starting with 'results_' found in '{output_base_path}'.\")\n",
    "        return\n",
    "    print(f\"üîç Found {len(result_folders)} result folder(s) to zip.\")\n",
    "    successful = 0\n",
    "    for folder in result_folders:\n",
    "        if zip_folder(folder, output_base_path):\n",
    "            successful += 1\n",
    "    print(\n",
    "        f\"\\n‚úÖ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\"\n",
    "    )\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Prefer an environment variable; fall back to a global if defined\n",
    "        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n",
    "        if not output_root:\n",
    "            raise ValueError(\"OUTPUT_PATH not defined\")\n",
    "        # The script expects a sub‚Äëfolder named 'OuroTrace' under OUTPUT_PATH\n",
    "        target_path = os.path.join(output_root, \"\")\n",
    "        zip_stats_results_folders(target_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "execution": {
     "iopub.execute_input": "2025-12-25T11:20:53.164408Z",
     "iopub.status.busy": "2025-12-25T11:20:53.164181Z",
     "iopub.status.idle": "2025-12-25T11:20:53.250046Z",
     "shell.execute_reply": "2025-12-25T11:20:53.249144Z",
     "shell.execute_reply.started": "2025-12-25T11:20:53.164388Z"
    },
    "id": "0p4QBYsDnzBB",
    "outputId": "ddf28a27-d457-4c57-9376-ad7411a8f9f9",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3738634459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3. Save Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppl_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_hol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhol_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 4. Visualization & Reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_results' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Save Results\n",
    "df_simple = pd.DataFrame(simple_reasoning_results)\n",
    "df_ppl = pd.DataFrame(ppl_results)\n",
    "df_primitives = pd.DataFrame(primitives_results)\n",
    "df_benchmark = pd.DataFrame(benchmark_results)\n",
    "# 4. Visualization & Reporting\n",
    "if not df_simple.empty:\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\nüìä VISUALIZATION\\n\" + \"=\" * 50)\n",
    "\n",
    "    # Summary Tables\n",
    "    # NOTE: The variable 'results_acc' is used here, assuming it holds the raw data\n",
    "    # (list of dicts) required by 'analyze_experiment_results'.\n",
    "    summary = analyze_experiment_results(simple_reasoning_results)\n",
    "    print(\"\\n--- Summary Statistics ---\")\n",
    "    print(summary)\n",
    "\n",
    "    # Plotting\n",
    "    try:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        # Plot 1: Accuracy\n",
    "        acc_summary = (\n",
    "            df_simple.groupby([\"task_type\", \"ut_steps\"])[\"is_correct\"].mean().reset_index()\n",
    "        )\n",
    "        sns.barplot(\n",
    "            data=acc_summary, x=\"ut_steps\", y=\"is_correct\", hue=\"task_type\", ax=axes[0]\n",
    "        )\n",
    "        axes[0].set_title(\"Accuracy by UT Steps\")\n",
    "        axes[0].set_ylabel(\"Accuracy\")\n",
    "        axes[0].yaxis.set_major_formatter(\n",
    "            plt.FuncFormatter(lambda y, _: \"{:.0%}\".format(y))\n",
    "        )\n",
    "\n",
    "        # Plot 2: Time\n",
    "        time_summary = (\n",
    "            df_simple.groupby([\"task_type\", \"ut_steps\"])[\"generation_time\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        sns.barplot(\n",
    "            data=time_summary,\n",
    "            x=\"ut_steps\",\n",
    "            y=\"generation_time\",\n",
    "            hue=\"task_type\",\n",
    "            ax=axes[1],\n",
    "        )\n",
    "        axes[1].set_title(\"Inference Time (s) by UT Steps\")\n",
    "\n",
    "        # Plot 3: Token Count\n",
    "        sns.boxplot(\n",
    "            data=df_simple, x=\"ut_steps\", y=\"generated_tokens\", hue=\"task_type\", ax=axes[2]\n",
    "        )\n",
    "        axes[2].set_title(\"Generated Tokens Distribution\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Visualization error: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to visualize.\")\n",
    "\n",
    "print(\"\\nüèÅ Experiment Complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-25T11:20:53.250519Z",
     "iopub.status.idle": "2025-12-25T11:20:53.250734Z",
     "shell.execute_reply": "2025-12-25T11:20:53.250639Z",
     "shell.execute_reply.started": "2025-12-25T11:20:53.250630Z"
    },
    "id": "3zpz9ccInzBD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Final Inspection:\\n\")\n",
    "print(\"Top 20 Accuracy Report:\\n\")\n",
    "print(df_simple.head(20))\n",
    "print(f\"Full Response:\\n\")\n",
    "print(df_simple[\"full_response\"])\n",
    "print(\"Perplexity Report:\\n\")\n",
    "print(df_ppl.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-25T11:20:53.252034Z",
     "iopub.status.idle": "2025-12-25T11:20:53.252299Z",
     "shell.execute_reply": "2025-12-25T11:20:53.252195Z",
     "shell.execute_reply.started": "2025-12-25T11:20:53.252181Z"
    },
    "id": "EDWCUkMqnzBD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_simple[[\"full_response\", \"generated_tokens\"]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ourotrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00bff0f8b54c4197ab187fcd6e588e39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "00e636d24a1243bba1af2976e5f2a351": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff520aa3e391400581f63a3263013554",
       "IPY_MODEL_d3b973bb7a974c2e9e74ff7952651f21",
       "IPY_MODEL_255351f21e8b434c9723c81e7b5a325b"
      ],
      "layout": "IPY_MODEL_2b0f6ebbae2b49d1980455b75e0389d6"
     }
    },
    "02ac4778ccdd4802be47212eaba2a1d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02f0fa76199841c5977583e53fdaa8e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0377003ca31a4243a1fc05e16ee04e8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a47140d632ad4658aeb600860dea1b8a",
      "max": 2869336434,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ff9fa63aa39421991add3abf091fe2d",
      "value": 2869336434
     }
    },
    "087cab126dd44468b3ef1d5b394d0f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_924bf862d4c04627afe9872513104de3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0eaca6b136024916b5ac13970a66ae39",
      "value": "‚Äá300/300‚Äá[30:23&lt;00:00,‚Äá‚Äá5.92s/it]"
     }
    },
    "0940b5445b4c4a4a9be7ca85e0de2639": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a4841d4045a4790bddcfbb30baf4609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b695f73bc164545bc789335bf81baef",
       "IPY_MODEL_23ebc544202e48898690f47a3369a4e3",
       "IPY_MODEL_1c4b37ea6cb3414c831264c95fb67d56"
      ],
      "layout": "IPY_MODEL_f13e34e7d2704839ac8a24057bdd13d7"
     }
    },
    "0a6b79e0705248228b39371effe2a4f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd7b08f9fdb34d0fb21d136ac53036f1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_128f9484db2d4e19a44b4fb42e634c44",
      "value": "tokenizer_config.json:‚Äá"
     }
    },
    "0d5ee60de5594e18b3126a5fa071193c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d878ea979d84aa5947a25012ac0261d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "0eaca6b136024916b5ac13970a66ae39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eb7ae3617be4994aa24212e5f456b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c77830d137740499fd5cbc00b8e605a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fac34a603e4e4d31b53ca192a0acfa0d",
      "value": "‚Äá4.30k/?‚Äá[00:00&lt;00:00,‚Äá463kB/s]"
     }
    },
    "0eef5f77c30d4586a0b029c4f73ee8b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fe25d33cdc54c468fd6be7e12853787": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0ffb44153c0343c792b52c08c7b9aa29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_127e2867ebbc4d4f97f5e2e18dea976c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c08a74cde5a84274bb9b4a854a21d5ba",
      "value": "‚Äá100/100‚Äá[02:49&lt;00:00,‚Äá‚Äá1.66s/it]"
     }
    },
    "1238ab2d40f744958a700d06534cfb81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "127e2867ebbc4d4f97f5e2e18dea976c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "128f9484db2d4e19a44b4fb42e634c44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12983b08161342b7a07c26c4514b4faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ded889acb0954c5cba7087912b92d21d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ac2242c775c34fda9eea450dffdd8dce",
      "value": "‚Äá100/100‚Äá[12:07&lt;00:00,‚Äá‚Äá7.44s/it]"
     }
    },
    "12eb202be4a942a6ba12537d10622460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14044963aa0a4337b5a4f80e9cfeb8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e03d79995f4a4f7080c42bf0a8c04698",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6189ea16af96404986a327189de50fe3",
      "value": 100
     }
    },
    "170060331edb442e9256fec6644ccbbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "174d54aed8444f59b8079c277a4be223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a2b4e6e6d094331b5d4c1e90fa3d85b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2346f06b7b7540779ee90a260fc3d3ac",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a000075646d043e8818541eba57dd200",
      "value": "‚Äá100/100‚Äá[03:02&lt;00:00,‚Äá‚Äá1.81s/it]"
     }
    },
    "1c4b37ea6cb3414c831264c95fb67d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc56705b4a85494bbf9c55f86906c2a2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c042fc57f3534773898d9022683216de",
      "value": "‚Äá33.4k/?‚Äá[00:00&lt;00:00,‚Äá3.14MB/s]"
     }
    },
    "1cd9b4059f464b2e9241d03337c333c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86a409e057ca45ebbf38e80bfa7da470",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c27ac76c8ecc41f38139b2cd3c38f939",
      "value": 500
     }
    },
    "1d69deb69f16485887b8aa7eced8175e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0d7fc737c674bc8905f3eca84877dd5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_12eb202be4a942a6ba12537d10622460",
      "value": "configuration_ouro.py:‚Äá"
     }
    },
    "1da91bf625f74079992e1329235a185b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dc962b0847a48d591a671c33f60e7a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e180467f1fd4a6b9febca2bf2d8f9e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ef9126e931d491fa5619dd299830c89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f36784a96704d46943899b88d4428ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "224c2b91e4e24d2088c6b7f33bfe1421": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2291ff5734ec4ba1911d6e943ae1f9a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f066616f5e0a4362bfd31bf99dd0f93b",
       "IPY_MODEL_c8c38c84eb2647e8bfd686f99fcd8d64",
       "IPY_MODEL_b2b7e3dcda4c44658ce6cfd0ff754ab3"
      ],
      "layout": "IPY_MODEL_02f0fa76199841c5977583e53fdaa8e4"
     }
    },
    "2302a1d65c2540218df9b9023d3b49ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3173a511c1d845ea985508eb179e330a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_279451c430c245c7b0886608d1e56d93",
      "value": "‚Äá8/8‚Äá[00:47&lt;00:00,‚Äá‚Äá4.46s/it]"
     }
    },
    "2346f06b7b7540779ee90a260fc3d3ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ebc544202e48898690f47a3369a4e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe25d33cdc54c468fd6be7e12853787",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf825b79d93c4814b38ed50bf4703bd6",
      "value": 1
     }
    },
    "243040275475440a9ef530817299f9eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "255351f21e8b434c9723c81e7b5a325b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c0fa98798d246789842b401f5e7a991",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_77e5990db89f48d29d986eed7d5b9776",
      "value": "‚Äá3.52M/?‚Äá[00:00&lt;00:00,‚Äá114MB/s]"
     }
    },
    "265a55436ae14b5e9c9733f439968ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "279451c430c245c7b0886608d1e56d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "287fd97e376145d592117779c56df99a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34f0e68584b541939d3e07a76ebe2e04",
       "IPY_MODEL_3f61c26020a9411ba9131c79b6069d3d",
       "IPY_MODEL_2302a1d65c2540218df9b9023d3b49ce"
      ],
      "layout": "IPY_MODEL_ed351b21ef5e4fa293a0afb033ede290"
     }
    },
    "2afe9861bbb641e6b69ed4a458bacb77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c17054c81cb84fa9b9946dbb8e954ca6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_891b67a5b11b411f9ee5ab0603549e60",
      "value": "‚Äá100/100‚Äá[03:08&lt;00:00,‚Äá‚Äá1.94s/it]"
     }
    },
    "2b0f6ebbae2b49d1980455b75e0389d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b72136554ca4a8f9555779e0f6cca12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "2c77830d137740499fd5cbc00b8e605a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c8a972d0e374bb6b78a50fbdbb591ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e49f6ed7ae54d97a70743215a962167": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "2eb1ce648b244803a75ec172579f2293": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_170060331edb442e9256fec6644ccbbd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3c27f75092bc4a6b81ef2af0436e55a0",
      "value": "special_tokens_map.json:‚Äá100%"
     }
    },
    "30277af41e624effb1c6db107b6b0410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30e5e9df1cc9410a8bba297f9f9800c7",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66b7abaa9fba48f988805741129c3011",
      "value": 100
     }
    },
    "308c4bfab2b044b6b927ca155ed9ce49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30e5e9df1cc9410a8bba297f9f9800c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3149cf61638a481b845a6bb18e4997ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49f1107fe58249588bc0b598ccdf03bc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d91aef84ddbe4cbaa3141f0400fb1728",
      "value": "‚Äá965/965‚Äá[00:00&lt;00:00,‚Äá94.6kB/s]"
     }
    },
    "3173a511c1d845ea985508eb179e330a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32d64f7859d0495087977a8163873269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "334009881da948eb9a14ce51d95495ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f780bfbb1ec4da7bce17feec07e6cf2",
       "IPY_MODEL_78211784f6d3442c9a09a60dd3c63d7f",
       "IPY_MODEL_9241e16aa3f9470481e8b0e2ffc4c415"
      ],
      "layout": "IPY_MODEL_a025bc8e6e504b928a794f77659c9119"
     }
    },
    "34f0e68584b541939d3e07a76ebe2e04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d600c6f93656424c80e65a79edc0a70e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9f9f6b24d95541bb844ec84196280a97",
      "value": "Calculating‚ÄáPPL‚Äá(UT=3):‚Äá100%"
     }
    },
    "39893eb67d6740108ceb4cd8ec90fd4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c8a972d0e374bb6b78a50fbdbb591ce",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_aedd6e462be241fbbf80c71d69f28e6b",
      "value": "‚Äá500/500‚Äá[50:07&lt;00:00,‚Äá‚Äá6.26s/it]"
     }
    },
    "39d6523408794ddcb010e2e9382b9249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eb1ce648b244803a75ec172579f2293",
       "IPY_MODEL_b609829825a44f4a9ca93a3c6dc8502b",
       "IPY_MODEL_3149cf61638a481b845a6bb18e4997ab"
      ],
      "layout": "IPY_MODEL_901128df3b0d419992db002393bf70bc"
     }
    },
    "3a8b36867d5a4796a8351280dc3a9a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bbcf2e880ea4913a294a8ef2bbe4545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c27f75092bc4a6b81ef2af0436e55a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c8fad91575649d89bbc4931c102aad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43e7ff0df93041118e6a268913eca96e",
       "IPY_MODEL_eef7ab4c24d24171bc4a0b14ef329c42",
       "IPY_MODEL_8ad6e8c890e0494680a2f29c73185547"
      ],
      "layout": "IPY_MODEL_4feb5dd1d8a644c087017f78b31dd48f"
     }
    },
    "3de30de904f4473d9a18ec878c091a7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ee883bce4c04f99a4194c6381e14db9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "3f61c26020a9411ba9131c79b6069d3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecbdf29cc83e4d92b35f0812ca11b004",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bbcf2e880ea4913a294a8ef2bbe4545",
      "value": 8
     }
    },
    "3fc57b16685f4158a935c653c992b7a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d5ee60de5594e18b3126a5fa071193c",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66795aad1ac046df81d4771e597b8dda",
      "value": 100
     }
    },
    "43da7795a14f45af849d3bab0c619e3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43e7ff0df93041118e6a268913eca96e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c97106b431fb4bfeb3efee815237acc4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_bcd89ce5674d413eadab34e7f5130baa",
      "value": "merges.txt:‚Äá"
     }
    },
    "4580bfe8487c4aa09a73b6b18e6aeed1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f664bd54b79c4b75b1744fa4364747bb",
       "IPY_MODEL_fe80ab4ed279469aae889f0c8fa368eb",
       "IPY_MODEL_1a2b4e6e6d094331b5d4c1e90fa3d85b"
      ],
      "layout": "IPY_MODEL_d7eadca85cee45b9982a2e5929003a41"
     }
    },
    "49f1107fe58249588bc0b598ccdf03bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bd67410be064937a0af997b6eebde7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c4e01259c6a4cb7a6f063af39249dd4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3a8b36867d5a4796a8351280dc3a9a4b",
      "value": "config.json:‚Äá"
     }
    },
    "4c2715e08e074ae686836ea170599808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4feb5dd1d8a644c087017f78b31dd48f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "528bf418a11747a094e43adf12be7728": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "586e419c4199491abdf9f335f394fccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "591065db87054ba687f0f7ebdf824e3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59f04750571246d5adf68403d3b54fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b144326bc074fb186d70ba2c6357bfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b4d6ab30d0a4cf68cf9d5429a449555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b724a79e703474baa97c846d547afa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_528bf418a11747a094e43adf12be7728",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a2ef69d8474c4f0fb9e537d6b6862b4a",
      "value": "‚Äá‚Äávar_assign_depth_0_equation:‚Äá100%"
     }
    },
    "5d30538a9c734c93b9e3f2f68e7f6fc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "5e5d820b85bf45aa8cb2ff85afa477d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f5b4525963441ea904d91f5b4fd544b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6006d76bed564d53ad11b8dbe2875171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6189ea16af96404986a327189de50fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "657e721703484b88bb066c97d40c0cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66795aad1ac046df81d4771e597b8dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66b7abaa9fba48f988805741129c3011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67551c1d99334956a320731c7986d8a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "680f12fe070a490e9a01c67f48ffa21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6be8d40f8ff94e1e98eae3dd8f124696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9045ddb139c54c298d8effcbfed4a09b",
      "max": 300,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3508523bd7a46aa9073cd0b468dd3d6",
      "value": 300
     }
    },
    "6bf1a8026cd04f23828f448622b3531a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ef9126e931d491fa5619dd299830c89",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0eef5f77c30d4586a0b029c4f73ee8b7",
      "value": "‚Äá1.47k/?‚Äá[00:00&lt;00:00,‚Äá122kB/s]"
     }
    },
    "6c0aeb82560145f3999cce68fd888546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e5c1211f58a455f9c6232afcec02e2f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d0cf358ecb74425f9663d69d30aef4b1",
      "value": "‚Äá‚Äá‚Äáigsm:‚Äá100%"
     }
    },
    "6dbfaa7d00a340cf8d947d0f502ca9c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dff8ee1e8574823bfd40521758fe6c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fca1084afb5845279b083ad832e77416",
       "IPY_MODEL_82871130571744708bdd69db2c4556ed",
       "IPY_MODEL_2afe9861bbb641e6b69ed4a458bacb77"
      ],
      "layout": "IPY_MODEL_2e49f6ed7ae54d97a70743215a962167"
     }
    },
    "6e6a5c83577e4b53b9e1de6a0676e540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fe15a1762f647d2bef3444557848e17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73ca724e8eba42ad9f766d42343fa1f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75e2e19ee06c4fe39fb605f82e7671f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_766ab922a2ca4fdc8cd5aa2fcd403267",
       "IPY_MODEL_1cd9b4059f464b2e9241d03337c333c0",
       "IPY_MODEL_39893eb67d6740108ceb4cd8ec90fd4b"
      ],
      "layout": "IPY_MODEL_5d30538a9c734c93b9e3f2f68e7f6fc8"
     }
    },
    "766ab922a2ca4fdc8cd5aa2fcd403267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e690a92329f3404d889307e627f108c3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a6dec74354744c40bca4cab11c0cfb23",
      "value": "‚Äá‚Äá‚Äán_ary:‚Äá100%"
     }
    },
    "77e5990db89f48d29d986eed7d5b9776": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78211784f6d3442c9a09a60dd3c63d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_224c2b91e4e24d2088c6b7f33bfe1421",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5d13e3ee0114ee19bd716e67302e899",
      "value": 100
     }
    },
    "7b86ab3075094e4d924c32cf77dc8b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_174d54aed8444f59b8079c277a4be223",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_43da7795a14f45af849d3bab0c619e3d",
      "value": "‚Äá100/100‚Äá[02:59&lt;00:00,‚Äá‚Äá1.73s/it]"
     }
    },
    "7c0fa98798d246789842b401f5e7a991": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dda006b7a2f414f916e6ab423c1a5d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "7e5c1211f58a455f9c6232afcec02e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f780bfbb1ec4da7bce17feec07e6cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dbfaa7d00a340cf8d947d0f502ca9c3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b0d2d89d5bc64322ae7d9f885470b84d",
      "value": "‚Äá‚Äávar_assign_depth_1_equation:‚Äá100%"
     }
    },
    "80c094f4a3f540d7b6bc27bcef5fbaec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82871130571744708bdd69db2c4556ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cb6c3f88dd346b499d7c00f4f3bf6ce",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c2715e08e074ae686836ea170599808",
      "value": 100
     }
    },
    "86a409e057ca45ebbf38e80bfa7da470": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891b67a5b11b411f9ee5ab0603549e60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ad6e8c890e0494680a2f29c73185547": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e2a7f67db94fae8ce893ad901fac1a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1dc962b0847a48d591a671c33f60e7a1",
      "value": "‚Äá466k/?‚Äá[00:00&lt;00:00,‚Äá29.0MB/s]"
     }
    },
    "8b695f73bc164545bc789335bf81baef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae1c0af3d107451fb772ba90bbc7fde0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_73ca724e8eba42ad9f766d42343fa1f2",
      "value": "modeling_ouro.py:‚Äá"
     }
    },
    "901128df3b0d419992db002393bf70bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9045ddb139c54c298d8effcbfed4a09b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9241e16aa3f9470481e8b0e2ffc4c415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3de30de904f4473d9a18ec878c091a7c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_67551c1d99334956a320731c7986d8a1",
      "value": "‚Äá100/100‚Äá[02:51&lt;00:00,‚Äá‚Äá1.79s/it]"
     }
    },
    "924bf862d4c04627afe9872513104de3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92c99b9eef0948f8898ce03d022c80e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9cbb14496b9a4ab3960bbb46f8584312",
       "IPY_MODEL_3fc57b16685f4158a935c653c992b7a1",
       "IPY_MODEL_7b86ab3075094e4d924c32cf77dc8b15"
      ],
      "layout": "IPY_MODEL_3ee883bce4c04f99a4194c6381e14db9"
     }
    },
    "9b6b40b787b748dcaee129a002da764b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9c4e01259c6a4cb7a6f063af39249dd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cb6c3f88dd346b499d7c00f4f3bf6ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cbb14496b9a4ab3960bbb46f8584312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f5b4525963441ea904d91f5b4fd544b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b1e72c05c5494b8981ac2a06ba687ffa",
      "value": "‚Äá‚Äávar_assign_depth_0_code:‚Äá100%"
     }
    },
    "9e2fcd2684994c86b3d2cb6b5671fad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b724a79e703474baa97c846d547afa7",
       "IPY_MODEL_ae896314d0da4fb693199e0197144f81",
       "IPY_MODEL_d38b03c312c64d0699d9add3d16b9449"
      ],
      "layout": "IPY_MODEL_7dda006b7a2f414f916e6ab423c1a5d9"
     }
    },
    "9f9f6b24d95541bb844ec84196280a97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ff9fa63aa39421991add3abf091fe2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a000075646d043e8818541eba57dd200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a025bc8e6e504b928a794f77659c9119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a0d7fc737c674bc8905f3eca84877dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2ef69d8474c4f0fb9e537d6b6862b4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a47140d632ad4658aeb600860dea1b8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58cb076794e42a3bffef58a8641b529": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6999d1edf6d4b2b953ebf8a969e6df3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a6dec74354744c40bca4cab11c0cfb23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac2242c775c34fda9eea450dffdd8dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae1c0af3d107451fb772ba90bbc7fde0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae896314d0da4fb693199e0197144f81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5b4463b3bab43d29bb9427ebcb4b5df",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2ea13681cc8476c8d2d0f6ed00e00b4",
      "value": 100
     }
    },
    "aedd6e462be241fbbf80c71d69f28e6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af7342dcf91c4ad49f1515d5011991fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d69deb69f16485887b8aa7eced8175e",
       "IPY_MODEL_f27fa9d55d324b8ba5b5684b321fd63d",
       "IPY_MODEL_f8c8fa759c764996a4e20505eef8ae8a"
      ],
      "layout": "IPY_MODEL_1e180467f1fd4a6b9febca2bf2d8f9e9"
     }
    },
    "b09e7737f46b49d49d53385ed4452efe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0d2d89d5bc64322ae7d9f885470b84d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1e72c05c5494b8981ac2a06ba687ffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b26f309881184bea8c466d93f5272bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b09e7737f46b49d49d53385ed4452efe",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_32d64f7859d0495087977a8163873269",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "b2b7e3dcda4c44658ce6cfd0ff754ab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2cfc03dfba844818e707df380c1764b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_586e419c4199491abdf9f335f394fccf",
      "value": "‚Äá801k/?‚Äá[00:00&lt;00:00,‚Äá30.2MB/s]"
     }
    },
    "b2f2c8a0874543c0974a0b1e29ada8ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bad6e2e9aa6743a197a23cbb69f7beb2",
       "IPY_MODEL_6be8d40f8ff94e1e98eae3dd8f124696",
       "IPY_MODEL_087cab126dd44468b3ef1d5b394d0f13"
      ],
      "layout": "IPY_MODEL_0d878ea979d84aa5947a25012ac0261d"
     }
    },
    "b3b8f0b5d6944f129ea48094f15c42a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b609829825a44f4a9ca93a3c6dc8502b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1da91bf625f74079992e1329235a185b",
      "max": 965,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e6a5c83577e4b53b9e1de6a0676e540",
      "value": 965
     }
    },
    "ba47e4a401b3479692807b9e21295bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c0aeb82560145f3999cce68fd888546",
       "IPY_MODEL_14044963aa0a4337b5a4f80e9cfeb8fa",
       "IPY_MODEL_12983b08161342b7a07c26c4514b4faf"
      ],
      "layout": "IPY_MODEL_d023d11ec64e4d50b2a6facabdcfaf11"
     }
    },
    "bad6e2e9aa6743a197a23cbb69f7beb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02ac4778ccdd4802be47212eaba2a1d0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_df40151cabad423aad29237f0ff28254",
      "value": "‚Äá‚Äá‚Äáp_hop:‚Äá100%"
     }
    },
    "bcd89ce5674d413eadab34e7f5130baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdc46d40d0624f6fb779480f30505992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a6b79e0705248228b39371effe2a4f8",
       "IPY_MODEL_c506b78df32d4e0385aeff435f9f0573",
       "IPY_MODEL_0eb7ae3617be4994aa24212e5f456b44"
      ],
      "layout": "IPY_MODEL_0940b5445b4c4a4a9be7ca85e0de2639"
     }
    },
    "c042fc57f3534773898d9022683216de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c08a74cde5a84274bb9b4a854a21d5ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c17054c81cb84fa9b9946dbb8e954ca6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1e0ea4bec734f6d8a5b95f78befcc91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27ac76c8ecc41f38139b2cd3c38f939": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c307767c53984c7b821b73c66dc778f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2c7dcaea33f4b0c9a00ae0612d88ea7",
       "IPY_MODEL_30277af41e624effb1c6db107b6b0410",
       "IPY_MODEL_0ffb44153c0343c792b52c08c7b9aa29"
      ],
      "layout": "IPY_MODEL_d548bf72e90243eab3a845d961d0eead"
     }
    },
    "c506b78df32d4e0385aeff435f9f0573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6999d1edf6d4b2b953ebf8a969e6df3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fe15a1762f647d2bef3444557848e17",
      "value": 1
     }
    },
    "c8c38c84eb2647e8bfd686f99fcd8d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b6b40b787b748dcaee129a002da764b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f36784a96704d46943899b88d4428ee",
      "value": 1
     }
    },
    "c97106b431fb4bfeb3efee815237acc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9853f28d4a34033ab4381503e7ba9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b26f309881184bea8c466d93f5272bda",
       "IPY_MODEL_0377003ca31a4243a1fc05e16ee04e8a",
       "IPY_MODEL_defad53d63a743579977e43ca6934d24"
      ],
      "layout": "IPY_MODEL_e3fd5d05c0de4d608d5f79e727cc9f38"
     }
    },
    "cc56705b4a85494bbf9c55f86906c2a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cca0c3d6164b4fe98ffd9d4301a73fde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd11c1fd898c484a8ffd770004f67066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd7b08f9fdb34d0fb21d136ac53036f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf825b79d93c4814b38ed50bf4703bd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d023d11ec64e4d50b2a6facabdcfaf11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "d0cf358ecb74425f9663d69d30aef4b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2080b903a80478da504a7fa6fde8cfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d2ea13681cc8476c8d2d0f6ed00e00b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3508523bd7a46aa9073cd0b468dd3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d38b03c312c64d0699d9add3d16b9449": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5d8ec708995480c99ef8dc1d1806475",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_308c4bfab2b044b6b927ca155ed9ce49",
      "value": "‚Äá100/100‚Äá[02:57&lt;00:00,‚Äá‚Äá1.78s/it]"
     }
    },
    "d3b973bb7a974c2e9e74ff7952651f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b72136554ca4a8f9555779e0f6cca12",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_265a55436ae14b5e9c9733f439968ac6",
      "value": 1
     }
    },
    "d3e2a7f67db94fae8ce893ad901fac1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d548bf72e90243eab3a845d961d0eead": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "d5b4463b3bab43d29bb9427ebcb4b5df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d8ec708995480c99ef8dc1d1806475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d600c6f93656424c80e65a79edc0a70e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7eadca85cee45b9982a2e5929003a41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "d91aef84ddbe4cbaa3141f0400fb1728": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ded889acb0954c5cba7087912b92d21d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "defad53d63a743579977e43ca6934d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_591065db87054ba687f0f7ebdf824e3e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_00bff0f8b54c4197ab187fcd6e588e39",
      "value": "‚Äá2.87G/2.87G‚Äá[01:04&lt;00:00,‚Äá47.0MB/s]"
     }
    },
    "df40151cabad423aad29237f0ff28254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df9b669447944921be88020e1a3b49ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "dfbc1053c2e84bfb8d05d7e5f88b89f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2080b903a80478da504a7fa6fde8cfb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_680f12fe070a490e9a01c67f48ffa21b",
      "value": 1
     }
    },
    "e03d79995f4a4f7080c42bf0a8c04698": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2622ff0f2bf42268e31c725498658d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2c7dcaea33f4b0c9a00ae0612d88ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f687f481d4434014b18071565099df95",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_80c094f4a3f540d7b6bc27bcef5fbaec",
      "value": "‚Äá‚Äávar_assign_depth_1_code:‚Äá100%"
     }
    },
    "e2cfc03dfba844818e707df380c1764b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3fd5d05c0de4d608d5f79e727cc9f38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e690a92329f3404d889307e627f108c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7d94bb4eefe48e98f5571cea360d804": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ecbdf29cc83e4d92b35f0812ca11b004": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed351b21ef5e4fa293a0afb033ede290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edfb3980cc964ddcab8e6ad051f57918": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bd67410be064937a0af997b6eebde7b",
       "IPY_MODEL_dfbc1053c2e84bfb8d05d7e5f88b89f5",
       "IPY_MODEL_6bf1a8026cd04f23828f448622b3531a"
      ],
      "layout": "IPY_MODEL_e2622ff0f2bf42268e31c725498658d9"
     }
    },
    "eef7ab4c24d24171bc4a0b14ef329c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_243040275475440a9ef530817299f9eb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b4d6ab30d0a4cf68cf9d5429a449555",
      "value": 1
     }
    },
    "f066616f5e0a4362bfd31bf99dd0f93b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a58cb076794e42a3bffef58a8641b529",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6006d76bed564d53ad11b8dbe2875171",
      "value": "vocab.json:‚Äá"
     }
    },
    "f13e34e7d2704839ac8a24057bdd13d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f27fa9d55d324b8ba5b5684b321fd63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df9b669447944921be88020e1a3b49ef",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1238ab2d40f744958a700d06534cfb81",
      "value": 1
     }
    },
    "f5d13e3ee0114ee19bd716e67302e899": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f664bd54b79c4b75b1744fa4364747bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1e0ea4bec734f6d8a5b95f78befcc91",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_59f04750571246d5adf68403d3b54fd9",
      "value": "‚Äá‚Äávar_assign_depth_1_math:‚Äá100%"
     }
    },
    "f687f481d4434014b18071565099df95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8c8fa759c764996a4e20505eef8ae8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd11c1fd898c484a8ffd770004f67066",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fe97b2c6f4b5474392ef8406a4e9ea4d",
      "value": "‚Äá11.6k/?‚Äá[00:00&lt;00:00,‚Äá1.08MB/s]"
     }
    },
    "fac34a603e4e4d31b53ca192a0acfa0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fca1084afb5845279b083ad832e77416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cca0c3d6164b4fe98ffd9d4301a73fde",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_657e721703484b88bb066c97d40c0cab",
      "value": "‚Äá‚Äávar_assign_depth_0_math:‚Äá100%"
     }
    },
    "fe80ab4ed279469aae889f0c8fa368eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3b8f0b5d6944f129ea48094f15c42a4",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7d94bb4eefe48e98f5571cea360d804",
      "value": 100
     }
    },
    "fe97b2c6f4b5474392ef8406a4e9ea4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff520aa3e391400581f63a3263013554": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e5d820b85bf45aa8cb2ff85afa477d1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5b144326bc074fb186d70ba2c6357bfe",
      "value": "tokenizer.json:‚Äá"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
