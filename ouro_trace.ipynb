{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"gpuType":"T4","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"030e5d70d47647ea9c0dee7d3c793749":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3354b005dea7425db4694cc3fc82172b","IPY_MODEL_2d225ae48e9240dda3ba4332f03789ea","IPY_MODEL_4ad5443483e540cc899e4da94fdd9147"],"layout":"IPY_MODEL_cfa315ea61ca49c8b68e9a0e00785d56"}},"3354b005dea7425db4694cc3fc82172b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b63abc3e15564dfeb18b7f32b561b7cf","placeholder":"​","style":"IPY_MODEL_f1cbf0b7c6fb48b3a094fe2c508a8662","value":"Calculating PPL (UT=8): 100%"}},"2d225ae48e9240dda3ba4332f03789ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19dd5a88238e496ea7582eab65ff9d1a","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_189b1f92bfd441c29dc49ef20307286e","value":8}},"4ad5443483e540cc899e4da94fdd9147":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd71b1ae6565402caba7db39a8b2911d","placeholder":"​","style":"IPY_MODEL_b895cc67d77c4ef386ae6d36ea3763cd","value":" 8/8 [02:16&lt;00:00, 12.64s/it]"}},"cfa315ea61ca49c8b68e9a0e00785d56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b63abc3e15564dfeb18b7f32b561b7cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1cbf0b7c6fb48b3a094fe2c508a8662":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19dd5a88238e496ea7582eab65ff9d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"189b1f92bfd441c29dc49ef20307286e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd71b1ae6565402caba7db39a8b2911d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b895cc67d77c4ef386ae6d36ea3763cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a16f618ae4e54ccba5e53bd12cb5ca62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bcb00faafcb4cd88de64b19ba212f4d","IPY_MODEL_a348dea938d140cdb29a471d756f796e","IPY_MODEL_41e4dc728f4a4e88a3253f542a40c3b3"],"layout":"IPY_MODEL_218f44a2a97047b2a401e93e28490f80"}},"6bcb00faafcb4cd88de64b19ba212f4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b246da7b2fa4e14ba25acc9d6c5d5ef","placeholder":"​","style":"IPY_MODEL_ec85e0e989b7455bb62af345f8890590","value":"  var_assign_depth_0_code: 100%"}},"a348dea938d140cdb29a471d756f796e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_830e5e68cb0542da8f2337b6e05040b4","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7db0f6a2755442095d549b2b410f55b","value":100}},"41e4dc728f4a4e88a3253f542a40c3b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49d6398b23b9426ca6163abdb5d4f7c5","placeholder":"​","style":"IPY_MODEL_ff918d2f818f4c579e9864ffa244b85d","value":" 100/100 [08:05&lt;00:00,  4.78s/it]"}},"218f44a2a97047b2a401e93e28490f80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1b246da7b2fa4e14ba25acc9d6c5d5ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec85e0e989b7455bb62af345f8890590":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"830e5e68cb0542da8f2337b6e05040b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7db0f6a2755442095d549b2b410f55b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49d6398b23b9426ca6163abdb5d4f7c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff918d2f818f4c579e9864ffa244b85d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71ee8681b3af42f1bc9a550ac6f06873":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32407569c5134661a19c81e9251630ee","IPY_MODEL_2582e982cc7a4631943f29154d8ea16b","IPY_MODEL_364ec44a4b54402abfd348382d1995bc"],"layout":"IPY_MODEL_73d1080db01d4f38a75674291d9ffbf3"}},"32407569c5134661a19c81e9251630ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_282e53cba3ee45a99b247536d647e69e","placeholder":"​","style":"IPY_MODEL_6368e65a8b1d4f85b73df777d2a8acb4","value":"  var_assign_depth_0_math: 100%"}},"2582e982cc7a4631943f29154d8ea16b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_09ea87de086c422991d6bd8ff92f1476","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0517e5b7b162403dbacd93f7eedd441c","value":100}},"364ec44a4b54402abfd348382d1995bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4af1800c888f41599687d5355d435369","placeholder":"​","style":"IPY_MODEL_d03bbbcae9fd482e97e62165ca01a368","value":" 100/100 [08:15&lt;00:00,  4.54s/it]"}},"73d1080db01d4f38a75674291d9ffbf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"282e53cba3ee45a99b247536d647e69e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6368e65a8b1d4f85b73df777d2a8acb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09ea87de086c422991d6bd8ff92f1476":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0517e5b7b162403dbacd93f7eedd441c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4af1800c888f41599687d5355d435369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d03bbbcae9fd482e97e62165ca01a368":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05c2b41a25cb430299b979990006f307":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c46f3bd9a8a4d89aebd24e96b888eaa","IPY_MODEL_1de0e87e63c04d09bdfced8b1f131cbc","IPY_MODEL_762c688139014e63a5d82e0ab31df83b"],"layout":"IPY_MODEL_2435b71004724038987a64ee49ede31b"}},"4c46f3bd9a8a4d89aebd24e96b888eaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc52da185bd94b118cffc10b95395c0d","placeholder":"​","style":"IPY_MODEL_98470ff4b5214905a8053ee6abf3714c","value":"  var_assign_depth_0_equation: 100%"}},"1de0e87e63c04d09bdfced8b1f131cbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b8e55fdcb64fc7bbe6fffaa44df5d3","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0efc8a45246c44eb84da7963d2d4a4ef","value":100}},"762c688139014e63a5d82e0ab31df83b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20ce4caf5ec041deadd791b1145f7c30","placeholder":"​","style":"IPY_MODEL_38cc2f8228c6491aace159adae75cead","value":" 100/100 [07:52&lt;00:00,  4.53s/it]"}},"2435b71004724038987a64ee49ede31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cc52da185bd94b118cffc10b95395c0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98470ff4b5214905a8053ee6abf3714c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80b8e55fdcb64fc7bbe6fffaa44df5d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efc8a45246c44eb84da7963d2d4a4ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20ce4caf5ec041deadd791b1145f7c30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38cc2f8228c6491aace159adae75cead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc60ba79431646048acec97037d64537":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a5e656a3c6043a4ad6510bfb499d8a7","IPY_MODEL_7271295655554dccacaec86a99e4b874","IPY_MODEL_a433630711644edebc6aac3f629a1390"],"layout":"IPY_MODEL_e0eb4bf70abf484e842f0632cfc9be3d"}},"6a5e656a3c6043a4ad6510bfb499d8a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6362748c820f4e0c809a867229d37851","placeholder":"​","style":"IPY_MODEL_d54b9be8e48f44f3950e49b9363b02d9","value":"  var_assign_depth_1_code: 100%"}},"7271295655554dccacaec86a99e4b874":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ebbbe246467421782e467db767aa995","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71b851688fbf410bae6b1a44140f42fb","value":100}},"a433630711644edebc6aac3f629a1390":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2fbd7e07c8a411bb982b67bfa3a2722","placeholder":"​","style":"IPY_MODEL_d18f1c309a1b4470b61b0fe3fa441837","value":" 100/100 [07:32&lt;00:00,  4.49s/it]"}},"e0eb4bf70abf484e842f0632cfc9be3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"6362748c820f4e0c809a867229d37851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d54b9be8e48f44f3950e49b9363b02d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ebbbe246467421782e467db767aa995":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71b851688fbf410bae6b1a44140f42fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2fbd7e07c8a411bb982b67bfa3a2722":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d18f1c309a1b4470b61b0fe3fa441837":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa526860703d4a2fa6234c7d01be7260":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fff381cfcc67449f896a912ea6222e82","IPY_MODEL_c86a47732a5c4a3bbd5fe74e091211b5","IPY_MODEL_35194af6dc2341549db31b74813b0f28"],"layout":"IPY_MODEL_7f2e51a0e0f742489d2d7c60474be6bd"}},"fff381cfcc67449f896a912ea6222e82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd4597f0f4564f4b9d74104d9a29a96a","placeholder":"​","style":"IPY_MODEL_61d3062eb3f1443caa87ecaf20ee817e","value":"  var_assign_depth_1_math: 100%"}},"c86a47732a5c4a3bbd5fe74e091211b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_775c90d1551f4574876a4cabc4c16d54","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_270856e780f340ce86d32b89000baeaf","value":100}},"35194af6dc2341549db31b74813b0f28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7801cd32c71047d2bd9726558c79f3a2","placeholder":"​","style":"IPY_MODEL_fad5147665d948c4beac31c78c47b979","value":" 100/100 [08:01&lt;00:00,  4.88s/it]"}},"7f2e51a0e0f742489d2d7c60474be6bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"bd4597f0f4564f4b9d74104d9a29a96a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d3062eb3f1443caa87ecaf20ee817e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"775c90d1551f4574876a4cabc4c16d54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"270856e780f340ce86d32b89000baeaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7801cd32c71047d2bd9726558c79f3a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fad5147665d948c4beac31c78c47b979":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc0dbc1eaa23421cada26a18994289fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cc1e2fee62346b68b6b21a0e9842bf0","IPY_MODEL_e17a89b57db34f9388d1ee2f869be83d","IPY_MODEL_1f7aaee04ead4f4db10f4a7f4bd8290a"],"layout":"IPY_MODEL_5bc60176deb14f609ba00e727b39df3f"}},"4cc1e2fee62346b68b6b21a0e9842bf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c42d31b5018b4eb89a6cd539cc069534","placeholder":"​","style":"IPY_MODEL_094b2bf7829d42e6a63b1bf0ab939d88","value":"  var_assign_depth_1_equation: 100%"}},"e17a89b57db34f9388d1ee2f869be83d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0395cefb9c6a49808332eb1c13a8183a","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d159c8af2ac40a7b22a305ec50aac41","value":100}},"1f7aaee04ead4f4db10f4a7f4bd8290a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dc1ff4a305e43e9aff2995770c5d8ce","placeholder":"​","style":"IPY_MODEL_48a6c64a24c34b0bbde4f50dbb4e8a3c","value":" 100/100 [07:10&lt;00:00,  4.12s/it]"}},"5bc60176deb14f609ba00e727b39df3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c42d31b5018b4eb89a6cd539cc069534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094b2bf7829d42e6a63b1bf0ab939d88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0395cefb9c6a49808332eb1c13a8183a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d159c8af2ac40a7b22a305ec50aac41":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4dc1ff4a305e43e9aff2995770c5d8ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a6c64a24c34b0bbde4f50dbb4e8a3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup libraries","metadata":{"id":"S0M-JZCdnzA6"}},{"cell_type":"code","source":"!uv pip install --upgrade pip\n!uv pip uninstall transformers tokenizers accelerate -q\n\n!uv pip install \"transformers==4.56.0\" \"protobuf==5.29.3\" -q\n!uv pip install torch datasets -q\n!uv pip install pandas matplotlib seaborn tqdm wandb pyyaml\n!uv pip install bitsandbytes accelerate optimum lm_eval\n# !uv pip install -r requirements.txt\n!uv pip install --force-reinstall --no-cache-dir \"numpy<2.0\"","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:42:37.759515Z","iopub.execute_input":"2025-12-23T16:42:37.759691Z","iopub.status.idle":"2025-12-23T16:43:07.201552Z","shell.execute_reply.started":"2025-12-23T16:42:37.759674Z","shell.execute_reply":"2025-12-23T16:43:07.200825Z"},"id":"tjC_YOBlnzA-","outputId":"57ddb2c1-f656-485d-c5ee-785875be74ed","trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 118ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 147ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 112ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m110 packages\u001b[0m \u001b[2min 2.77s\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m18 packages\u001b[0m \u001b[2min 2.58s\u001b[0m\u001b[0m                                            \n\u001b[2K\u001b[2mInstalled \u001b[1m18 packages\u001b[0m \u001b[2min 301ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.49.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdataproperty\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mjsonlines\u001b[0m\u001b[2m==4.0.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-eval\u001b[0m\u001b[2m==0.4.9.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmbstrdecoder\u001b[0m\u001b[2m==1.1.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==2.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpathvalidate\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mportalocker\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpytablewriter\u001b[0m\u001b[2m==1.2.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msacrebleu\u001b[0m\u001b[2m==2.5.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msqlitedict\u001b[0m\u001b[2m==2.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtabledata\u001b[0m\u001b[2m==1.3.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtcolorpy\u001b[0m\u001b[2m==0.1.7\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtqdm-multiprocess\u001b[0m\u001b[2m==0.0.11\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtypepy\u001b[0m\u001b[2m==1.3.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mword2number\u001b[0m\u001b[2m==1.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 132ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 399ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 77ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Suppress warnings","metadata":{"id":"7t_XpUsOs_my"}},{"cell_type":"code","source":"# Suppress warnings for clean output\nimport warnings\nimport os\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nos.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\nprint(\"✅ Packages installed successfully!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:43:07.203387Z","iopub.execute_input":"2025-12-23T16:43:07.203592Z","iopub.status.idle":"2025-12-23T16:43:07.208478Z","shell.execute_reply.started":"2025-12-23T16:43:07.203572Z","shell.execute_reply":"2025-12-23T16:43:07.207760Z"},"id":"t3KSZamlnzA_","outputId":"10de497f-7b99-42f2-e9f2-dc2585def0fb","trusted":true},"outputs":[{"name":"stdout","text":"✅ Packages installed successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Install Libraries","metadata":{"id":"abWE_VV3s_my"}},{"cell_type":"code","source":"\"Built-in libraries\"\nimport re\nimport sys\nimport gc\nimport time\nimport json\nimport hashlib\nimport glob\nimport zipfile\nfrom io import StringIO\nfrom datetime import datetime\nfrom typing import Dict, List, Optional, Tuple, Any\nimport yaml\nimport logging\nimport random\n\n\"Deep learning and NLP libraries\"\nimport torch\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    GenerationConfig,\n    logging as hf_logging\n)\n\n\"Data processing libraries\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport wandb\nfrom tqdm.auto import tqdm\nfrom IPython import get_ipython\n\n# Configure logging\nlogging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\nhf_logging.set_verbosity_error()\n\n\nprint(f\"Python Version: {sys.version}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA Version: {torch.version.cuda}\")\n!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:43:07.209120Z","iopub.execute_input":"2025-12-23T16:43:07.209323Z","iopub.status.idle":"2025-12-23T16:43:19.358306Z","shell.execute_reply.started":"2025-12-23T16:43:07.209308Z","shell.execute_reply":"2025-12-23T16:43:19.357433Z"},"id":"vW3-Anw9nzBA","outputId":"a2bca20b-ecd9-4b10-c773-cc8e70c7eba3","trusted":true},"outputs":[{"name":"stdout","text":"Python Version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch Version: 2.6.0+cu124\nCUDA Available: True\nCUDA Version: 12.4\nTue Dec 23 16:43:19 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   40C    P8             11W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8             11W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"✅ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"✅ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"⚠️ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"⚠️ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"📂 Data Path: {base_data_path}\")\n    print(f\"📦 Output Path: {base_output_path}\")\n\n    return base_data_path, base_output_path, environment_name\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:43:19.359562Z","iopub.execute_input":"2025-12-23T16:43:19.359910Z","iopub.status.idle":"2025-12-23T16:43:19.367083Z","shell.execute_reply.started":"2025-12-23T16:43:19.359862Z","shell.execute_reply":"2025-12-23T16:43:19.366399Z"},"id":"NxqV6hTMs_mz","outputId":"4dff7511-debd-45dd-8798-acec74a33f73","trusted":true},"outputs":[{"name":"stdout","text":"✅ Environment: Kaggle\n📂 Data Path: /kaggle/input/\n📦 Output Path: /kaggle/working/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Setup WANDB","metadata":{"id":"m0HV8HMrs_mz"}},{"cell_type":"code","source":"import os\nimport wandb\n\nif \"colab\" in ENV_NAME:\n    from google.colab import userdata\n    try:\n        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n        wandb_key = userdata.get('WANDB_API_KEY')\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n\n# 2. Check if running in Kaggle\nelif \"kaggle\" in ENV_NAME:\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:43:19.367853Z","iopub.execute_input":"2025-12-23T16:43:19.368454Z","iopub.status.idle":"2025-12-23T16:43:26.452513Z","shell.execute_reply.started":"2025-12-23T16:43:19.368424Z","shell.execute_reply":"2025-12-23T16:43:26.451905Z"},"id":"UaOteqd3nzBA","outputId":"d0492386-00c0-4801-af51-4de937be535a","trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Config input/output path and clone latest repo","metadata":{"id":"wDA1HyzsnzA_"}},{"cell_type":"code","source":"# Clone the latest github repo version\n%cd {OUTPUT_PATH}\ntorch.cuda.empty_cache()\n!rm -rf OuroTrace","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:43:26.453217Z","iopub.execute_input":"2025-12-23T16:43:26.453669Z","iopub.status.idle":"2025-12-23T16:43:26.586907Z","shell.execute_reply.started":"2025-12-23T16:43:26.453647Z","shell.execute_reply":"2025-12-23T16:43:26.586233Z"},"id":"qyaPdq3RnzA8","outputId":"9c79513f-400c-4abf-dd42-842f0794afdf","trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!git clone --branch claude https://github.com/dzungphieuluuky/OuroTrace.git\n%cd OuroTrace","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T16:43:26.589086Z","iopub.execute_input":"2025-12-23T16:43:26.589378Z","iopub.status.idle":"2025-12-23T16:43:27.483743Z","shell.execute_reply.started":"2025-12-23T16:43:26.589352Z","shell.execute_reply":"2025-12-23T16:43:27.483028Z"},"id":"3S4kc_Vjs_m0","outputId":"ec834da5-b74a-44b5-fadc-a3d4d263f7d7","trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'OuroTrace'...\nremote: Enumerating objects: 1926, done.\u001b[K\nremote: Counting objects: 100% (143/143), done.\u001b[K\nremote: Compressing objects: 100% (101/101), done.\u001b[K\nremote: Total 1926 (delta 75), reused 97 (delta 42), pack-reused 1783 (from 1)\u001b[K\nReceiving objects: 100% (1926/1926), 3.37 MiB | 16.28 MiB/s, done.\nResolving deltas: 100% (1249/1249), done.\n/kaggle/working/OuroTrace\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Run Benchmark","metadata":{"id":"GmJUVG32s_m0"}},{"cell_type":"code","source":"import pandas as pd\nfrom src.config_loader import load_config_from_json, post_process_config\n\n# this is the fused version when single and batch use the same predict function\nfrom src.new_runner import run_batch_experiment\n\n# this is the original version when single and batch use different functions\n# from src.runner import run_batch_experiment\n\nfrom src.evaluation_metrics import analyze_experiment_results\n\n\n# 1. Load Configuration from JSON\nconfig = load_config_from_json('configs/batch_ouro_1.4b_thinking.json')\n\n# 2. Post-process (Convert 'torch.float16' string to object, generate timestamps)\nconfig = post_process_config(config)\n\nconfig[\"INFERENCE_STEPS\"] = [12]\nconfig[\"EVAL_SETTINGS\"][\"calculate_perplexity\"] = False\n\nconfig[\"DATA\"][\"n_ary\"][\"num_samples_per_level\"] = 0\n# config[\"DATA\"][\"p_hop\"][\"num_samples_per_level\"] = 0\nconfig[\"DATA\"][\"igsm\"][\"num_samples_total\"] = 0\nconfig[\"DATA\"][\"reasoning_primitives\"][\"num_samples\"] = 0\n# 4. Execute\nprint(\"🚀 Starting Experiment...\")\ntry:\n    del model, tokenizer\n    torch.cuda.empty_cache()\n    gc.collect()\nexcept:\n    pass\n\ntry:\n  acc_results, ppl_results, hol_results = run_batch_experiment(config)\nexcept Exception as e:\n  print(f\"An unexpected error occurred: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["030e5d70d47647ea9c0dee7d3c793749","3354b005dea7425db4694cc3fc82172b","2d225ae48e9240dda3ba4332f03789ea","4ad5443483e540cc899e4da94fdd9147","cfa315ea61ca49c8b68e9a0e00785d56","b63abc3e15564dfeb18b7f32b561b7cf","f1cbf0b7c6fb48b3a094fe2c508a8662","19dd5a88238e496ea7582eab65ff9d1a","189b1f92bfd441c29dc49ef20307286e","fd71b1ae6565402caba7db39a8b2911d","b895cc67d77c4ef386ae6d36ea3763cd","a16f618ae4e54ccba5e53bd12cb5ca62","6bcb00faafcb4cd88de64b19ba212f4d","a348dea938d140cdb29a471d756f796e","41e4dc728f4a4e88a3253f542a40c3b3","218f44a2a97047b2a401e93e28490f80","1b246da7b2fa4e14ba25acc9d6c5d5ef","ec85e0e989b7455bb62af345f8890590","830e5e68cb0542da8f2337b6e05040b4","b7db0f6a2755442095d549b2b410f55b","49d6398b23b9426ca6163abdb5d4f7c5","ff918d2f818f4c579e9864ffa244b85d","71ee8681b3af42f1bc9a550ac6f06873","32407569c5134661a19c81e9251630ee","2582e982cc7a4631943f29154d8ea16b","364ec44a4b54402abfd348382d1995bc","73d1080db01d4f38a75674291d9ffbf3","282e53cba3ee45a99b247536d647e69e","6368e65a8b1d4f85b73df777d2a8acb4","09ea87de086c422991d6bd8ff92f1476","0517e5b7b162403dbacd93f7eedd441c","4af1800c888f41599687d5355d435369","d03bbbcae9fd482e97e62165ca01a368","05c2b41a25cb430299b979990006f307","4c46f3bd9a8a4d89aebd24e96b888eaa","1de0e87e63c04d09bdfced8b1f131cbc","762c688139014e63a5d82e0ab31df83b","2435b71004724038987a64ee49ede31b","cc52da185bd94b118cffc10b95395c0d","98470ff4b5214905a8053ee6abf3714c","80b8e55fdcb64fc7bbe6fffaa44df5d3","0efc8a45246c44eb84da7963d2d4a4ef","20ce4caf5ec041deadd791b1145f7c30","38cc2f8228c6491aace159adae75cead","dc60ba79431646048acec97037d64537","6a5e656a3c6043a4ad6510bfb499d8a7","7271295655554dccacaec86a99e4b874","a433630711644edebc6aac3f629a1390","e0eb4bf70abf484e842f0632cfc9be3d","6362748c820f4e0c809a867229d37851","d54b9be8e48f44f3950e49b9363b02d9","6ebbbe246467421782e467db767aa995","71b851688fbf410bae6b1a44140f42fb","b2fbd7e07c8a411bb982b67bfa3a2722","d18f1c309a1b4470b61b0fe3fa441837","aa526860703d4a2fa6234c7d01be7260","fff381cfcc67449f896a912ea6222e82","c86a47732a5c4a3bbd5fe74e091211b5","35194af6dc2341549db31b74813b0f28","7f2e51a0e0f742489d2d7c60474be6bd","bd4597f0f4564f4b9d74104d9a29a96a","61d3062eb3f1443caa87ecaf20ee817e","775c90d1551f4574876a4cabc4c16d54","270856e780f340ce86d32b89000baeaf","7801cd32c71047d2bd9726558c79f3a2","fad5147665d948c4beac31c78c47b979","dc0dbc1eaa23421cada26a18994289fb","4cc1e2fee62346b68b6b21a0e9842bf0","e17a89b57db34f9388d1ee2f869be83d","1f7aaee04ead4f4db10f4a7f4bd8290a","5bc60176deb14f609ba00e727b39df3f","c42d31b5018b4eb89a6cd539cc069534","094b2bf7829d42e6a63b1bf0ab939d88","0395cefb9c6a49808332eb1c13a8183a","4d159c8af2ac40a7b22a305ec50aac41","4dc1ff4a305e43e9aff2995770c5d8ce","48a6c64a24c34b0bbde4f50dbb4e8a3c"]},"execution":{"iopub.status.busy":"2025-12-23T16:43:27.484682Z","iopub.execute_input":"2025-12-23T16:43:27.485257Z","iopub.status.idle":"2025-12-23T17:56:07.782760Z","shell.execute_reply.started":"2025-12-23T16:43:27.485228Z","shell.execute_reply":"2025-12-23T17:56:07.781999Z"},"id":"CKc8czt-nzBB","outputId":"9fcc114b-ab7e-4c0c-b6b0-929138e9e7f6","trusted":true},"outputs":[{"name":"stdout","text":"🚀 Starting Experiment...\n🔗 Initializing W&B (timeout: 30s)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251223_164327-4ltakt14</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/4ltakt14' target=\"_blank\">misunderstood-universe-124</a></strong> to <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/4ltakt14' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/4ltakt14</a>"},"metadata":{}},{"name":"stdout","text":"✅ W&B initialized\n\n======================================================================\n🔧 EXPERIMENT CONFIGURATION\n======================================================================\nModel Path: ByteDance/Ouro-1.4B-Thinking\nUT Steps to Test: [12]\nData Type: torch.bfloat16\n4-bit Quantization: False\nTorch Compile: False\nMax Batch Size: 8\nMax New Tokens: 16\nBatching: True\nCalculate Perplexity: False\nEarly Exit: 1.0\n======================================================================\n\n[+] Quality monitor initialized:\n    → Garbage threshold: 30%\n    → Example similarity threshold: 85%\n    → Min samples before check: 10\n🎲 Random seed set to 42\n\n======================================================================\n📦 LOADING TEST DATASETS\n======================================================================\n⚙️ Generating new test datasets...\n✅ Generated test datasets\n\nDataset Summary:\n   n_ary       :    0 samples\n   p_hop       :  300 samples\n   igsm        :  100 samples\n======================================================================\n\n\n======================================================================\n📋 PAPER COMPLIANCE CHECK\n======================================================================\nTask Alignment: {'has_n_ary': True, 'has_p_hop': True, 'has_igsm': True, 'all_paper_tasks': True}\nUT Steps Coverage: {'min_ut': 12, 'max_ut': 12, 'covers_baseline': False, 'covers_paper_range': False, 'recommended_range': [1, 2, 4, 8]}\n======================================================================\n\n✅ Configuration saved to ../results_20251223_164334_UT_12/config.json\n✅ Task templates saved to ../results_20251223_164334_UT_12/task_templates.json\n\n======================================================================\n🧪 EXPERIMENT 1/1: UT Steps = 12\n======================================================================\n\n\n============================================================\n⚙️  LOADING MODEL CONFIGURATION\n============================================================\nModel Path: ByteDance/Ouro-1.4B-Thinking\nRequested UT Steps: 12\nData Type: torch.bfloat16\n4-bit Quantization: False\nTorch Compile: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77af9c8be37040e69c5639c163427371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_ouro.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87fe6453ee624d2a857ef37edff30502"}},"metadata":{}},{"name":"stdout","text":"\n→ Base config loaded\n   Original UT steps: 4\n   Original early exit: 1.0\n\n→ Modified config:\n   New UT steps: 12\n   Early exit threshold: 1.0 (from default)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"611e3baf87c042a680d00ff94b47fe27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a560eb5b32ea4ae1bedec8e7115778fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e3805f7e4d4e5d9186530e0bdd8c54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8d08237b1845a1b379bbdc7403a516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2079418f911343c79e3acec76043fcd4"}},"metadata":{}},{"name":"stdout","text":"\n→ Tokenizer loaded\n   Vocab size: 49152\n   PAD token: <|im_end|>\n   EOS token: <|im_end|>\n\n→ Loading model weights...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_ouro.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7105391d42de464d88b9037a3a260f53"}},"metadata":{}},{"name":"stderr","text":"2025-12-23 16:43:38.020681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766508218.196695      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766508218.248062      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db0258ade58647e999e2847640411d34"}},"metadata":{}},{"name":"stdout","text":"\n────────────────────────────────────────────────────────────\n🚀 APPLYING SAFE OPTIMIZATIONS\n────────────────────────────────────────────────────────────\n   ✓ Flash Attention / SDPA enabled\n   ✓ TF32 enabled for matmul\n   ✓ cuDNN auto-tuning enabled\n   ✓ Memory pool optimized\n   → Running 3 warmup passes...\n   ✓ Warmup complete\n────────────────────────────────────────────────────────────\n\n============================================================\n✅ MODEL LOADED SUCCESSFULLY\n============================================================\nDevice: cuda:0\nModel dtype: torch.bfloat16\nVERIFIED UT steps: 12\nVERIFIED early exit: 1.0\n============================================================\n\n🔧 Building task templates...\n[+] Task templates with pre-tokenized components computed.\n    System prompt N_ary tokens: 1168 tokens\n    System prompt P_hop tokens: 880 tokens\n    System prompt IGSM tokens: 1463 tokens\n    User prefix tokens: 14 tokens\n    User suffix tokens: 6 tokens\n    Force start tokens: 4 tokens\n✅ Task templates built\n\n✅ Configuration saved to ../results_20251223_164334_UT_12/config.json\n✅ Task templates saved to ../results_20251223_164334_UT_12/task_templates.json\n✅ Experiment configuration saved with task templates\n\n\n======================================================================\n🎯 ACCURACY EVALUATION\n======================================================================\n\n⚠️ Skipping n_ary - no test items\n\n\n──────────────────────────────────────────────────────────────────────\n📝 Task: P_HOP\n──────────────────────────────────────────────────────────────────────\nTotal Samples: 300\nBatch Size: 4\nStrategy: Batched Processing\n\nRunning 75 batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   p_hop:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ad4b56d22ec40249234816756933708"}},"metadata":{}},{"name":"stdout","text":"                                          test_input     full_response  \\\n0  Sequence: B B B A B C B B D D D D C A C C C D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D D D B A A D D D D D B B A D B A ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A A B A C A C C A C B D C B D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A C D B C C A D A B C C A D B D A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D D A B A C B D C D A B B B B D A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A B C D D D D D D A D C D D B D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D D B D C B C C C B A A C A C C D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A B C B D C A B C C A A A B C D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D B B A B B A D C C D A D B C B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A A D C C B C A C D C A D C C A D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C C D B D D A B C A D B C D B D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C C C C A C D B A A C C D D C D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: C D B B C D D A C D D D C B A C D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D D B D A B B B A C B C B C D A C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C B D B A C A A A C D B B B B C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D C A A B D A D B B D B D D B D B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D B B C D C A B D A A B A C C D D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A A A B D D A A A A C B A C C A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C C B C B B A D A A A C C A D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D B A B A C C A D D D D C C C B D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B D D B C B D D C D B D B C B B A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A B B C D A A D C D D D C D A C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D B C D B C D C A C A D D A B C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D A A D A C C B A B D A A D A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B C B B A D C B A D B A D A C A D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A A C B D C D A C C C B B B C A B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C B A D B A B A B C B A A B C B B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B B C A A B A C C B D A A D A C D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: B A C D B D A D C D A B A B A C B C ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A D B B B C C B B C B A D B C C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D C C C B C C A D D C D A C A A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D B C D C C B C A C C B B D C A D ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C D D A C B B D D B C D B D B C ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B A B C B B D B C B A D D D A B B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D C B B A A A C A A B B C A B A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C D A C B D C D D B B A B D C D A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A A C D C B A D A B B D C C D D C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A D B C D B A B D C A C A D D A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D A D C D B C A C D D D C A B C A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C B B D A D D D C B D A D D C B D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D D D C A D A B B A A B A B A B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D C D A A A C D B D A A C B A C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D D C D B A B A B B B D D D A A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D B D A C A A D A B D A A C A D B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: A B D D C B B D C D D C B D A C C D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A A C D D A D A A A A D B A D B B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D C D B A C D B D D A D A C A A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D A B C D B D A C C C C D C D C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A C A B A D C C A D D B D A B D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D D B B D B C A A C D D B A B A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A A C A D C B C A D B D D D C D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D B D C D D C A D D C C C A B B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A A C D C B C A C A B B C A C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B B C C A D B D A A B A C D B D B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C B D B C D A D D B B C B D B D D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D D D C C A B C B C D D B D D B C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A A D B B A C D D B C B D B A C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D C D B C B B D B B A B B A C A C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A A C B C B C B D A A A D B C C A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A D C B D D A A A B D D D A A B D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: C B B A D B B B B A D D D B A A C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C D A A D C A B D A B A B D D D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A D C D A C A C A B B B C D C D D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C D B A D A A A A C D B D C D C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B A C B A A D D D C B A A C B C B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A D B A C D C A A C C D D A D A D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A C B B C D D A B B B B C B C C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B C B A D C C C D B C A A A C C C ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C C A C B A D C A A D C A C D D C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A D C B A C B B A A B B C A A A C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D B D B B A B C B A D B B D D D C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A B A D B B B D A C A A B A C A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C C C D A B D B C D A D D B D A C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B D A C C D B C D C A D B A B D A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C A C D D B D C C D B B A D D B A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D D C A D D A A B C A C A D C B D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: D D D C C C B C A D C B C A D A C C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D B D A C A D A D A C C D B C A D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A B A B D D C D A C C D B C B A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C B B B B A D A A C B A D B B D A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C D C B A B D C C D D D A B C D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D D C D A C C B D D D C B A B A B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D A D A B C D D B C C B B A D C D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D C A B D B C B C C B C D C C A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D C A B D D B C A B C A D A D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B D C D D C C B C A A D C C D B A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A A C A A B B B C A B C B D B D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D A C B A B B B D C D B D B A A D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A A B D B C A C A C B B C A C C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A D A A B B C A D B A C D B A C D ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D C B B B C C A C B C A B D D D B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A A D A B D B D C A D D B A B C C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: A C D A D C B D A D B B A A A C C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D A A A B C A D D C A A D A D D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D B D D A A B A A B B B A C B B A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C A D B C A C C D C B A B D C A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C D B D C C D D D B A C A A D C A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C B B A C B D A C C B A D B B C D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B A D C C A B A C B B A C B A A D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B C C C A C A B A B D C A B A A A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C A D D D A D D B C C C D C D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A C B A A A D C D D A C B C A B D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D B D A C C D A A C D D A B D A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A B A D D A A C B D B A D B C B D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A C C D B B B D C D D A A D B D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A C C B D C A C A D C B C A C C A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A A D B C C C A C A C C D B D D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C D C A A C B D A D C A C C B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: B C B C C B A C D B C B D C B A B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B C A A A A D A B B A D B B D D A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B A D D B D C A C A B C C A D D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A B B B D B B C A A B A B A D C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A C B A B A D A C D B A C B A D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A C B A B D B C B A D A A D C A B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B C B B C A C D C B A A A C B C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D C A C C B C B D D B A B C D B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C B B D C B B B D D C B A D B D C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A B B B C A C D D C D B A C A C D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B A D C A B D C A A B D A D A D B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C C C A A B C C A D C B B D D D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C A D D B B C A D A A B A D C B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C D B D C C C C D D B B C C D C D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D D C D D B B B C A A D D C B C C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B B B B A B C A D A A D C A A C C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: B B D A B B C B A C C B B D D D D D ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B C D A D D A B C B A C B B C B A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B B A A A B C B A A D C B B A C C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B B A D A C D C D D D C C D B D D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D D D A C A B D C C D A A B C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B B C A A C A D A D B B A C A D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A B D D B C A C C C A D B D D C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A D C B C C D D A C B A C D C B D ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D C D A A C C D B B A B A A A A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A D C C B B B A B C D C B D C D D ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D B C A C D B A B B C C D A A B C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D C B D B C C C B B A D B B C A C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n❌ Aborting due to repeated outputs...\n\n⚠️ Batch 35 failed: Experiment failed: 5 repeated outputs\n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A B B C C C B A B A C C C B A C A C ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: B C D A A C D A C D D B B D B B A A ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input     full_response  \\\n0  Sequence: A A C B D A D C C C B C A A A C B C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A A B C B C D C D D C D C C C B A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: D A C D A D A D A B A B C A C B C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D D A B D C A C D B D D A B A C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A B B D B C C A A A B B A B B C A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A D C A B B A C A A D D D A C A C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C B B C D A A C D D A C C C A A C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A C B D C B B B A B B A B B D D B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C C A C D D D B C B D C A C C A B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B A C B D A B D B D A C B A A C A B ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D C C C C A C C D D A C A A D D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B B D B A C B A C B A C A D A B B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C A A A D D A A B C D A A B D C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A A D D D B C D D B C C C A C B C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D B B D D C C B A B C C C B A B A A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D A C A A B D C C D B D D D B B C A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C D A C B D A B A B A A D B B A A C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B D C B C A A C A A D A B C C B C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: A B C C C C A C C A B C C D B D A C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B B C A A A B C A A D C C D D A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D C B B C B D D B C C D B A D B B B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D A A D B D B B B C A A D D C B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C C A B D A A C D D C C C A C A A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C A C B D C B B B C B B B C A D B ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B D B D B C D C B B D D A A A C B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A C A C B A D C D A B C D C B C A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B C B A D B A C D B B A A B D D B D ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A B D B B A D C B D D D B D B D A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C A C D C A D D A D C B A A C C A C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C C D C C A B B C B B B D D D A D B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B D A A D B A A A D C B D A A D C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B D B A C D C D D A C B C C D B A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B C D D A A D B B B B C C B C A B ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: D D B D D D B C B B C D B B C A C C ...  [FINAL]  B [END]   \n\n   generated_tokens  \n0                 4  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n                                          test_input     full_response  \\\n0  Sequence: C C D B B D C B A D D D A B D C D C ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A B B D D A D B B D B A A D C A C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: C B C A B A D B B A D C C B D D B A ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C A D B B B D A C A A C C D B C C ...  [FINAL]  D [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A A B A D A D C B D D D B C A B A A ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A D D A A B C A C B B A D D D B B C ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: A C B D C C B B D B C D D C C A A B ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n                                          test_input     full_response  \\\n0  Sequence: B B C A A A C B D A A B D B A A D A ...  [FINAL]  A [END]   \n\n   generated_tokens  \n0                 4  \n❌ Aborting due to repeated outputs...\n\n⚠️ Batch 46 failed: Experiment failed: 5 repeated outputs\n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A A B C B D A B B D A B D A A C D C ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: D B B B C D B C A A D A C D C C A B ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A B C A C A C A B B D C C D B D B D ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A C C B B A B D C C B C A B A C B B ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n❌ Aborting due to repeated outputs...\n\n⚠️ Batch 47 failed: Experiment failed: 5 repeated outputs\n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: A C A D B C D A A A C D A D B A D A ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n❌ Aborting due to repeated outputs...\n⚠️ Item failed: Experiment failed: 5 repeated outputs\n                                          test_input  \\\n0  Sequence: C A A A A C B D B D D D A B A C B A ...   \n\n                           full_response  generated_tokens  \n0  Experiment failed: 5 repeated outputs                 0  \n                                          test_input     full_response  \\\n0  Sequence: C A B D B A C C D C D B B D D C A D ...  [FINAL]  C [END]   \n\n   generated_tokens  \n0                 4  \n\n======================================================================\n❌ EXPERIMENT INTERRUPTED BY USER\n======================================================================\n\n🔗 Finalizing W&B...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">misunderstood-universe-124</strong> at: <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/4ltakt14' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking/runs/4ltakt14</a><br> View project at: <a href='https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking' target=\"_blank\">https://wandb.ai/dungngocpham171-university-of-science/ouro-1.4b-thinking</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>/kaggle/working/wandb/run-20251223_164327-4ltakt14/logs</code>"},"metadata":{}},{"name":"stdout","text":"✅ W&B session closed\n======================================================================\n\n✅ Periodic save: simple reasoning results to ../results_20251223_164334_UT_12/simple_reasoning.csv\n✅ Configuration saved to ../results_20251223_164334_UT_12/config.json\n✅ Task templates saved to ../results_20251223_164334_UT_12/task_templates.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport glob\nimport zipfile\nfrom typing import List\n\n\ndef find_result_folders(base_path: str) -> List[str]:\n    \"\"\"\n    Return a list of absolute paths to all directories under `base_path`\n    whose names start with 'results_'.\n    \"\"\"\n    pattern = os.path.join(base_path, \"results_*\")\n    # glob returns both files and directories; filter to directories only\n    return [p for p in glob.glob(pattern) if os.path.isdir(p)]\n\n\ndef zip_folder(folder_path: str, output_base_path: str) -> bool:\n    \"\"\"\n    Zip the contents of `folder_path` into a file named\n    <folder_name>.zip` inside `output_base_path`.\n\n    Returns True on success, False otherwise.\n    \"\"\"\n    folder_name = os.path.basename(folder_path)\n    zip_path = os.path.join(output_base_path, f\"{folder_name}.zip\")\n\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for root, _, files in os.walk(folder_path):\n                for file in files:\n                    full_path = os.path.join(root, file)\n                    # Preserve relative path inside the zip\n                    arcname = os.path.relpath(full_path, os.path.dirname(folder_path))\n                    zipf.write(full_path, arcname)\n        print(f\"   ✅ Created ZIP: {os.path.basename(zip_path)}\")\n        return True\n    except Exception as exc:\n        print(f\"   ❌ Failed to zip {folder_name}: {exc}\")\n        return False\n\n\ndef zip_stats_results_folders(output_base_path: str) -> None:\n    \"\"\"\n    Main driver: locate all result folders and zip each one.\n    \"\"\"\n    # Ensure the output directory exists\n    os.makedirs(output_base_path, exist_ok=True)\n\n    result_folders = find_result_folders(output_base_path)\n\n    if not result_folders:\n        print(f\"⚠️ No folders starting with 'results_' found in '{output_base_path}'.\")\n        return\n\n    print(f\"🔍 Found {len(result_folders)} result folder(s) to zip.\")\n    successful = 0\n\n    for folder in result_folders:\n        if zip_folder(folder, output_base_path):\n            successful += 1\n\n    print(f\"\\n✅ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        # Prefer an environment variable; fall back to a global if defined\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n\n        # The script expects a sub‑folder named 'OuroTrace' under OUTPUT_PATH\n        target_path = os.path.join(output_root, \"\")\n        zip_stats_results_folders(target_path)\n\n    except Exception as e:\n        print(f\"❌ An error occurred: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T17:56:07.784281Z","iopub.execute_input":"2025-12-23T17:56:07.784494Z","iopub.status.idle":"2025-12-23T17:56:07.806340Z","shell.execute_reply.started":"2025-12-23T17:56:07.784476Z","shell.execute_reply":"2025-12-23T17:56:07.805701Z"},"id":"8inXWmVwnzBC","outputId":"b9672875-7573-404e-b4d4-4c652abf9ec3","trusted":true},"outputs":[{"name":"stdout","text":"🔍 Found 1 result folder(s) to zip.\n   -> Zipping folder: results_20251223_164334_UT_12...\n   ✅ Created ZIP: results_20251223_164334_UT_12.zip\n\n✅ DONE! Successfully zipped 1 out of 1 folder(s).\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 3. Save Results\ndf_acc = pd.DataFrame(acc_results)\ndf_ppl = pd.DataFrame(ppl_results)\ndf_hol = pd.DataFrame(hol_results)\n# 4. Visualization & Reporting\nif not df_acc.empty:\n    print(\"\\n\" + \"=\"*50 + \"\\n📊 VISUALIZATION\\n\" + \"=\"*50)\n\n    # Summary Tables\n    # NOTE: The variable 'results_acc' is used here, assuming it holds the raw data\n    # (list of dicts) required by 'analyze_experiment_results'.\n    summary = analyze_experiment_results(acc_results)\n    print(\"\\n--- Summary Statistics ---\")\n    print(summary)\n\n    # Plotting\n    try:\n        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n        # Plot 1: Accuracy\n        acc_summary = df_acc.groupby(['task_type', 'ut_steps'])['is_correct'].mean().reset_index()\n        sns.barplot(data=acc_summary, x='ut_steps', y='is_correct', hue='task_type', ax=axes[0])\n        axes[0].set_title('Accuracy by UT Steps')\n        axes[0].set_ylabel('Accuracy')\n        axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n\n        # Plot 2: Time\n        time_summary = df_acc.groupby(['task_type', 'ut_steps'])['generation_time'].mean().reset_index()\n        sns.barplot(data=time_summary, x='ut_steps', y='generation_time', hue='task_type', ax=axes[1])\n        axes[1].set_title('Inference Time (s) by UT Steps')\n\n        # Plot 3: Token Count\n        sns.boxplot(data=df_acc, x='ut_steps', y='generated_tokens', hue='task_type', ax=axes[2])\n        axes[2].set_title('Generated Tokens Distribution')\n\n        plt.tight_layout()\n        plt.show()\n\n    except Exception as e:\n        print(f\"⚠️ Visualization error: {e}\")\nelse:\n    print(\"⚠️ No results to visualize.\")\n\nprint(\"\\n🏁 Experiment Complete.\\n\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-23T17:56:07.807160Z","iopub.execute_input":"2025-12-23T17:56:07.807413Z","iopub.status.idle":"2025-12-23T17:56:07.854286Z","shell.execute_reply.started":"2025-12-23T17:56:07.807397Z","shell.execute_reply":"2025-12-23T17:56:07.853377Z"},"id":"0p4QBYsDnzBB","outputId":"854d9a46-3a89-4cf0-cf1e-154e45e7019c","trusted":true},"outputs":[{"name":"stdout","text":"\n==================================================\n📊 VISUALIZATION\n==================================================\n\n======================================================================\n📊 COMPREHENSIVE METRICS ANALYSIS\n======================================================================\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3413224372.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# NOTE: The variable 'results_acc' is used here, assuming it holds the raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# (list of dicts) required by 'analyze_experiment_results'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_experiment_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Summary Statistics ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/OuroTrace/src/evaluation_metrics.py\u001b[0m in \u001b[0;36manalyze_experiment_results\u001b[0;34m(results_folder, save_plots, save_dir)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnhancedOuroMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m     \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"plots\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;31m# --- Load results CSV ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"],"ename":"TypeError","evalue":"expected str, bytes or os.PathLike object, not list","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"print(\"Final Inspection:\\n\")\nprint(\"Top 20 Accuracy Report:\\n\")\nprint(df_acc.head(20))\nprint(f\"Full Response:\\n\")\nprint(df_acc['full_response'])\nprint(\"Perplexity Report:\\n\")\nprint(df_ppl.head(20))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"execution":{"iopub.status.busy":"2025-12-23T17:56:07.854812Z","iopub.status.idle":"2025-12-23T17:56:07.855126Z","shell.execute_reply.started":"2025-12-23T17:56:07.854944Z","shell.execute_reply":"2025-12-23T17:56:07.854976Z"},"id":"3zpz9ccInzBD","outputId":"67c1fda1-7384-4d83-a26b-161de09cba68","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_acc[['full_response', 'generated_tokens']])","metadata":{"execution":{"iopub.status.busy":"2025-12-23T17:56:07.856447Z","iopub.status.idle":"2025-12-23T17:56:07.856679Z","shell.execute_reply.started":"2025-12-23T17:56:07.856578Z","shell.execute_reply":"2025-12-23T17:56:07.856587Z"},"id":"EDWCUkMqnzBD","trusted":true},"outputs":[],"execution_count":null}]}