{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":672476,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":509506,"modelId":524172}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CELL 1: Environment Setup & Package Installation","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 1: Environment Setup & Package Installation\nPurpose: Install required packages and suppress warnings\n\"\"\"\n\n# Install core packages\n!pip install --upgrade pip\n!pip uninstall -y transformers tokenizers accelerate -q\n!pip install \"transformers==4.56.0\" \"protobuf>=5.29.4\" -q\n!pip install torch datasets -q\n!pip install pandas matplotlib seaborn tqdm wandb pyyaml\n!pip install bitsandbytes accelerate\n\n# Suppress warnings for clean output\nimport warnings\nimport os\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nos.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\n\nprint(\"âœ… Packages installed successfully!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:25:02.385575Z","iopub.execute_input":"2025-12-14T15:25:02.385768Z","iopub.status.idle":"2025-12-14T15:26:38.421443Z","shell.execute_reply.started":"2025-12-14T15:25:02.385750Z","shell.execute_reply":"2025-12-14T15:26:38.420459Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.3.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.5.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (6.33.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.12.4)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.15.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.3)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.36.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\nDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\nInstalling collected packages: bitsandbytes, accelerate\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [accelerate]2\u001b[0m [accelerate]\n\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0\nâœ… Packages installed successfully!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# CELL 2: Core Imports","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 2: Core Imports\nPurpose: Import all necessary libraries\n\"\"\"\n\"Built-in libraries\"\nimport re\nimport sys\nimport gc\nimport time\nimport json\nimport hashlib\nimport glob\nimport zipfile\nfrom io import StringIO\nfrom datetime import datetime\nfrom typing import Dict, List, Optional, Tuple, Any\nimport yaml\nimport logging\nimport random\n\n\"Deep learning and NLP libraries\"\nimport torch\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoConfig, \n    AutoTokenizer, \n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    GenerationConfig,\n    logging as hf_logging\n)\n\n\"Data processing libraries\"\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport wandb\nfrom tqdm.auto import tqdm\nfrom IPython import get_ipython\n\n# Configure logging\nlogging.getLogger(\"ContinuousBatchingLogger\").setLevel(logging.ERROR)\nhf_logging.set_verbosity_error()\n\nprint(f\"Python Version: {sys.version}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA Version: {torch.version.cuda}\")\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:26:38.423506Z","iopub.execute_input":"2025-12-14T15:26:38.423744Z","iopub.status.idle":"2025-12-14T15:26:49.135455Z","shell.execute_reply.started":"2025-12-14T15:26:38.423717Z","shell.execute_reply":"2025-12-14T15:26:49.134698Z"}},"outputs":[{"name":"stdout","text":"Python Version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch Version: 2.6.0+cu124\nCUDA Available: True\nCUDA Version: 12.4\nSun Dec 14 15:26:48 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P8             12W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# CELL 3: Environment Detection & Path Configuration","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 3: Environment Detection & Path Configuration\nPurpose: Detect runtime environment (Colab/Kaggle/Local) and set paths\n\"\"\"\n\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if 'google.colab' in str(get_ipython()):\n            print(\"âœ… Environment: Google Colab\")\n            base_data_path = '/content/'\n            base_output_path = '/content/output/'\n            environment_name = 'colab'\n        elif os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n            print(\"âœ… Environment: Kaggle\")\n            base_data_path = '/kaggle/input/'\n            base_output_path = '/kaggle/working/'\n            environment_name = 'kaggle'\n        else:\n            print(\"âš ï¸ Environment: Local/Unknown\")\n            base_data_path = './data/'\n            base_output_path = './output/'\n            environment_name = 'local'\n    except NameError:\n        print(\"âš ï¸ Non-interactive session. Using local paths.\")\n        base_data_path = './data/'\n        base_output_path = './output/'\n        environment_name = 'local'\n    \n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"ðŸ“‚ Data Path: {base_data_path}\")\n    print(f\"ðŸ“¦ Output Path: {base_output_path}\")\n    \n    return base_data_path, base_output_path, environment_name\n\ndef auto_unzip_colab_content(target_dir='/content/', zip_extension='*.zip'):\n    \"\"\"Auto-extract zip files in Colab environment\"\"\"\n    if 'google.colab' not in str(get_ipython()):\n        return\n    \n    print(f\"ðŸ”Ž Scanning for {zip_extension} files...\")\n    zip_files = glob.glob(os.path.join(target_dir, zip_extension))\n    \n    for zip_path in zip_files:\n        file_name = os.path.basename(zip_path)\n        base_name = os.path.splitext(file_name)[0]\n        expected_output = os.path.join(target_dir, base_name)\n        \n        if os.path.exists(expected_output) and os.listdir(expected_output):\n            print(f\"âž¡ï¸ Skipping '{file_name}' (already extracted)\")\n            continue\n        \n        try:\n            print(f\"ðŸ“‚ Extracting: {file_name}...\")\n            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n                zip_ref.extractall(target_dir)\n        except Exception as e:\n            print(f\"âŒ Error: {e}\")\n\n# Initialize paths\nDATA_PATH, OUTPUT_PATH, ENV = configure_environment_paths()\nauto_unzip_colab_content(DATA_PATH)\n\n# Optional: WandB login\ntry:\n    from google.colab import userdata\n    wandb_key = userdata.get('WANDB_API_KEY')\n    if wandb_key:\n        wandb.login(key=wandb_key)\nexcept:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:26:49.139068Z","iopub.execute_input":"2025-12-14T15:26:49.139319Z","iopub.status.idle":"2025-12-14T15:26:59.183017Z","shell.execute_reply.started":"2025-12-14T15:26:49.139294Z","shell.execute_reply":"2025-12-14T15:26:59.182420Z"}},"outputs":[{"name":"stdout","text":"âœ… Environment: Kaggle\nðŸ“‚ Data Path: /kaggle/input/\nðŸ“¦ Output Path: /kaggle/working/\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# CELL 4: Data Generation Utilities","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 4: Data Generation Utilities\nPurpose: Functions to create test datasets and perplexity data\n\"\"\"\n\ndef create_test_datasets(config: dict) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Generate algorithmic test datasets strictly matching ICLR 2025 specs:\n    1. N-ary Addition: Input-Output pairs, 3-digit operands, sum.\n    2. P-hop Induction: Sequence length 256, Alphabet 4, Chain embedded at random sorted indices.\n    3. Symbolic i-GSM: Hierarchy depth 4, strict Level i -> Level i+1 dependency, Modulo 7.\n    \"\"\"\n    test_data = {}\n    \n    # 1. N-ARY ADDITION (Unchanged, matches paper description)\n    if 'n_ary' in config:\n        n_ary_data = []\n        ops_levels = config['n_ary'].get('ops_levels', [8, 16, 24, 32])\n        num_samples = config['n_ary'].get('num_samples_per_level', 30)\n        \n        for n in ops_levels:\n            for _ in range(num_samples):\n                # Paper: sample operands [0, 999] uniformly\n                nums_int = [random.randint(0, 999) for _ in range(n)]\n                # Format: \"315 + 120 + ... =\"\n                nums_str = [str(x).zfill(3) for x in nums_int]\n                \n                prompt_str = \" + \".join(nums_str) + \" =\"\n                target_str = str(sum(nums_int))\n\n                n_ary_data.append({\n                    \"prompt\": prompt_str,\n                    \"expected_answer\": target_str,\n                    \"difficulty\": f\"{n}_ops\",\n                    \"task_type\": \"n_ary\"\n                })\n        test_data['n_ary'] = n_ary_data\n\n    # 2. P-HOP INDUCTION\n    # Description: \"Picking the sequence of p-hops randomly... shuffling them around in a sequence... \n    # sample remaining characters in place of filler tokens while respecting the p-hop order.\"\n    if 'p_hop' in config:\n        p_hop_data = []\n        alphabet = ['A', 'B', 'C', 'D']\n        seq_len = 256\n        hop_levels = config['p_hop'].get('hop_levels', [16, 24, 32])\n        num_samples = config['p_hop'].get('num_samples_per_level', 30)\n\n        for p in hop_levels:\n            for _ in range(num_samples):\n                # 1. Define the Chain: v_0 -> v_1 -> ... -> v_p\n                # The 'hop' logic implies identifying v_i and finding v_{i+1}\n                chain = [random.choice(alphabet) for _ in range(p + 1)]\n                \n                # 2. Embed in Sequence\n                # \"Shuffling them around... respecting p-hop order\" implies:\n                # We pick p+1 random positions in the 256-length sequence \n                # and place the chain items there in strictly increasing order.\n                indices = random.sample(range(seq_len), p + 1)\n                indices.sort()\n                \n                # Initialize sequence with \"filler\" logic\n                # \"Sample remaining characters... in place of filler tokens\"\n                seq = [random.choice(alphabet) for _ in range(seq_len)]\n                \n                # Overwrite fillers with the chain at the selected indices\n                for k, idx in enumerate(indices):\n                    seq[idx] = chain[k]\n                \n                # 3. Construct Prompt\n                # Input: Sequence + Start Node. Goal: Output the p-th hop (last item in chain).\n                seq_str = \"\".join(seq)\n                start_node = chain[0]\n                expected = chain[-1]\n                \n                full_prompt = f\"Sequence: {seq_str}. Start: {start_node}. Hop {p} times.\"\n                \n                p_hop_data.append({\n                    \"prompt\": full_prompt,\n                    \"expected_answer\": expected,\n                    \"difficulty\": f\"{p}_hops\",\n                    \"task_type\": \"p_hop\"\n                })\n        test_data['p_hop'] = p_hop_data\n\n    # 3. SYMBOLIC i-GSM\n    # Description: \"Hierarchy of depth 4... edges connect level i to level i+1... \n    # instance parameter is integer... arithmetic modulo 7... symbolic language\"\n    if 'igsm' in config:\n        igsm_data = []\n        num_total = config['igsm'].get('num_samples_total', 50)\n        \n        # Variable naming pool (e.g., E#I, K#N)\n        chars = \"ABCDEFGHIJKLMNOP\"\n        def get_var_name():\n            return f\"{random.choice(chars)}#{random.choice(chars)}\"\n\n        for _ in range(num_total):\n            # 1. Structure: Hierarchy Depth 4 (Levels 0 to 4)\n            # We assign variables to specific levels\n            levels = {0: [], 1: [], 2: [], 3: [], 4: []}\n            all_vars_data = {} # {name: val}\n            equations = []\n            \n            # 2. Level 0: Roots (Constants)\n            # Create ~4 root entities\n            for _ in range(4):\n                name = get_var_name()\n                val = random.randint(0, 6) # Modulo 7\n                levels[0].append(name)\n                all_vars_data[name] = val\n                equations.append(f\"{name} := {val}\")\n\n            # 3. Levels 1 to 4: Dependencies\n            # \"Edges connect entities in level i to those in level i+1\"\n            for i in range(1, 5):\n                # Number of variables in this level\n                num_vars_in_level = random.randint(2, 4)\n                \n                for _ in range(num_vars_in_level):\n                    target_var = get_var_name()\n                    \n                    # Ensure unique names\n                    while target_var in all_vars_data:\n                        target_var = get_var_name()\n                    \n                    # Select 1 or 2 operands from the PREVIOUS level (i-1)\n                    # This enforces the strict hierarchy described\n                    operands = random.choices(levels[i-1], k=random.randint(1, 2))\n                    op_vals = [all_vars_data[op] for op in operands]\n                    \n                    op_type = random.choice(['add', 'sub', 'mult', 'assign'])\n                    \n                    stmt = \"\"\n                    res = 0\n                    \n                    if op_type == 'assign' or len(operands) < 2:\n                        stmt = f\"{target_var} := {operands[0]}\"\n                        res = op_vals[0]\n                    elif op_type == 'add':\n                        stmt = f\"{target_var} := {operands[0]} + {operands[1]}\"\n                        res = (op_vals[0] + op_vals[1]) % 7\n                    elif op_type == 'sub':\n                        stmt = f\"{target_var} := {operands[0]} - {operands[1]}\"\n                        res = (op_vals[0] - op_vals[1]) % 7\n                    elif op_type == 'mult':\n                        stmt = f\"{target_var} := {operands[0]} * {operands[1]}\"\n                        res = (op_vals[0] * op_vals[1]) % 7\n                        \n                    equations.append(stmt)\n                    all_vars_data[target_var] = res\n                    levels[i].append(target_var)\n\n            # 4. Query\n            # \"Pick one of the nodes... compute value\"\n            # We pick from the deepest level (Level 4) to ensure the full chain is needed\n            target_var = random.choice(levels[4])\n            target_val = all_vars_data[target_var]\n            \n            # Shuffle equations to ensure model learns the dependency graph, not just order\n            random.shuffle(equations)\n            \n            # Format: \"Question. Eq1. Eq2. ... EqN. Target?\"\n            full_prompt = \"Question. \" + \". \".join(equations) + f\". {target_var}?\"\n            \n            igsm_data.append({\n                \"prompt\": full_prompt,\n                \"expected_answer\": str(target_val),\n                \"difficulty\": \"depth_4_hierarchical_mod_7\",\n                \"task_type\": \"igsm\"\n            })\n            \n    test_data['igsm'] = igsm_data\n    \n    return test_data\n\ndef create_perplexity_data(num_samples: int = 30) -> List[str]:\n    \"\"\"Generate reasoning traces for perplexity calculation\"\"\"\n    perplexity_texts = []\n    \n    # N-ARY traces\n    for _ in range(num_samples // 2):\n        n = random.choice([4, 6, 8])\n        nums = [random.randint(10, 99) for _ in range(n)]\n        trace = f\"System: You are a calculation engine.\\nUser: Sum: {nums}\\nAssistant: Current Sum: 0\\n\"\n        \n        current_sum = 0\n        for num in nums:\n            prev_sum = current_sum\n            current_sum += num\n            trace += f\"Add {num}: {prev_sum} + {num} = {current_sum}\\nCurrent Sum: {current_sum}\\n\"\n        \n        trace += f\"Final: {current_sum}\"\n        perplexity_texts.append(trace)\n    \n    # P-HOP traces\n    all_letters = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n    for _ in range(num_samples // 2):\n        hops = random.choice([3, 4, 5])\n        nodes = random.sample(all_letters, hops + 1)\n        facts = [f\"{nodes[i]}->{nodes[i+1]}\" for i in range(len(nodes) - 1)]\n        facts_str = \", \".join(facts)\n        \n        trace = f\"System: Logic engine.\\nUser: Facts: {facts_str}. Start: {nodes[0]}. Find: {nodes[-1]}.\\n\"\n        trace += f\"Assistant: Current Node: {nodes[0]}\\n\"\n        \n        for i in range(hops):\n            trace += f\"Rule Matches: {nodes[i]} -> {nodes[i+1]}\\nNext Node: {nodes[i+1]}\\n\"\n        \n        trace += f\"Final: {nodes[-1]}\"\n        perplexity_texts.append(trace)\n    \n    return perplexity_texts\n\n\ndef load_and_preprocess_data(file_path: str) -> Dict[str, List[Dict]]:\n    \"\"\"Load existing test data from JSON or CSV\"\"\"\n    print(f\"Loading data from: {file_path}\")\n    \n    if file_path.endswith('.json'):\n        with open(file_path, 'r', encoding='utf-8') as f:\n            raw_data = json.load(f)\n    elif file_path.endswith('.csv'):\n        df = pd.read_csv(file_path)\n        raw_data = df.to_dict('records')\n    else:\n        raise ValueError(\"Unsupported format. Use .json or .csv\")\n    \n    processed_data = {'n_ary': [], 'p_hop': [], 'igsm': []}\n    \n    for record in raw_data:\n        task = record.get('task_type')\n        if task in processed_data:\n            if all(k in record for k in ['prompt', 'expected_answer', 'difficulty']):\n                processed_data[task].append(record)\n    \n    print(f\"âœ… Loaded - N-ary: {len(processed_data['n_ary'])}, \"\n          f\"P-Hop: {len(processed_data['p_hop'])}, iGSM: {len(processed_data['igsm'])}\")\n    \n    return processed_data\n\n\ndef generate_test_id(task_type: str, difficulty: str, prompt: str) -> str:\n    \"\"\"Generate unique test ID\"\"\"\n    unique_str = f\"{task_type}_{difficulty}_{prompt}\"\n    return hashlib.md5(unique_str.encode()).hexdigest()[:8]\n\n\nprint(\"âœ… Data generation utilities loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:26:59.184104Z","iopub.execute_input":"2025-12-14T15:26:59.184424Z","iopub.status.idle":"2025-12-14T15:26:59.207120Z","shell.execute_reply.started":"2025-12-14T15:26:59.184393Z","shell.execute_reply":"2025-12-14T15:26:59.206396Z"}},"outputs":[{"name":"stdout","text":"âœ… Data generation utilities loaded\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# CELL 5: Core Experiment Class","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 5: Core Experiment Class\nPurpose: Main class for running Ouro model experiments (Updated for ICLR 2025 Formats)\n\"\"\"\n\nclass OuroThinkingExperiment:\n    \"\"\"Core experiment class for Ouro model testing\"\"\"\n    \n    def __init__(self, model_path: str, dtype=torch.float16, \n                 use_4bit_quant: bool = False, use_torch_compile: bool = False):\n        torch.cuda.empty_cache()\n        self.model_path = model_path\n        self.dtype = dtype\n        self.use_4bit_quant = use_4bit_quant\n        self.use_torch_compile = use_torch_compile\n        self.tokenizer = None\n        self.task_templates = {}\n    \n    def load_model_with_ut_steps(self, total_ut_steps: int, early_exit_threshold: float):\n        \"\"\"Load model with specific UT steps configuration\"\"\"\n        quantization_config = None\n        if self.use_4bit_quant:\n            print(\"â†’ Applying 4-bit quantization\")\n            quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n        \n        print(f\"Loading model: UT steps={total_ut_steps}, Early exit={early_exit_threshold}\")\n        \n        config = AutoConfig.from_pretrained(self.model_path, trust_remote_code=True)\n        config.total_ut_steps = total_ut_steps\n        config.early_exit_threshold = early_exit_threshold\n        \n        tokenizer = AutoTokenizer.from_pretrained(\n            self.model_path,\n            trust_remote_code=True,\n            padding_side=\"left\"\n        )\n        if tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            self.model_path,\n            config=config,\n            device_map=\"cuda\",\n            attn_implementation=\"sdpa_paged\",\n            dtype=self.dtype if not self.use_4bit_quant else None,\n            trust_remote_code=True,\n            quantization_config=quantization_config\n        )\n        \n        if self.use_torch_compile:\n            print(\"â†’ Applying torch.compile()\")\n            model = torch.compile(model)\n        \n        model.eval()\n        print(f\"âœ… Model loaded on {model.device}\")\n        \n        return model, tokenizer, None, {\n            \"total_ut_steps\": total_ut_steps,\n            \"early_exit_threshold\": early_exit_threshold\n        }\n    \n    def _build_task_templates(self, tokenizer):\n            \"\"\"\n            Pre-compute prompt templates for faster inference.\n            UPDATED: Refined Few-Shot examples to prevent babbling (added Step Prefixes and Guardrails).\n            \"\"\"\n            self.tokenizer = tokenizer\n            \n            task_configs = {\n                # 1. N-ARY ADDITION (TÃCH Há»¢P STEP PREFIX VÃ€ GUARDRAILS)\n                \"n_ary\": {\n                    # ThÃªm tá»« khÃ³a kiá»ƒm soÃ¡t: MUST, DO NOT\n                    \"system\": \"You are a mechanical calculation engine. Your output MUST be strictly sequential. DO NOT output introductions, explanations, or any text outside of the required calculation steps.\",\n                    \"example_user\": \"10 + 20 + 30 =\",\n                    # ThÃªm [STEP X] vÃ  [FINAL]\n                    \"example_asst\": \"[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10 = 10\\n[STEP 3] Current: 10\\n[STEP 4] Add 20: 10 + 20 = 30\\n[STEP 5] Current: 30\\n[STEP 6] Add 30: 30 + 30 = 60\\n[FINAL] 60\",\n                    # Báº¯t Ä‘áº§u báº±ng ngáº¯t dÃ²ng vÃ  kÃ½ hiá»‡u bÆ°á»›c Ä‘áº§u tiÃªn\n                    \"force_start\": \"\\n[STEP 1] Current: 0\", \n                    \"input_prefix\": \"\" \n                },\n                \n                # 2. P-HOP INDUCTION (RÃºt gá»n vÃ  ThÃªm Guardrail)\n                \"p_hop\": {\n                    # ThÃªm tá»« khÃ³a kiá»ƒm soÃ¡t vÃ  yÃªu cáº§u káº¿t thÃºc chá»‰ vá»›i token\n                    \"system\": \"You are an induction head mechanism. Strictly trace the sequence occurrences step-by-step. Do not provide any commentary or auxiliary information. End your response ONLY with the final traced token.\",\n                    \"example_user\": \"Sequence: A B C D A B. Start: A. Hop 1 times.\",\n                    # RÃºt gá»n vÃ­ dá»¥: dÃ¹ng [TRACE]\n                    \"example_asst\": \"\\n[TRACE] Start at A. Found 'A' in sequence. Next token is B.\\n[FINAL] B\",\n                    \"force_start\": \"\\n[TRACE] Start at\", \n                    \"input_prefix\": \"\" \n                },\n                \n                # 3. SYMBOLIC i-GSM (ThÃªm Step Prefix vÃ  Guardrail)\n                \"igsm\": {\n                    # TÄƒng cÆ°á»ng Guardrail\n                    \"system\": \"You are a symbolic math solver. You must solve the DAG modulo 7. Your reasoning MUST be concise, equation-based, and step-by-step. DO NOT generate preambles or verbose explanations.\",\n                    \"example_user\": \"Question. E#I := 4. E#J := E#I. F#K := E#J. H#J := E#J + F#K. H#J?\",\n                    # ThÃªm [EQ X] cho tá»«ng bÆ°á»›c vÃ  [FINAL]\n                    \"example_asst\": \"\\n[EQ 1] E#I = 4. [EQ 2] E#J = E#I. ==> E#J = 4. [EQ 3] F#K = E#J. ==> F#K = 4. [EQ 4] H#J = E#J + F#K. ==> H#J = 1.\\n[FINAL] 1\",\n                    \"force_start\": \"\\n[EQ 1]\", \n                    \"input_prefix\": \"\" \n                }\n            }\n            \n            for task_type, config in task_configs.items():\n                # 1. Build static context (Unchanged logic)\n                static_messages = [\n                    {\"role\": \"system\", \"content\": config[\"system\"]},\n                    {\"role\": \"user\", \"content\": config[\"example_user\"]},\n                    {\"role\": \"assistant\", \"content\": config[\"example_asst\"]}\n                ]\n                \n                static_prompt_text = tokenizer.apply_chat_template(\n                    static_messages, tokenize=False, add_generation_prompt=True\n                )\n                static_inputs = tokenizer(static_prompt_text, return_tensors=\"pt\")\n                \n                # 2. Tokenize Force Start (Unchanged logic)\n                force_start_tokens = tokenizer(\n                    config[\"force_start\"], \n                    return_tensors=\"pt\", \n                    add_special_tokens=False\n                )\n                \n                self.task_templates[task_type] = {\n                    \"static_input_ids\": static_inputs.input_ids,\n                    \"static_attention_mask\": static_inputs.attention_mask,\n                    \"force_start_ids\": force_start_tokens.input_ids,\n                    \"input_prefix\": config[\"input_prefix\"],\n                    \"force_start_text\": config[\"force_start\"]\n                }\n            \n            print(\"[+] Task templates pre-computed (Corrected with Step Prefixes and Guardrails)\")\n    \n    def _extract_final_answer(self, full_response: str, task_type: str) -> str:\n        \"\"\"Extract answer from model response\"\"\"\n        pred = \"0\"\n        \n        try:\n            if task_type == \"p_hop\":\n                patterns = [\n                    r\"Final\\s*:\\s*(\\w+)\",\n                    r\"Next token is\\s*(\\w+)\",\n                    r\"Answer\\s*:\\s*(\\w+)\",\n                ]\n                for pattern in patterns:\n                    match = re.search(pattern, full_response, re.IGNORECASE)\n                    if match:\n                        pred = match.group(1).strip()\n                        break\n                else:\n                    pred = \"Error\"\n            else:\n                patterns = [\n                    r\"Final\\s*:\\s*([-+]?\\d*\\.?\\d+)\",\n                    r\"Answer\\s*:\\s*([-+]?\\d*\\.?\\d+)\",\n                    r\"=\\s*([-+]?\\d*\\.?\\d+)$\" # Catches \"5 + 2 = 7\" at end\n                ]\n                all_matches = []\n                for pattern in patterns:\n                    matches = re.findall(pattern, full_response, re.IGNORECASE)\n                    all_matches.extend(matches)\n                \n                if all_matches:\n                    pred = all_matches[-1]\n        except Exception as e:\n            print(f\"[!] Parsing error: {e}\")\n            pred = \"ParseError\"\n        \n        return pred\n    \n    @torch.no_grad()\n    def predict_with_metrics_optimized(self, user_input: str, task_type: str, \n                                      model, tokenizer, ut_steps: int, \n                                      generation_config: dict = None):\n        \"\"\"Optimized prediction with repetition penalty to prevent loops\"\"\"\n        if not hasattr(self, 'task_templates') or task_type not in self.task_templates:\n            self._build_task_templates(tokenizer)\n        \n        template = self.task_templates[task_type]\n        device = model.device\n        \n        # Construct Input\n        input_ids = template[\"static_input_ids\"].to(device)\n        user_query = template[\"input_prefix\"] + user_input\n        user_tokens = tokenizer(user_query, return_tensors=\"pt\", \n                               add_special_tokens=False).input_ids.to(device)\n        force_start_ids = template[\"force_start_ids\"].to(device)\n        \n        input_ids = torch.cat([input_ids, user_tokens, force_start_ids], dim=1)\n        attention_mask = torch.ones_like(input_ids, device=device)\n        \n        # Improved Generation Config\n        start_time = time.perf_counter()\n        \n        gen_config = generation_config or {\n            'max_new_tokens': 1024,\n            'do_sample': False,\n            'num_beams': 1,\n            'min_length': 5\n        }\n        \n        outputs = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            pad_token_id=tokenizer.eos_token_id,\n            use_cache=True,\n            return_dict_in_generate=True,\n            output_scores=False,\n            **gen_config\n        )\n        \n        generation_time = time.perf_counter() - start_time\n        \n        # Decode\n        prompt_length = input_ids.shape[1]\n        generated_ids = outputs.sequences[0, prompt_length:]\n        generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n        \n        full_response = template[\"force_start_text\"] + generated_text\n        pred = self._extract_final_answer(full_response, task_type)\n        \n        return {\n            'full_response': full_response,\n            'prediction': pred,\n            'generation_time': generation_time,\n            'generated_tokens': generated_ids.shape[0],\n            'input_tokens': input_ids.shape[1],\n            'ut_steps': ut_steps\n        }\n    \n    @torch.no_grad()\n    def calculate_perplexity(self, model, tokenizer, text_data: List[str], \n                            ut_steps: int, max_length: int = 2048, stride: int = 512):\n        \"\"\"Calculate perplexity using sliding window\"\"\"\n        device = model.device\n        model.eval()\n        \n        if not text_data or not text_data[0]:\n            return float('nan'), float('nan')\n        \n        text_concat = text_data[0]\n        encodings = tokenizer(text_concat, return_tensors='pt', \n                            max_length=max_length * 2, truncation=True)\n        input_ids = encodings.input_ids.to(device)\n        attention_mask = encodings.attention_mask.to(device)\n        \n        if input_ids.size(1) < 2:\n            return float('nan'), float('nan')\n        \n        total_loss = 0.0\n        total_tokens = 0\n        \n        for i in tqdm(range(0, input_ids.size(1), stride), \n                     desc=f\"Calculating PPL (UT={ut_steps})\"):\n            end_loc = min(i + max_length, input_ids.size(1))\n            input_slice = input_ids[:, i:end_loc]\n            target_slice = input_slice.clone()\n            \n            if i > 0:\n                context_len = input_slice.size(1) - stride\n                if context_len > 0:\n                    target_slice[:, :context_len] = -100\n            \n            if (target_slice != -100).sum() == 0:\n                continue\n            \n            outputs = model(\n                input_ids=input_slice,\n                attention_mask=attention_mask[:, i:end_loc],\n                labels=target_slice\n            )\n            \n            if torch.isnan(outputs.loss):\n                continue\n            \n            num_valid = (target_slice != -100).sum().item()\n            total_loss += (outputs.loss * num_valid).item()\n            total_tokens += num_valid\n        \n        if total_tokens == 0:\n            return float('nan'), float('nan')\n        \n        avg_loss = total_loss / total_tokens\n        perplexity = torch.exp(torch.tensor(avg_loss)).item()\n        \n        return perplexity, avg_loss\n\n\nprint(\"âœ… OuroThinkingExperiment class loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:26:59.209087Z","iopub.execute_input":"2025-12-14T15:26:59.209301Z","iopub.status.idle":"2025-12-14T15:27:00.058580Z","shell.execute_reply.started":"2025-12-14T15:26:59.209283Z","shell.execute_reply":"2025-12-14T15:27:00.057909Z"}},"outputs":[{"name":"stdout","text":"âœ… OuroThinkingExperiment class loaded\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# CELL 6: Batch Experiment Class","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 6: Batch Experiment Class\nPurpose: Extended class with batch processing support\n\"\"\"\n\nclass OuroBatchExperiment(OuroThinkingExperiment):\n    \"\"\"Extended experiment class with batch processing\"\"\"\n    \n    def __init__(self, model_path: str, dtype=torch.float16, \n                 use_4bit_quant: bool = False, use_torch_compile: bool = False,\n                 max_batch_size: int = 4, max_new_tokens: int = 1024):\n        super().__init__(model_path, dtype, use_4bit_quant, use_torch_compile)\n        self.max_batch_size = max_batch_size\n        self.max_new_tokens = max_new_tokens\n    \n    def prepare_batch_inputs(self, prompts: List[str], task_type: str) -> List[List[int]]:\n        \"\"\"Prepare inputs for batch generation\"\"\"\n        if task_type not in self.task_templates:\n            raise ValueError(\"Templates not built. Call _build_task_templates first.\")\n        \n        template = self.task_templates[task_type]\n        \n        batch_texts = [template[\"input_prefix\"] + p for p in prompts]\n        user_encodings = self.tokenizer(batch_texts, add_special_tokens=False)\n        \n        static_ids = template[\"static_input_ids\"].squeeze(0).tolist()\n        force_ids = template[\"force_start_ids\"].squeeze(0).tolist()\n        \n        input_id_lists = []\n        for user_ids in user_encodings['input_ids']:\n            full_seq = static_ids + user_ids + force_ids\n            input_id_lists.append(full_seq)\n        \n        return input_id_lists\n    \n    @torch.no_grad()\n    def batch_predict_with_metrics(self, prompts: List[str], task_type: str,\n                                   model, tokenizer, ut_steps: int,\n                                   generation_config: Optional[GenerationConfig] = None):\n        \"\"\"Batch prediction with metrics\"\"\"\n        if not prompts:\n            return []\n        \n        simple_batch_inputs = self.prepare_batch_inputs(prompts, task_type)\n        input_lengths = [len(ids) for ids in simple_batch_inputs]\n        \n        if not hasattr(model, 'generate_batch'):\n            print(\"âš ï¸ Model doesn't support generate_batch(). Using sequential.\")\n            return self._sequential_fallback(prompts, task_type, model, \n                                            tokenizer, ut_steps, generation_config)\n        \n        if generation_config is None:\n            generation_config = GenerationConfig(\n                max_new_tokens=self.max_new_tokens,\n                use_cuda_graph=False,\n                eos_token_id=tokenizer.eos_token_id,\n                pad_token_id=tokenizer.pad_token_id,\n                do_sample=False,\n                max_batch_tokens=self.max_batch_size * self.max_new_tokens,\n            )\n        \n        start_time = time.perf_counter()\n        \n        try:\n            batch_outputs = model.generate_batch(\n                inputs=simple_batch_inputs,\n                generation_config=generation_config,\n            )\n        except Exception as e:\n            print(f\"âš ï¸ generate_batch failed: {e}. Falling back.\")\n            return self._sequential_fallback(prompts, task_type, model, \n                                            tokenizer, ut_steps, generation_config)\n        \n        batch_time = time.perf_counter() - start_time\n        \n        template = self.task_templates[task_type]\n        results = [None] * len(prompts)\n        request_ids = list(batch_outputs.keys())\n        \n        # Map outputs to prompts\n        if all(isinstance(rid, int) for rid in request_ids):\n            for request_id in request_ids:\n                if 0 <= request_id < len(prompts):\n                    output = batch_outputs[request_id]\n                    results[request_id] = self._process_single_output(\n                        output, request_id, input_lengths[request_id],\n                        template, tokenizer, task_type, ut_steps,\n                        batch_time / len(prompts)\n                    )\n        else:\n            # String/UUID request IDs\n            input_to_index = {\n                \" \".join(map(str, inp)): idx \n                for idx, inp in enumerate(simple_batch_inputs)\n            }\n            \n            for request_id in request_ids:\n                output = batch_outputs[request_id]\n                \n                if hasattr(output, 'prompt_ids'):\n                    input_key = \" \".join(map(str, output.prompt_ids))\n                    if input_key in input_to_index:\n                        idx = input_to_index[input_key]\n                        results[idx] = self._process_single_output(\n                            output, idx, len(output.prompt_ids),\n                            template, tokenizer, task_type, ut_steps,\n                            batch_time / len(prompts)\n                        )\n        \n        # Fill missing results\n        for i in range(len(prompts)):\n            if results[i] is None:\n                results[i] = {\n                    'full_response': 'ERROR: No output',\n                    'prediction': 'ERROR',\n                    'generation_time': batch_time / len(prompts),\n                    'generated_tokens': 0,\n                    'input_tokens': input_lengths[i],\n                    'ut_steps': ut_steps\n                }\n        \n        return results\n    \n    def _process_single_output(self, output, prompt_idx: int, input_length: int,\n                               template: dict, tokenizer, task_type: str,\n                               ut_steps: int, sample_time: float):\n        \"\"\"Process single batch output\"\"\"\n        if hasattr(output, 'generated_tokens'):\n            generated_ids = output.generated_tokens\n        elif hasattr(output, 'sequences') and len(output.sequences) > 0:\n            generated_ids = output.sequences[0]\n        else:\n            generated_ids = []\n        \n        generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n        full_response = template[\"force_start_text\"] + generated_text\n        \n        pred = self._extract_final_answer(full_response, task_type)\n        \n        return {\n            'full_response': full_response,\n            'prediction': pred,\n            'generation_time': sample_time,\n            'generated_tokens': len(generated_ids),\n            'input_tokens': input_length,\n            'ut_steps': ut_steps,\n            'prompt_idx': prompt_idx\n        }\n    \n    def _sequential_fallback(self, prompts, task_type, model, tokenizer, \n                            ut_steps, generation_config):\n        \"\"\"Fallback to sequential processing\"\"\"\n        results = []\n        for prompt in tqdm(prompts, desc=f\"Sequential fallback ({task_type})\"):\n            result = self.predict_with_metrics_optimized(\n                user_input=prompt,\n                task_type=task_type,\n                model=model,\n                tokenizer=tokenizer,\n                ut_steps=ut_steps,\n                generation_config=generation_config\n            )\n            results.append(result)\n        return results\n\nprint(\"âœ… OuroBatchExperiment class loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:27:00.059369Z","iopub.execute_input":"2025-12-14T15:27:00.059618Z","iopub.status.idle":"2025-12-14T15:27:00.076812Z","shell.execute_reply.started":"2025-12-14T15:27:00.059600Z","shell.execute_reply":"2025-12-14T15:27:00.076266Z"}},"outputs":[{"name":"stdout","text":"âœ… OuroBatchExperiment class loaded\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# CELL 7: Main Experiment Runner","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 7: Main Experiment Runner\nPurpose: Function to execute the full experiment pipeline with batching and logging\n\"\"\"\n\ndef run_batch_experiment(config: dict):\n    \"\"\"\n    Run experiment with batching support and W&B logging.\n    Returns: (accuracy_results, perplexity_results)\n    \"\"\"\n    # 1. Initialize W&B\n    use_wandb = config.get('WANDB', {}).get('enabled', False)\n    run = None\n    \n    if use_wandb:\n        wb_conf = config['WANDB']\n        print(f\"ðŸ”— Initializing W&B (timeout: {wb_conf.get('timeout', 30)}s)...\")\n        \n        os.environ['WANDB__SERVICE_WAIT'] = '300'\n        \n        try:\n            run = wandb.init(\n                project=wb_conf.get('project', 'ouro-looped-transformer'),\n                entity=wb_conf.get('entity', None),\n                name=wb_conf.get('run_name', f\"run_{int(time.time())}\"),\n                config=config,\n                mode=wb_conf.get('mode', 'online'),\n                settings=wandb.Settings(start_timeout=wb_conf.get('timeout', 30), _disable_stats=True)\n            )\n            print(\"âœ… W&B initialized\")\n        except Exception as e:\n            print(f\"âš ï¸ W&B failed: {e}. Continuing offline.\")\n            use_wandb = False\n            run = None\n\n    # 2. Extract Config\n    model_path = config['MODEL']['path']\n    ut_steps_list = config['INFERENCE_STEPS']\n    data_config = config['DATA']\n    eval_settings = config['EVAL_SETTINGS']\n    \n    # 3. Setup Experiment\n    experiment = OuroBatchExperiment(\n        model_path, \n        dtype=config['MODEL']['dtype'],\n        use_4bit_quant=config['MODEL'].get('use_4bit_quant', True),\n        use_torch_compile=config['MODEL'].get('use_torch_compile', True),\n        max_batch_size=config.get('OPTIMIZATION', {}).get('max_batch_size', 4),\n        max_new_tokens=config.get('OPTIMIZATION', {}).get('max_new_token', 1024)\n    )\n    \n    torch.manual_seed(42)\n    \n    # 4. Prepare Data\n    if data_config['load_existing']:\n        test_datasets = load_and_preprocess_data(data_config['data_file_path'])\n    else:\n        print(\"Generating new test datasets...\")\n        test_datasets = create_test_datasets(data_config)\n    \n    perplexity_results = []\n    perplexity_data = []\n    if eval_settings['calculate_perplexity']:\n        raw_ppl_data = create_perplexity_data(eval_settings['ppl_num_samples'])\n        perplexity_data = [\"\\n\\n\".join(raw_ppl_data)]\n    \n    all_results = []\n    \n    # 5. Main Loop\n    for ut_steps in ut_steps_list:\n        print(f\"\\n{'='*60}\\nðŸ§ª EXPERIMENT: UT Steps = {ut_steps}\\n{'='*60}\")\n        \n        # Load fresh model\n        model, tokenizer, _, _ = experiment.load_model_with_ut_steps(\n            ut_steps, eval_settings['early_exit_threshold']\n        )\n        \n        if not hasattr(experiment, '_templates_precomputed'):\n            experiment._build_task_templates(tokenizer)\n            experiment._templates_precomputed = True\n        \n        # A. Perplexity\n        if perplexity_data:\n            print(f\"ðŸ“‰ Calculating PPL...\")\n            ppl, avg_loss = experiment.calculate_perplexity(\n                model, tokenizer, perplexity_data, ut_steps,\n                max_length=eval_settings['ppl_max_length'],\n                stride=eval_settings['ppl_stride']\n            )\n            perplexity_results.append({'ut_steps': ut_steps, 'perplexity': ppl, 'avg_loss': avg_loss})\n            print(f\"âœ… PPL: {ppl:.4f} | Loss: {avg_loss:.4f}\")\n            \n            if use_wandb:\n                wandb.log({\"perplexity\": ppl, \"val_loss\": avg_loss, \"ut_steps\": ut_steps})\n        \n        # B. Accuracy & Time\n        enable_batch = config.get('OPTIMIZATION', {}).get('enable_batch', True)\n        \n        for task_type, items in test_datasets.items():\n            print(f\"\\nðŸ“ Task: {task_type} ({len(items)} samples)\")\n            task_results = []\n            start_time = time.time()\n            \n            # Determine batch strategy\n            batch_size = 1\n            if enable_batch:\n                limits = {'n_ary': 8, 'p_hop': 4, 'igsm': 2}\n                batch_size = min(limits.get(task_type, 1), experiment.max_batch_size)\n            \n            # Process Loop\n            if batch_size > 1 and len(items) >= 2:\n                # Batched Processing\n                for i in range(0, len(items), batch_size):\n                    batch_items = items[i : i + batch_size]\n                    prompts = [item['prompt'] for item in batch_items]\n                    \n                    batch_out = experiment.batch_predict_with_metrics(\n                        prompts, task_type, model, tokenizer, ut_steps\n                    )\n                    \n                    for res, item in zip(batch_out, batch_items):\n                        res_entry = _create_result_entry(res, item, task_type, ut_steps)\n                        task_results.append(res_entry)\n                        all_results.append(res_entry)\n            else:\n                # Sequential Processing\n                for item in tqdm(items, desc=f\"  {task_type}\", leave=False):\n                    res = experiment.predict_with_metrics_optimized(\n                        item['prompt'], task_type, model, tokenizer, ut_steps\n                    )\n                    res_entry = _create_result_entry(res, item, task_type, ut_steps)\n                    task_results.append(res_entry)\n                    all_results.append(res_entry)\n            \n            # Logging\n            _log_task_summary(task_results, task_type, ut_steps, start_time, use_wandb)\n        \n        # Cleanup\n        del model, tokenizer\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    # Final W&B Close\n    if use_wandb and run:\n        wandb.finish()\n        \n    return all_results, perplexity_results\n\ndef _create_result_entry(result, item, task_type, ut_steps):\n    \"\"\"Helper to format result dictionary\"\"\"\n    pred = str(result['prediction']).strip().lower()\n    target = str(item['expected_answer']).strip().lower()\n    \n    is_correct = False\n    if task_type == 'p_hop':\n        is_correct = pred == target\n    else:\n        try:\n            is_correct = abs(float(pred) - float(target)) < 0.001\n        except:\n            is_correct = pred == target\n            \n    return {\n        'task_type': task_type,\n        'difficulty': item.get('difficulty', 'unknown'),\n        'test_input': item['prompt'],\n        'expected_answer': item['expected_answer'],\n        'is_correct': is_correct,\n        'test_id': generate_test_id(task_type, item.get('difficulty', ''), item['prompt']),\n        'ut_steps': ut_steps,\n        **result\n    }\n\ndef _log_task_summary(results, task_type, ut_steps, start_time, use_wandb):\n    if not results: return\n    \n    acc = sum(r['is_correct'] for r in results) / len(results)\n    avg_time = sum(r['generation_time'] for r in results) / len(results)\n    duration = time.time() - start_time\n    \n    print(f\"    ðŸ“Š Acc={acc:.2%} | Time/Sample={avg_time:.3f}s | Total={duration:.1f}s\")\n    \n    if use_wandb:\n        wandb.log({\n            f\"{task_type}/accuracy\": acc,\n            f\"{task_type}/avg_time\": avg_time,\n            \"ut_steps\": ut_steps\n        })\n\nprint(\"âœ… Main experiment runner loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:27:00.077592Z","iopub.execute_input":"2025-12-14T15:27:00.077906Z","iopub.status.idle":"2025-12-14T15:27:00.095772Z","shell.execute_reply.started":"2025-12-14T15:27:00.077882Z","shell.execute_reply":"2025-12-14T15:27:00.095123Z"}},"outputs":[{"name":"stdout","text":"âœ… Main experiment runner loaded\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# CELL 8: Analysis Utilities","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 8: Analysis Utilities\nPurpose: Functions to analyze, clean, and merge results\n\"\"\"\n\ndef analyze_experiment_results(accuracy_results: list, perplexity_results: list = None):\n    \"\"\"Generate summary statistics dataframe\"\"\"\n    if not accuracy_results:\n        return pd.DataFrame()\n    \n    df = pd.DataFrame(accuracy_results)\n    \n    # Group by UT steps and task\n    summary = df.groupby(['ut_steps', 'task_type']).agg({\n        'is_correct': ['mean', 'count', 'std'],\n        'generation_time': ['mean', 'min', 'max'],\n        'generated_tokens': ['mean']\n    }).round(3)\n    \n    # Flatten columns\n    summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n    return summary\n\ndef load_and_process_results(file_path: str):\n    \"\"\"Load results CSV and add derived features\"\"\"\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        return pd.DataFrame()\n        \n    # Feature engineering\n    if 'generated_tokens' not in df.columns:\n        df['generated_tokens'] = df['full_response'].apply(\n            lambda x: len(re.findall(r'\\S+', str(x))) if pd.notna(x) else 0\n        )\n    \n    # Type conversion\n    df['is_correct'] = df['is_correct'].astype(bool)\n    df['ut_steps'] = pd.to_numeric(df['ut_steps'], errors='coerce').astype('Int64')\n    \n    return df\n\nprint(\"âœ… Analysis utilities loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:27:00.096481Z","iopub.execute_input":"2025-12-14T15:27:00.096723Z","iopub.status.idle":"2025-12-14T15:27:00.111908Z","shell.execute_reply.started":"2025-12-14T15:27:00.096707Z","shell.execute_reply":"2025-12-14T15:27:00.111242Z"}},"outputs":[{"name":"stdout","text":"âœ… Analysis utilities loaded\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# CELL 9: Configuration","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 9: Configuration\nPurpose: Define experiment parameters\n\"\"\"\n\nBatchConfig = {\n    # --- Model Settings ---\n    'MODEL': {\n        'path': \"ByteDance/Ouro-1.4B-Thinking\",\n        'dtype': torch.bfloat16,\n        'use_4bit_quant': False,      # Set True if low VRAM\n        'use_torch_compile': True     # Optimization\n    },\n\n    # --- Experiment Scope ---\n    'INFERENCE_STEPS': [1],           # List of loop counts to test (e.g., [1, 2, 4])\n\n    # --- Evaluation Logic ---\n    'EVAL_SETTINGS': {\n        'calculate_perplexity': True,\n        'early_exit_threshold': -1.0, # -1 disables early exit\n        'ppl_num_samples': 50,\n        'ppl_max_length': 2048,\n        'ppl_stride': 512,\n    },\n\n    # --- Logging ---\n    'WANDB': {\n        'enabled': True,\n        'project': \"ouro-trace\",\n        'run_name': f\"run_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n        'entity': None,\n        'mode': 'offline',            # Use 'online' to sync\n    },\n\n    # --- Data Generation ---\n    'DATA': {\n        'load_existing': False,\n        'data_file_path': '',\n        'n_ary': {'ops_levels': [4, 8], 'num_samples_per_level': 10},\n        'p_hop': {'hop_levels': [2, 4], 'num_samples_per_level': 10},\n        'igsm': {'num_samples_total': 20}\n    },\n\n    # --- Performance Optimization ---\n    'OPTIMIZATION': {\n        'enable_batch': True,\n        'max_batch_size': 8,\n        'max_new_token': 1024\n    }\n}\n\nprint(\"âœ… Configuration loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:27:00.112519Z","iopub.execute_input":"2025-12-14T15:27:00.113184Z","iopub.status.idle":"2025-12-14T15:27:00.128280Z","shell.execute_reply.started":"2025-12-14T15:27:00.113167Z","shell.execute_reply":"2025-12-14T15:27:00.127663Z"}},"outputs":[{"name":"stdout","text":"âœ… Configuration loaded\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# CELL 10: Execution & Visualization","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCELL 10: Execution & Visualization\nPurpose: Run the experiment, save results, and visualize outcomes\n\"\"\"\n\n# 1. Setup\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nprint(f\"ðŸ•’ Timestamp: {timestamp}\")\nprint(\"\\n\" + \"=\"*50 + \"\\nðŸš€ STARTING EXPERIMENT\\n\" + \"=\"*50)\n\n# 2. Run\nresults_acc, results_ppl = run_batch_experiment(BatchConfig)\n\n# 3. Save Results\ndf_acc = pd.DataFrame(results_acc)\ndf_ppl = pd.DataFrame(results_ppl)\n\nRUN_RESULTS_NAME = f\"run_{timestamp}\"\nos.makedirs(os.path.join(OUTPUT_PATH, RUN_RESULTS_NAME))\nacc_path = os.path.join(OUTPUT_PATH, RUN_RESULTS_NAME, f\"ouro_acc_{timestamp}.csv\")\nppl_path = os.path.join(OUTPUT_PATH, RUN_RESULTS_NAME, f\"ouro_ppl_{timestamp}.csv\")\ncfg_path = os.path.join(OUTPUT_PATH, RUN_RESULTS_NAME, f\"ouro_config_{timestamp}.yaml\")\n\ndf_acc.to_csv(acc_path, index=False)\nif not df_ppl.empty:\n    df_ppl.to_csv(ppl_path, index=False)\n\n# Save Config\ndef sanitize_config(cfg):\n    \"\"\"Convert config to YAML-safe format\"\"\"\n    clean = {}\n    for k, v in cfg.items():\n        if isinstance(v, dict):\n            clean[k] = sanitize_config(v)\n        elif str(type(v)).find('torch.') != -1:\n            clean[k] = str(v)\n        else:\n            clean[k] = v\n    return clean\n\nwith open(cfg_path, 'w') as f:\n    yaml.dump(sanitize_config(BatchConfig), f)\n\nprint(f\"\\nðŸ’¾ Results saved to {OUTPUT_PATH}\")\n\n# 4. Visualization & Reporting\nif not df_acc.empty:\n    print(\"\\n\" + \"=\"*50 + \"\\nðŸ“Š VISUALIZATION\\n\" + \"=\"*50)\n    \n    # Summary Tables\n    summary = analyze_experiment_results(results_acc)\n    print(\"\\n--- Summary Statistics ---\")\n    print(summary)\n    \n    # Plotting\n    try:\n        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n        \n        # Plot 1: Accuracy\n        acc_summary = df_acc.groupby(['task_type', 'ut_steps'])['is_correct'].mean().reset_index()\n        sns.barplot(data=acc_summary, x='ut_steps', y='is_correct', hue='task_type', ax=axes[0])\n        axes[0].set_title('Accuracy by UT Steps')\n        axes[0].set_ylabel('Accuracy')\n        axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n        \n        # Plot 2: Time\n        time_summary = df_acc.groupby(['task_type', 'ut_steps'])['generation_time'].mean().reset_index()\n        sns.barplot(data=time_summary, x='ut_steps', y='generation_time', hue='task_type', ax=axes[1])\n        axes[1].set_title('Inference Time (s) by UT Steps')\n        \n        # Plot 3: Token Count\n        sns.boxplot(data=df_acc, x='ut_steps', y='generated_tokens', hue='task_type', ax=axes[2])\n        axes[2].set_title('Generated Tokens Distribution')\n        \n        plt.tight_layout()\n        plt.show()\n        \n    except Exception as e:\n        print(f\"âš ï¸ Visualization error: {e}\")\nelse:\n    print(\"âš ï¸ No results to visualize.\")\n\nprint(\"\\nðŸ Experiment Complete.\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:27:00.129098Z","iopub.execute_input":"2025-12-14T15:27:00.129320Z","iopub.status.idle":"2025-12-14T15:38:21.430791Z","shell.execute_reply.started":"2025-12-14T15:27:00.129305Z","shell.execute_reply":"2025-12-14T15:38:21.430165Z"}},"outputs":[{"name":"stdout","text":"ðŸ•’ Timestamp: 20251214_152700\n\n==================================================\nðŸš€ STARTING EXPERIMENT\n==================================================\nðŸ”— Initializing W&B (timeout: 30s)...\nâš ï¸ W&B failed: 1 validation error for Settings\nstart_timeout\n  Extra inputs are not permitted [type=extra_forbidden, input_value=30, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden. Continuing offline.\nGenerating new test datasets...\n\n============================================================\nðŸ§ª EXPERIMENT: UT Steps = 1\n============================================================\nLoading model: UT steps=1, Early exit=-1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb59c0d351a4cd0b2d56b36ecac404b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_ouro.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80a3780016854050ba0ac2d2fe42fb4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e77033a2094f13814a64d89d3feb1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ce2bb3eea64a28addefa21f2570f85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6f0f62fdd74fd78d2c2b254ce40338"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f25fa095783411f8666d683a34abd3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab50ff4c666a4d68abbcff56505b639e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_ouro.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56bc4d98ea3a4d60af16955ae07b01eb"}},"metadata":{}},{"name":"stderr","text":"2025-12-14 15:27:03.982586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765726024.141083      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765726024.187384      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4896907f5364016b89cbb53e6e10faf"}},"metadata":{}},{"name":"stdout","text":"â†’ Applying torch.compile()\nâœ… Model loaded on cuda:0\n[+] Task templates pre-computed (Corrected with Step Prefixes and Guardrails)\nðŸ“‰ Calculating PPL...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Calculating PPL (UT=1):   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c34491e4c354f638ebccc48f52455e3"}},"metadata":{}},{"name":"stderr","text":"W1214 15:27:49.926000 47 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n","output_type":"stream"},{"name":"stdout","text":"âœ… PPL: 8.9785 | Loss: 2.1948\n\nðŸ“ Task: n_ary (20 samples)\n","output_type":"stream"},{"name":"stderr","text":"Solving 8 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:24<00:00,  3.11s/request]\nSolving 8 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [02:26<00:00, 18.28s/request]\nSolving 4 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:44<00:00, 11.04s/request]\n","output_type":"stream"},{"name":"stdout","text":"    ðŸ“Š Acc=35.00% | Time/Sample=10.778s | Total=215.6s\n\nðŸ“ Task: p_hop (20 samples)\n","output_type":"stream"},{"name":"stderr","text":"Solving 4 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/request]\nSolving 4 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/request]\nSolving 4 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/request]\nSolving 4 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/request]\nSolving 4 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/request]\n","output_type":"stream"},{"name":"stdout","text":"    ðŸ“Š Acc=35.00% | Time/Sample=1.073s | Total=21.5s\n\nðŸ“ Task: igsm (20 samples)\n","output_type":"stream"},{"name":"stderr","text":"Solving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.64s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.33s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:57<00:00, 58.70s/request] \nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:49<00:00, 24.80s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.57s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:50<00:00, 25.20s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.88s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.29s/request]\nSolving 2 requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.93s/request]\n","output_type":"stream"},{"name":"stdout","text":"    ðŸ“Š Acc=55.00% | Time/Sample=15.442s | Total=308.8s\n\nðŸ’¾ Results saved to /kaggle/working/\n\n==================================================\nðŸ“Š VISUALIZATION\n==================================================\n\n--- Summary Statistics ---\n                    is_correct_mean  is_correct_count  is_correct_std  \\\nut_steps task_type                                                      \n1        igsm                  0.55                20           0.510   \n         n_ary                 0.35                20           0.489   \n         p_hop                 0.35                20           0.489   \n\n                    generation_time_mean  generation_time_min  \\\nut_steps task_type                                              \n1        igsm                     15.442                2.318   \n         n_ary                    10.778                3.114   \n         p_hop                     1.073                1.043   \n\n                    generation_time_max  generated_tokens_mean  \nut_steps task_type                                              \n1        igsm                    58.764                  305.6  \n         n_ary                   18.305                  393.2  \n         p_hop                    1.095                   22.1  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x500 with 3 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nðŸ Experiment Complete.\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(\"Final Inspection:\\n\")\nprint(\"Top 20 Accuracy Report:\\n\")\nprint(df_acc.head(20))\nprint(f\"Full Response:\\n\")\nprint(df_acc['full_response'])\nprint(\"Perplexity Report:\\n\")\nprint(df_ppl.head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:38:21.432192Z","iopub.execute_input":"2025-12-14T15:38:21.432410Z","iopub.status.idle":"2025-12-14T15:38:21.443566Z","shell.execute_reply.started":"2025-12-14T15:38:21.432393Z","shell.execute_reply":"2025-12-14T15:38:21.442887Z"}},"outputs":[{"name":"stdout","text":"Final Inspection:\n\nTop 20 Accuracy Report:\n\n   task_type difficulty                                       test_input  \\\n0      n_ary      4_ops                          969 + 763 + 500 + 313 =   \n1      n_ary      4_ops                          237 + 353 + 914 + 403 =   \n2      n_ary      4_ops                          984 + 573 + 379 + 966 =   \n3      n_ary      4_ops                          320 + 844 + 579 + 302 =   \n4      n_ary      4_ops                          962 + 178 + 464 + 521 =   \n5      n_ary      4_ops                          145 + 286 + 461 + 906 =   \n6      n_ary      4_ops                          591 + 913 + 635 + 102 =   \n7      n_ary      4_ops                          903 + 887 + 110 + 026 =   \n8      n_ary      4_ops                          478 + 729 + 504 + 600 =   \n9      n_ary      4_ops                          262 + 850 + 494 + 859 =   \n10     n_ary      8_ops  088 + 284 + 750 + 175 + 182 + 184 + 394 + 183 =   \n11     n_ary      8_ops  647 + 691 + 601 + 698 + 340 + 823 + 079 + 416 =   \n12     n_ary      8_ops  310 + 842 + 286 + 762 + 371 + 474 + 180 + 458 =   \n13     n_ary      8_ops  780 + 669 + 885 + 126 + 363 + 058 + 594 + 688 =   \n14     n_ary      8_ops  572 + 904 + 130 + 778 + 599 + 324 + 830 + 754 =   \n15     n_ary      8_ops  884 + 792 + 713 + 735 + 949 + 963 + 797 + 374 =   \n16     n_ary      8_ops  000 + 248 + 484 + 873 + 661 + 779 + 149 + 705 =   \n17     n_ary      8_ops  781 + 522 + 983 + 185 + 514 + 753 + 657 + 435 =   \n18     n_ary      8_ops  203 + 049 + 906 + 891 + 455 + 344 + 759 + 068 =   \n19     n_ary      8_ops  972 + 606 + 088 + 688 + 378 + 797 + 401 + 033 =   \n\n   expected_answer  is_correct   test_id  ut_steps  \\\n0             2545        True  25318106         1   \n1             1907       False  d19f18ea         1   \n2             2902        True  9b82a795         1   \n3             2045       False  760b3c40         1   \n4             2125        True  1402221a         1   \n5             1798       False  b309f8d8         1   \n6             2241        True  e606ca41         1   \n7             1926        True  eba25c0b         1   \n8             2311        True  54f209e7         1   \n9             2465       False  df026a70         1   \n10            2240       False  1427d125         1   \n11            4295       False  6aa03c2d         1   \n12            3683       False  f36a3a49         1   \n13            4163       False  f69cca41         1   \n14            4891       False  baab6f98         1   \n15            6207       False  c0f0f7db         1   \n16            3899       False  b925ea77         1   \n17            4830       False  d0cca032         1   \n18            3675       False  8541c93d         1   \n19            3963        True  7ffa1ee1         1   \n\n                                        full_response prediction  \\\n0   \\n[STEP 1] Current: 0\\n[STEP 2] Add 969: 0 + 9...       2545   \n1   \\n[STEP 1] Current: 0\\n[STEP 2] Add 200: 0 + 2...          0   \n2   \\n[STEP 1] Current: 0\\n[STEP 2] Add 984: 0 + 9...       2902   \n3   \\n[STEP 1] Current: 0\\n[STEP 2] Add 320: 0 + 3...          0   \n4   \\n[STEP 1] Current: 0\\n[STEP 2] Add 962: 0 + 9...       2125   \n5   \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...          0   \n6   \\n[STEP 1] Current: 0\\n[STEP 2] Add 591: 0 + 5...       2241   \n7   \\n[STEP 1] Current: 0\\n[STEP 2] Add 903: 0 + 9...       1926   \n8   \\n[STEP 1] Current: 0\\n[STEP 2] Add 478: 0 + 4...       2311   \n9   \\n[STEP 1] Current: 0\\n[STEP 2] Add 200: 0 + 2...       5300   \n10  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...          0   \n11  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...      44956   \n12  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...          0   \n13  \\n[STEP 1] Current: 0\\n[STEP 2] Add 780: 0 + 7...          0   \n14  \\n[STEP 1] Current: 0\\n[STEP 2] Add 572: 0 + 5...          0   \n15  \\n[STEP 1] Current: 0\\n[STEP 2] Add 1000: 0 + ...          0   \n16  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...          0   \n17  \\n[STEP 1] Current: 0\\n[STEP 2] Add 781: 0 + 7...          0   \n18  \\n[STEP 1] Current: 0\\n[STEP 2] Add 20: 0 + 20...          0   \n19  \\n[STEP 1] Current: 0\\n[STEP 2] Add 972: 0 + 9...       3963   \n\n    generation_time  generated_tokens  input_tokens  prompt_idx  \n0          3.114034               126           195           0  \n1          3.114034               110           195           1  \n2          3.114034               126           195           2  \n3          3.114034               156           195           3  \n4          3.114034               126           195           4  \n5          3.114034               279           195           5  \n6          3.114034               126           195           6  \n7          3.114034               126           195           7  \n8         18.304797               126           195           0  \n9         18.304797               143           195           1  \n10        18.304797                96           215           2  \n11        18.304797              1024           215           3  \n12        18.304797              1024           215           4  \n13        18.304797              1024           215           5  \n14        18.304797              1024           215           6  \n15        18.304797              1024           215           7  \n16        11.053883                96           215           0  \n17        11.053883               285           215           1  \n18        11.053883               475           215           2  \n19        11.053883               348           215           3  \nFull Response:\n\n0     \\n[STEP 1] Current: 0\\n[STEP 2] Add 969: 0 + 9...\n1     \\n[STEP 1] Current: 0\\n[STEP 2] Add 200: 0 + 2...\n2     \\n[STEP 1] Current: 0\\n[STEP 2] Add 984: 0 + 9...\n3     \\n[STEP 1] Current: 0\\n[STEP 2] Add 320: 0 + 3...\n4     \\n[STEP 1] Current: 0\\n[STEP 2] Add 962: 0 + 9...\n5     \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...\n6     \\n[STEP 1] Current: 0\\n[STEP 2] Add 591: 0 + 5...\n7     \\n[STEP 1] Current: 0\\n[STEP 2] Add 903: 0 + 9...\n8     \\n[STEP 1] Current: 0\\n[STEP 2] Add 478: 0 + 4...\n9     \\n[STEP 1] Current: 0\\n[STEP 2] Add 200: 0 + 2...\n10    \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...\n11    \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...\n12    \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...\n13    \\n[STEP 1] Current: 0\\n[STEP 2] Add 780: 0 + 7...\n14    \\n[STEP 1] Current: 0\\n[STEP 2] Add 572: 0 + 5...\n15    \\n[STEP 1] Current: 0\\n[STEP 2] Add 1000: 0 + ...\n16    \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...\n17    \\n[STEP 1] Current: 0\\n[STEP 2] Add 781: 0 + 7...\n18    \\n[STEP 1] Current: 0\\n[STEP 2] Add 20: 0 + 20...\n19    \\n[STEP 1] Current: 0\\n[STEP 2] Add 972: 0 + 9...\n20    \\n[TRACE] Start at C. Found 'C' in sequence. N...\n21    \\n[TRACE] Start at B. Found 'B' in sequence. N...\n22    \\n[TRACE] Start at B. Found 'B' in sequence. N...\n23    \\n[TRACE] Start at B. Found 'B' in sequence. N...\n24    \\n[TRACE] Start at A. Found 'A' in sequence. N...\n25    \\n[TRACE] Start at D. Found 'D' in sequence. N...\n26    \\n[TRACE] Start at A. Found 'A' in sequence. N...\n27    \\n[TRACE] Start at D. Found 'D' in sequence. N...\n28    \\n[TRACE] Start at B. Found 'B' in sequence. N...\n29    \\n[TRACE] Start at D. Found 'D' in sequence. N...\n30    \\n[TRACE] Start at B. Found 'B' in sequence. N...\n31    \\n[TRACE] Start at D. Found 'D' in sequence. N...\n32    \\n[TRACE] Start at C. Found 'C' in sequence. N...\n33    \\n[TRACE] Start at B. Found 'B' in sequence. N...\n34    \\n[TRACE] Start at C. Found 'C' in sequence. N...\n35    \\n[TRACE] Start at D. Found 'D' in sequence. N...\n36    \\n[TRACE] Start at D. Found 'D' in sequence. N...\n37    \\n[TRACE] Start at A. Found 'A' in sequence. N...\n38    \\n[TRACE] Start at C. Found 'C' in sequence. N...\n39    \\n[TRACE] Start at C. Found 'C' in sequence. N...\n40    \\n[EQ 1] 1. = 4. [EQ 2] 4. = 4. [EQ 3] 4. = 4....\n41               \\n[EQ 1] 1.\\n\\n[EQ 2] 1.\\n\\n[FINAL] 1.\n42    \\n[EQ 1] 1.\\n\\n[EQ 2] 2.\\n\\n[EQ 3] 3.\\n\\n[EQ 4...\n43                   \\n[EQ 1] 1.\\n[EQ 2] 1.\\n[FINAL] 1.\n44    \\n[EQ 1] F#C = 3. [EQ 2] F#G = 5. [EQ 3] J#G =...\n45    \\n[EQ 1] 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...\n46    \\n[EQ 1] G#A = 5 * 4 = 20. [EQ 2] G#J = 4 * 4 ...\n47    \\n[EQ 1] B#L = 3. [EQ 2] P#L = 3. [EQ 3] G#M =...\n48    \\n[EQ 1] 1.\\n[EQ 2] 2.\\n[EQ 3] 3.\\n[EQ 4] 4.\\n...\n49    \\n[EQ 1] G#K = 4. [EQ 2] G#K = 4. [EQ 3] F#K =...\n50    \\n[EQ 1] F#J = 4. [EQ 2] F#K = 4. [EQ 3] G#E =...\n51    \\n[EQ 1] P#N = 4. [EQ 2] P#J = 6. [EQ 3] F#O =...\n52    \\n[EQ 1] L#N = 4. [EQ 2] I#L = 1. [EQ 3] J#M =...\n53    \\n[EQ 1] 1. = 4. = 4. = 4. = 4. = 4. = 4. = 4....\n54    \\n[EQ 1] 1. [EQ 2] 0. [EQ 3] 0. [EQ 4] 0. [FIN...\n55    \\n[EQ 1] I#L = 4. [EQ 2] I#J = I#L. ==> I#J = ...\n56    \\n[EQ 1] 1.\\n\\n[EQ 2] 2.\\n\\n[EQ 3] 3.\\n\\n[EQ 4...\n57                   \\n[EQ 1] 1.\\n[EQ 2] 1.\\n[FINAL] 1.\n58    \\n[EQ 1] E#B = 2. [EQ 2] N#O = O#G. [EQ 3] F#K...\n59    \\n[EQ 1] 4. [EQ 2] 4. [EQ 3] 2. [EQ 4] 1. [FIN...\nName: full_response, dtype: object\nPerplexity Report:\n\n   ut_steps  perplexity  avg_loss\n0         1    8.978494  2.194832\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(df_acc[['full_response', 'generated_tokens']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:39:50.914440Z","iopub.execute_input":"2025-12-14T15:39:50.914837Z","iopub.status.idle":"2025-12-14T15:39:50.924527Z","shell.execute_reply.started":"2025-12-14T15:39:50.914803Z","shell.execute_reply":"2025-12-14T15:39:50.923810Z"}},"outputs":[{"name":"stdout","text":"                                        full_response  generated_tokens\n0   \\n[STEP 1] Current: 0\\n[STEP 2] Add 969: 0 + 9...               126\n1   \\n[STEP 1] Current: 0\\n[STEP 2] Add 200: 0 + 2...               110\n2   \\n[STEP 1] Current: 0\\n[STEP 2] Add 984: 0 + 9...               126\n3   \\n[STEP 1] Current: 0\\n[STEP 2] Add 320: 0 + 3...               156\n4   \\n[STEP 1] Current: 0\\n[STEP 2] Add 962: 0 + 9...               126\n5   \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...               279\n6   \\n[STEP 1] Current: 0\\n[STEP 2] Add 591: 0 + 5...               126\n7   \\n[STEP 1] Current: 0\\n[STEP 2] Add 903: 0 + 9...               126\n8   \\n[STEP 1] Current: 0\\n[STEP 2] Add 478: 0 + 4...               126\n9   \\n[STEP 1] Current: 0\\n[STEP 2] Add 200: 0 + 2...               143\n10  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...                96\n11  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...              1024\n12  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...              1024\n13  \\n[STEP 1] Current: 0\\n[STEP 2] Add 780: 0 + 7...              1024\n14  \\n[STEP 1] Current: 0\\n[STEP 2] Add 572: 0 + 5...              1024\n15  \\n[STEP 1] Current: 0\\n[STEP 2] Add 1000: 0 + ...              1024\n16  \\n[STEP 1] Current: 0\\n[STEP 2] Add 10: 0 + 10...                96\n17  \\n[STEP 1] Current: 0\\n[STEP 2] Add 781: 0 + 7...               285\n18  \\n[STEP 1] Current: 0\\n[STEP 2] Add 20: 0 + 20...               475\n19  \\n[STEP 1] Current: 0\\n[STEP 2] Add 972: 0 + 9...               348\n20  \\n[TRACE] Start at C. Found 'C' in sequence. N...                21\n21  \\n[TRACE] Start at B. Found 'B' in sequence. N...                23\n22  \\n[TRACE] Start at B. Found 'B' in sequence. N...                23\n23  \\n[TRACE] Start at B. Found 'B' in sequence. N...                23\n24  \\n[TRACE] Start at A. Found 'A' in sequence. N...                22\n25  \\n[TRACE] Start at D. Found 'D' in sequence. N...                22\n26  \\n[TRACE] Start at A. Found 'A' in sequence. N...                22\n27  \\n[TRACE] Start at D. Found 'D' in sequence. N...                22\n28  \\n[TRACE] Start at B. Found 'B' in sequence. N...                23\n29  \\n[TRACE] Start at D. Found 'D' in sequence. N...                21\n30  \\n[TRACE] Start at B. Found 'B' in sequence. N...                23\n31  \\n[TRACE] Start at D. Found 'D' in sequence. N...                23\n32  \\n[TRACE] Start at C. Found 'C' in sequence. N...                21\n33  \\n[TRACE] Start at B. Found 'B' in sequence. N...                23\n34  \\n[TRACE] Start at C. Found 'C' in sequence. N...                21\n35  \\n[TRACE] Start at D. Found 'D' in sequence. N...                21\n36  \\n[TRACE] Start at D. Found 'D' in sequence. N...                22\n37  \\n[TRACE] Start at A. Found 'A' in sequence. N...                22\n38  \\n[TRACE] Start at C. Found 'C' in sequence. N...                22\n39  \\n[TRACE] Start at C. Found 'C' in sequence. N...                22\n40  \\n[EQ 1] 1. = 4. [EQ 2] 4. = 4. [EQ 3] 4. = 4....                59\n41             \\n[EQ 1] 1.\\n\\n[EQ 2] 1.\\n\\n[FINAL] 1.                24\n42  \\n[EQ 1] 1.\\n\\n[EQ 2] 2.\\n\\n[EQ 3] 3.\\n\\n[EQ 4...                47\n43                 \\n[EQ 1] 1.\\n[EQ 2] 1.\\n[FINAL] 1.                22\n44  \\n[EQ 1] F#C = 3. [EQ 2] F#G = 5. [EQ 3] J#G =...              1024\n45  \\n[EQ 1] 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0...              1024\n46  \\n[EQ 1] G#A = 5 * 4 = 20. [EQ 2] G#J = 4 * 4 ...                84\n47  \\n[EQ 1] B#L = 3. [EQ 2] P#L = 3. [EQ 3] G#M =...              1024\n48  \\n[EQ 1] 1.\\n[EQ 2] 2.\\n[EQ 3] 3.\\n[EQ 4] 4.\\n...                42\n49  \\n[EQ 1] G#K = 4. [EQ 2] G#K = 4. [EQ 3] F#K =...              1024\n50  \\n[EQ 1] F#J = 4. [EQ 2] F#K = 4. [EQ 3] G#E =...                54\n51  \\n[EQ 1] P#N = 4. [EQ 2] P#J = 6. [EQ 3] F#O =...               167\n52  \\n[EQ 1] L#N = 4. [EQ 2] I#L = 1. [EQ 3] J#M =...                98\n53  \\n[EQ 1] 1. = 4. = 4. = 4. = 4. = 4. = 4. = 4....              1024\n54  \\n[EQ 1] 1. [EQ 2] 0. [EQ 3] 0. [EQ 4] 0. [FIN...                38\n55  \\n[EQ 1] I#L = 4. [EQ 2] I#J = I#L. ==> I#J = ...               101\n56  \\n[EQ 1] 1.\\n\\n[EQ 2] 2.\\n\\n[EQ 3] 3.\\n\\n[EQ 4...                47\n57                 \\n[EQ 1] 1.\\n[EQ 2] 1.\\n[FINAL] 1.                22\n58  \\n[EQ 1] E#B = 2. [EQ 2] N#O = O#G. [EQ 3] F#K...               149\n59  \\n[EQ 1] 4. [EQ 2] 4. [EQ 3] 2. [EQ 4] 1. [FIN...                38\n","output_type":"stream"}],"execution_count":13}]}